{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5v1ITAx0Se8M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import erfcinv\n",
        "\n",
        "class EdgeComputingEnvironment:\n",
        "    def __init__(self, M=15, area_size=100, D_m=1354, eta_m_range=(100, 300), F_max_ue=1.5e9, P_max=23, B=5e6, T_max=10e-3, F_max_es=30e9, S_max_es=60e3, epsilon=10**-7, E_max=3e-3, theta=10**-26, L=8, phi=1.0, N0_dbm=-174, simulation_max_time=100):\n",
        "        \"\"\"\n",
        "        Initialize the edge computing environment with given parameters.\n",
        "        \"\"\"\n",
        "        self.M = M  # Number of users\n",
        "        self.area_size = area_size  # Size of the area in which users are distributed\n",
        "        self.D_m = D_m  # Task data size\n",
        "        self.eta_m_range = eta_m_range  # Range of computation requirements\n",
        "        self.F_max_ue = F_max_ue  # Maximum frequency of user equipment\n",
        "        self.P_max = 10 ** (P_max / 10)  # Convert maximum transmission power from dB to Watts\n",
        "        self.B = B  # Bandwidth\n",
        "        self.T_max = T_max  # Maximum tolerable delay\n",
        "        self.F_max_es = F_max_es  # Maximum frequency of edge server\n",
        "        self.S_max_es = S_max_es  # Maximum storage size of edge server\n",
        "        self.epsilon = epsilon  # Error tolerance for rate calculation\n",
        "        self.E_max = E_max  # Maximum energy consumption\n",
        "        self.theta = theta  # Energy coefficient\n",
        "        self.L = L  # Number of antennas\n",
        "        self.phi = phi  # Transmission probability\n",
        "        self.R_min = 1e6  # Minimum data rate\n",
        "        self.N0_dbm = N0_dbm  # Noise power in dBm\n",
        "        self.N0 = 10 ** (N0_dbm / 10) / 1000  # Convert noise power from dBm/Hz to Watts/Hz\n",
        "        self.simulation_max_time = simulation_max_time  # Maximum simulation time\n",
        "        self.PL_d = lambda d: 10 ** ((-35.3 - 37.6 * np.log10(d)) / 10)  # Path loss model\n",
        "\n",
        "\n",
        "        self.user_device_params = []  # List to store parameters for each user device\n",
        "        self.initialize_user_device_params()  # Initialize user device parameters\n",
        "\n",
        "        self.server_params = self.initialize_server_params()  # Initialize server parameters\n",
        "\n",
        "        self.cache = []  # Cache to store tasks\n",
        "        self.current_cache_size = 0  # Current size of the cache\n",
        "        self.transmitting_tasks = []  # List to store transmitting tasks\n",
        "        self.processing_tasks = []  # List to store processing tasks\n",
        "        self.current_time = 0  # Current simulation time\n",
        "\n",
        "        # Initialize bandwidth and computation attributes\n",
        "        self.total_bandwidth = 0 # Initialize total bandwidth\n",
        "        self.total_computation = 0 # Initialize total computation\n",
        "\n",
        "\n",
        "\n",
        "    def initialize_user_device_params(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters for each user device.\n",
        "        \"\"\"\n",
        "        for device_id in range(self.M):\n",
        "            d = np.random.uniform(0, self.area_size / 2)  # Distance to server\n",
        "            g_m = np.array([self.PL_d(d)])  # Path loss\n",
        "            h_bar = np.random.randn(1, self.L) + 1j * np.random.randn(1, self.L)  # Channel gain\n",
        "\n",
        "            self.user_device_params.append({\n",
        "                'device_id': device_id,  # Assign a unique ID to each device\n",
        "                'd': d,\n",
        "                'g_m': g_m,\n",
        "                'h_bar': h_bar,\n",
        "            })\n",
        "\n",
        "    def initialize_server_params(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters for the edge server.\n",
        "        \"\"\"\n",
        "        f_es_m = np.random.choice(np.linspace(1, self.F_max_es, 10, dtype=int))  # Server frequency\n",
        "        f_es_est = f_es_m * 0.02  # Estimated server frequency\n",
        "\n",
        "        return {\n",
        "            'f_es_m': f_es_m,\n",
        "            'f_es_est': f_es_est,\n",
        "            'S_max_es': self.S_max_es  # Maximum storage size\n",
        "        }\n",
        "\n",
        "    def create_task(self):\n",
        "        \"\"\"\n",
        "        Create a new task for a specific user.\n",
        "        \"\"\"\n",
        "        eta_m = np.random.choice(np.linspace(self.eta_m_range[0], self.eta_m_range[1], 10))  # Computation requirement\n",
        "        T_max_task = np.random.choice(np.linspace(self.T_max / 2, self.T_max, 10))  # Maximum tolerable delay for task\n",
        "        T_max_task = 0.001 # Static for article\n",
        "        task_info = {\n",
        "            'eta_m': eta_m,\n",
        "            'T_max': T_max_task,\n",
        "            'D_m': self.D_m  # Task data size\n",
        "        }\n",
        "        return task_info\n",
        "\n",
        "    def calculate_gamma_m(self, b_m, p_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the signal-to-noise ratio (SNR) for a given user.\n",
        "        \"\"\"\n",
        "        h_m = np.sqrt(self.user_device_params[user_id]['g_m'])[:, None] * self.user_device_params[user_id]['h_bar']  # Channel gain\n",
        "        gamma_m = (p_m * np.linalg.norm(h_m, axis=1) ** 2) / (b_m * self.B * self.N0)  # SNR\n",
        "\n",
        "        return gamma_m\n",
        "\n",
        "    def calculate_uplink_rate(self, b_m, p_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the uplink data rate for a given user.\n",
        "        \"\"\"\n",
        "        gamma_m = self.calculate_gamma_m(b_m, p_m, user_id)  # SNR\n",
        "        V_m = 1 - (1 / (1 + gamma_m) ** 2)  # Intermediate variable for rate calculation\n",
        "        Q_inv = np.sqrt(2) * erfcinv(2 * self.epsilon)  # Inverse Q-function\n",
        "        R_m = (self.B / np.log(2)) * (b_m * np.log(1 + gamma_m) - np.sqrt((b_m * V_m) / (self.phi * self.B)) * Q_inv)  # Uplink data rate\n",
        "\n",
        "        return R_m\n",
        "\n",
        "    def calculate_delay(self, alpha_m, cache_hit, b_m, p_m, D_m, f_ue_m, f_es_m, f_ue_est, f_es_est, eta_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the end-to-end delay for a given task.\n",
        "        \"\"\"\n",
        "        actual_f_ue_m = f_ue_m - f_ue_est  # Actual processing rate of the user device\n",
        "\n",
        "        if cache_hit == 1:\n",
        "            T_e2e = (1 - alpha_m) * eta_m * D_m / (f_es_m - f_es_est)  # Delay if task is in cache\n",
        "        else:\n",
        "            T_ue = (alpha_m * eta_m * D_m) / actual_f_ue_m  # User device processing delay\n",
        "            R_m = self.calculate_uplink_rate(b_m, p_m, user_id)  # Uplink data rate\n",
        "            T_tr = D_m / R_m  # Transmission delay\n",
        "            T_es = (1 - alpha_m) * eta_m * D_m / (f_es_m - f_es_est)  # Edge server processing delay\n",
        "            T_e2e = T_ue + T_tr + T_es  # Total end-to-end delay\n",
        "\n",
        "        return T_e2e\n",
        "\n",
        "    def calculate_energy_consumption(self, s_m, b_m, alpha_m, p_m, D_m, f_ue_m, f_ue_est, eta_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the energy consumption for a given task.\n",
        "        \"\"\"\n",
        "        R_m = self.calculate_uplink_rate(b_m, p_m, user_id)  # Calculate uplink data rate\n",
        "\n",
        "        actual_f_ue_m = f_ue_m - f_ue_est  # Calculate the actual processing rate of the UE\n",
        "\n",
        "        E_ue = alpha_m * (self.theta / 2 * eta_m * D_m * (actual_f_ue_m ** 2))  # Energy consumption at the user device\n",
        "        E_tx = ((1 - alpha_m) * D_m * p_m) / R_m  # Transmission energy\n",
        "\n",
        "        if s_m == 1:  # Task is in cache\n",
        "            E_total = 0  # No energy consumed when task is in cache\n",
        "        else:\n",
        "            E_total = (1 - s_m) * (E_ue + E_tx)  # Total energy consumption\n",
        "\n",
        "\n",
        "        return E_total\n",
        "\n",
        "    def manage_cache(self, task_info, task_delay):\n",
        "        \"\"\"\n",
        "        Manage the cache for storing and retrieving tasks.\n",
        "        \"\"\"\n",
        "        if task_delay == 0:\n",
        "            for task in self.cache:\n",
        "                if task_info == task[0]:  # Check if the task is already in cache\n",
        "                    return True\n",
        "            return False\n",
        "\n",
        "        task_size = task_info['D_m']  # Task size\n",
        "        Server_Max_Capacity = self.server_params['S_max_es']  # Server maximum capacity\n",
        "\n",
        "        if (task_size + self.current_cache_size) <= Server_Max_Capacity:\n",
        "            self.cache.append((task_info, task_delay))  # Add task to cache\n",
        "            self.current_cache_size += task_size  # Update cache size\n",
        "            return True\n",
        "        else:\n",
        "            sorted_cache = sorted(self.cache, key=lambda x: x[1], reverse=True)  # Sort tasks by delay in descending order\n",
        "\n",
        "            while (task_size + self.current_cache_size) > Server_Max_Capacity:\n",
        "                if not sorted_cache:\n",
        "                    break  # Exit loop if sorted_cache is empty\n",
        "                last_task = sorted_cache.pop()  # Remove the last task from sorted_cache\n",
        "                self.cache.remove(last_task)  # Remove the task from the cache\n",
        "                self.current_cache_size -= last_task[0]['D_m']  # Update current cache size\n",
        "\n",
        "            self.cache.append((task_info, task_delay))  # Add task to cache\n",
        "            self.current_cache_size += task_size  # Update cache size\n",
        "\n",
        "            return True\n",
        "\n",
        "    def step(self, actions):\n",
        "        \"\"\"\n",
        "        Execute a single simulation step.\n",
        "        \"\"\"\n",
        "        # Initialize cumulative metrics for the step\n",
        "        task_rewards = []  # List to store reward for each task\n",
        "        state_info = []  # List to store individual task and device state information\n",
        "\n",
        "\n",
        "        for user_id, action in enumerate(actions):\n",
        "            # Create a new task (user_id not necessary for task creation in this case)\n",
        "            task = self.create_task()\n",
        "            # Determine if the task is a cache hit or miss\n",
        "            cache_hit = 1 if self.manage_cache(task, 0) else 0\n",
        "            f_es_est = action['f_es_m'] * 0.02\n",
        "            f_ue_est = action['f_ue_m'] * 0.02\n",
        "\n",
        "\n",
        "            # Calculate the end-to-end delay for the task\n",
        "            delay = self.calculate_delay(\n",
        "                action['alpha_m'], cache_hit, action['b_m'], action['p_m'],\n",
        "                task['D_m'], action['f_ue_m'], action['f_es_m'], f_ue_est,\n",
        "                f_es_est, task['eta_m'], user_id\n",
        "            )\n",
        "\n",
        "            # Calculate the energy consumption for the task\n",
        "            energy = self.calculate_energy_consumption(\n",
        "                cache_hit, action['b_m'], action['alpha_m'], action['p_m'], task['D_m'], action['f_ue_m'],\n",
        "                f_es_est, task['eta_m'], user_id\n",
        "            )\n",
        "\n",
        "            # Calculate the uplink data rate for the user\n",
        "            R_m = self.calculate_uplink_rate(action['b_m'], action['p_m'], user_id)\n",
        "\n",
        "            # Manage task transmission and processing times\n",
        "            if cache_hit == 0:\n",
        "                transmission_end_time = self.current_time + task['D_m'] / R_m\n",
        "                processing_end_time = transmission_end_time + (1 - action['alpha_m']) * task['eta_m'] * task['D_m'] / (action['f_es_m'] - f_es_est)\n",
        "\n",
        "                self.transmitting_tasks.append((self.current_time, transmission_end_time, action['b_m']))\n",
        "                self.processing_tasks.append((transmission_end_time, processing_end_time, ((1 - action['alpha_m']) * action['f_es_m'])))\n",
        "\n",
        "                # Update cache with the task if it becomes eligible\n",
        "                self.manage_cache(task, delay)\n",
        "            else:\n",
        "                # For cache hit, only processing delay is considered\n",
        "                processing_end_time = self.current_time + (1 - action['alpha_m']) * task['eta_m'] * task['D_m'] / (action['f_es_m'] - f_es_est)\n",
        "                self.processing_tasks.append((self.current_time, processing_end_time, action['f_es_m']))\n",
        "\n",
        "            # Calculate total bandwidth and computation resource usage at current time\n",
        "            self.total_bandwidth = sum(b for _, end_time, b in self.transmitting_tasks if end_time > self.current_time)\n",
        "            self.total_computation = sum(f for _, end_time, f in self.processing_tasks if end_time > self.current_time)\n",
        "\n",
        "            # Free resources for tasks that have completed transmission or processing\n",
        "            self.transmitting_tasks = [(start_time, end_time, b) for start_time, end_time, b in self.transmitting_tasks if end_time > self.current_time]\n",
        "            self.processing_tasks = [(start_time, end_time, f) for start_time, end_time, f in self.processing_tasks if end_time > self.current_time]\n",
        "\n",
        "            Penalties = []\n",
        "\n",
        "            # Calculate reward\n",
        "            task_reward  = -delay - energy * 1e3\n",
        "\n",
        "            # Apply penalties for exceeding resource limits\n",
        "            if delay > task['T_max']:\n",
        "                task_reward -= 1e6\n",
        "                Penalties.append(\"T_max\")\n",
        "            if energy > self.E_max:\n",
        "                task_reward -= 1e6\n",
        "                Penalties.append(\"E_max\")\n",
        "            if R_m < self.R_min:\n",
        "                task_reward -= 1e6\n",
        "                Penalties.append(\"R_m\")\n",
        "            if self.total_bandwidth > 1:\n",
        "                task_reward -= 1e6\n",
        "                Penalties.append(\"Bandwith\")\n",
        "            if self.total_computation > self.F_max_es:\n",
        "                task_reward -= 1e6\n",
        "                Penalties.append(\"F_Max\")\n",
        "\n",
        "            print(Penalties)\n",
        "\n",
        "            # Check if the cumulative reward is below a certain threshold\n",
        "            if task_reward < -1e5:\n",
        "                done = True\n",
        "\n",
        "            # Store metrics and state information for the task\n",
        "            task_rewards.append(task_reward)\n",
        "\n",
        "            state_info.append({\n",
        "                'device_id': user_id,\n",
        "                'task': task,  # Include task information directly\n",
        "                'delay': delay,\n",
        "                'energy': energy,\n",
        "                'cache_hit': cache_hit,\n",
        "                'Occupied bandwidth': self.total_bandwidth,\n",
        "                'Occupied computation': self.total_computation\n",
        "            })\n",
        "\n",
        "\n",
        "            print(\"action :\", action)\n",
        "\n",
        "        print(\"state_info :\", state_info)\n",
        "        print(\"task_rewards :\", task_rewards)\n",
        "\n",
        "        # Increment current simulation time\n",
        "        self.current_time += 1\n",
        "\n",
        "        # Check if the simulation has reached its maximum allowed time\n",
        "        done = self.current_time >= self.simulation_max_time\n",
        "\n",
        "        # Prepare the next state\n",
        "        next_state = self.get_state(state_info)\n",
        "\n",
        "        return task_rewards, next_state, done\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the environment to its initial state.\n",
        "        \"\"\"\n",
        "        self.cache = []  # Clear cache\n",
        "        self.current_cache_size = 0  # Reset cache size\n",
        "        self.transmitting_tasks = []  # Clear transmitting tasks\n",
        "        self.processing_tasks = []  # Clear processing tasks\n",
        "        self.current_time = 0  # Reset current time\n",
        "        self.initialize_user_device_params()  # Reinitialize user device parameters\n",
        "        self.total_bandwidth = 0  # Reinitialize total bandwidth\n",
        "        self.total_computation = 0  # Reinitialize total computation\n",
        "        self.server_params = self.initialize_server_params()  # Reinitialize server parameters\n",
        "\n",
        "        state_info = [{\n",
        "            'device_id': user_id,\n",
        "            'task': None,  # Initial task is None\n",
        "            'delay': 0,\n",
        "            'energy': 0,\n",
        "            'cache_hit': 0,\n",
        "            'Occupied bandwidth': self.total_bandwidth,\n",
        "            'Occupied computation': self.total_computation\n",
        "        } for user_id in range(self.M)]\n",
        "\n",
        "        initial_state = self.get_state(state_info)  # Get the initial state\n",
        "        return initial_state\n",
        "\n",
        "\n",
        "    def get_state(self, state_info):\n",
        "        \"\"\"\n",
        "        Get the current state of the environment.\n",
        "        \"\"\"\n",
        "        state = {\n",
        "            'total_bandwidth': self.total_bandwidth,\n",
        "            'total_computation': self.total_computation,\n",
        "            'current_time': self.current_time,\n",
        "            'cache_size': self.current_cache_size,\n",
        "            'state_info': state_info  # Include task and device information\n",
        "        }\n",
        "        return state\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Total Bandwidth Used: {self.total_bandwidth}\")\n",
        "        print(f\"Total Computation Used: {self.total_computation}\")\n",
        "        print(f\"Current Cache Size: {self.current_cache_size}\")\n",
        "        print(f\"Number of Transmitting Tasks: {len(self.transmitting_tasks)}\")\n",
        "        print(f\"Number of Processing Tasks (Not Exist In Cache): {len(self.processing_tasks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bir8fLMtSm6e",
        "outputId": "551b9f38-849f-4331-f6ca-132e448e3559"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'EdgeComputingEnvironment' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 257\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_table \u001b[39m=\u001b[39m convert_keys_to_tuple(json\u001b[39m.\u001b[39mload(f))\n\u001b[0;32m    256\u001b[0m \u001b[39m# Assuming you have your EdgeComputingEnvironment defined as per your code\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m env \u001b[39m=\u001b[39m EdgeComputingEnvironment()\n\u001b[0;32m    259\u001b[0m \u001b[39m# Define the number of users/devices\u001b[39;00m\n\u001b[0;32m    260\u001b[0m num_users \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mM\n",
            "\u001b[1;31mNameError\u001b[0m: name 'EdgeComputingEnvironment' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, env, num_users, alpha=0.1, gamma=0.95, epsilon=1, max_steps_per_episode=20):\n",
        "        self.env = env\n",
        "        self.num_users = num_users\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = {}\n",
        "        self.max_steps_per_episode = max_steps_per_episode\n",
        "\n",
        "    def get_state(self, state_info):\n",
        "        state = self.env.get_state(state_info)\n",
        "        return state\n",
        "\n",
        "    def make_hashable(self, d):\n",
        "        if isinstance(d, dict):\n",
        "            return tuple(sorted((k, self.make_hashable(v)) for k, v in d.items()))\n",
        "        if isinstance(d, list):\n",
        "            return tuple(self.make_hashable(e) for e in d)\n",
        "        if isinstance(d, np.ndarray):\n",
        "            return tuple(d.tolist())\n",
        "        return d\n",
        "    \n",
        "    def update_epsilon(self, decay_rate=0.995, min_epsilon=0.01):\n",
        "        self.epsilon = max(min_epsilon, self.epsilon * decay_rate)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        state_key = self.make_hashable(state)\n",
        "        print(f\"State Key: {state_key}\")\n",
        "        \n",
        "        if state_key not in self.q_table:\n",
        "            print(\"State key not in Q-table, initializing Q-values\")\n",
        "            self.q_table[state_key] = self.initialize_q_values()\n",
        "\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            action = self.generate_random_action()\n",
        "            print(\"Random Action:\", action)\n",
        "            action_key = tuple(action.items())\n",
        "            if action_key not in self.q_table[state_key]:\n",
        "                self.q_table[state_key][action_key] = -100\n",
        "        else:\n",
        "            action_key = max(self.q_table[state_key], key=self.q_table[state_key].get)\n",
        "            action = dict(action_key)\n",
        "            print(\"Q-table Action:\", action)\n",
        "        \n",
        "        return action\n",
        "\n",
        "\n",
        "    def initialize_q_values(self):\n",
        "        q_values = {}\n",
        "        random_action = self.generate_random_action()\n",
        "        q_values[tuple(random_action.items())] = -100\n",
        "        return q_values\n",
        "\n",
        "\n",
        "    def generate_random_action(self):\n",
        "        alpha = np.random.choice(np.linspace(0.1, 1, 3))\n",
        "        b = np.random.choice(np.linspace(0.1, 0.3, 3))\n",
        "        p = np.random.choice(np.linspace(self.env.P_max / 10, self.env.P_max, 3))\n",
        "        f_ue = np.random.choice(np.linspace(self.env.F_max_ue / 3, self.env.F_max_ue, 3))\n",
        "        f_es = np.random.choice(np.linspace(self.env.F_max_es / 100, self.env.F_max_es / 10, 3))\n",
        "\n",
        "        action = {\n",
        "            'alpha_m': alpha,\n",
        "            'b_m': b,\n",
        "            'p_m': p,\n",
        "            'f_ue_m': f_ue,\n",
        "            'f_es_m': f_es\n",
        "        }\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        state_key = self.make_hashable(state)\n",
        "        action_key = tuple(action.items())\n",
        "        next_state_key = self.make_hashable(next_state)\n",
        "\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = self.initialize_q_values()\n",
        "        \n",
        "        if action_key not in self.q_table[state_key]:\n",
        "            self.q_table[state_key][action_key] = -100\n",
        "        \n",
        "        if next_state_key not in self.q_table:\n",
        "            self.q_table[next_state_key] = self.initialize_q_values()\n",
        "\n",
        "        current_q = self.q_table[state_key][action_key]\n",
        "        max_next_q = max(self.q_table[next_state_key].values())\n",
        "\n",
        "        self.q_table[state_key][action_key] = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
        "\n",
        "        print(f\"\\nState: {state_key}\")\n",
        "        print(f\"Action: {action_key}\")\n",
        "        print(f\"Reward: {reward}\")\n",
        "        print(f\"Next State: {next_state_key}\")\n",
        "        print(\"current_q :\", current_q)\n",
        "        print(f\"Updated Q-value: {self.q_table[state_key][action_key]}\")\n",
        "\n",
        "    def train(self, num_episodes):\n",
        "        avg_delays = []\n",
        "        avg_energies = []\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            state_info = self.env.reset()\n",
        "            state = self.get_state(state_info)\n",
        "            total_delay = 0\n",
        "            total_energy = 0\n",
        "            num_steps = 0\n",
        "\n",
        "            states_choose_actions = [{\n",
        "                'total_bandwidth': 0,\n",
        "                'total_computation': 0,\n",
        "                'current_time': 0,\n",
        "                'cache_size': 0,\n",
        "                'device_id': user_id,\n",
        "                'task': None,\n",
        "                'cache_hit': 0,\n",
        "                'Occupied bandwidth': 0,\n",
        "                'Occupied computation': 0\n",
        "            } for user_id in range(self.num_users)]\n",
        "\n",
        "            for step in range(self.max_steps_per_episode):\n",
        "                actions = []\n",
        "                states_choose_actions = self.make_hashable(states_choose_actions)\n",
        "\n",
        "                for user_id in range(self.num_users):\n",
        "                    action = self.get_action(states_choose_actions[user_id])\n",
        "                    actions.append(action)\n",
        "                    print(\"actions : \",actions)\n",
        "                print(\"total_energy :\", total_energy)\n",
        "                rewards, next_state_info, done = self.env.step(actions)\n",
        "                next_state = self.get_state(next_state_info)\n",
        "\n",
        "                state_info_list = state['state_info']\n",
        "                state_info_list = state_info_list['state_info']\n",
        "\n",
        "                next_state_info_list = next_state_info['state_info']\n",
        "                # Debug: print state_info and next_state_info\n",
        "                print(\"next_state: ,\", next_state)\n",
        "                print(f\"state_info: {state_info}\")\n",
        "                print(f\"state: {state}\")\n",
        "                print(f\"next_state_info: {next_state_info}\")\n",
        "                print(\"len(state_info_list): \",len(state_info_list))\n",
        "                print(\"state_info_list: \",state_info_list)\n",
        "                print(\"next_state_info_list: \",next_state_info_list)\n",
        "                states_choose_actions = []\n",
        "\n",
        "                for user_id in range(len(state_info_list)):\n",
        "                    device_info = state_info_list[user_id]\n",
        "                    next_device_info = next_state_info_list[user_id]\n",
        "                    action = actions[user_id]\n",
        "                    reward = rewards[user_id]\n",
        "                    print(f\"device_info: {device_info}\")\n",
        "                    print(f\"next_device_info: {next_device_info}\")\n",
        "                    print(f\"action: {actions[user_id]}\")\n",
        "                    print(f\"reward: {rewards[user_id]}\")\n",
        "\n",
        "                    # Extract 'delay' and 'energy' for calculations\n",
        "                    delay = next_device_info.pop('delay', 0)\n",
        "                    energy = next_device_info.pop('energy', 0)\n",
        "                    device_info.pop('delay', 0)\n",
        "                    device_info.pop('energy', 0)\n",
        "                    print(\"delay :\", delay)\n",
        "                    print(\"energy :\", energy)\n",
        "                    \n",
        "                    if isinstance(device_info, dict) and isinstance(next_device_info, dict):\n",
        "                        state_without_last = {k: state[k] for k in list(state.keys())[:-1]}\n",
        "                        next_state_without_last = {k: next_state[k] for k in list(next_state.keys())[:-1]}\n",
        "                        combined_state = {**state_without_last, **device_info}\n",
        "                        combined_next_state = {**next_state_without_last, **next_device_info}\n",
        "                        states_choose_actions.append(combined_next_state)\n",
        "                        print(\"combined_state111: ,\", combined_state)\n",
        "\n",
        "                        combined_state = self.make_hashable(combined_state)\n",
        "                        combined_next_state = self.make_hashable(combined_next_state)\n",
        "                        print(\"combined_state: ,\", combined_state)\n",
        "                        print(\"combined_next_state: ,\", combined_next_state)\n",
        "\n",
        "                        print(\"states_choose_actions: ,\", states_choose_actions)\n",
        "                        self.update_q_table(combined_state, action, reward, combined_next_state)\n",
        "                        total_delay += delay\n",
        "                        total_energy += energy\n",
        "                    else:\n",
        "                        raise TypeError(\"device_info and next_device_info must be dictionaries\")\n",
        "\n",
        "                state = next_state\n",
        "                print(\"total_delay :\",total_delay)\n",
        "                print(\"total_energy :\",total_energy)\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "                num_steps += 1\n",
        "\n",
        "            avg_delay = total_delay / ((num_steps if num_steps > 0 else 0) * len(state_info_list)) # or self.num_users\n",
        "            avg_energy = total_energy / ((num_steps if num_steps > 0 else 0) * len(state_info_list))\n",
        "            avg_delays.append(avg_delay)\n",
        "            avg_energies.append(avg_energy)\n",
        "\n",
        "            print(f'Episode {episode + 1}/{num_episodes} - Avg Delay: {avg_delay}, Avg Energy: {avg_energy}')\n",
        "            print(\"-\" * 100)\n",
        "            \n",
        "            # Update epsilon at the end of each episode\n",
        "            self.update_epsilon()\n",
        "\n",
        "        self.plot_results(avg_delays, avg_energies)\n",
        "\n",
        "    def plot_results(self, avg_delays, avg_energies):\n",
        "        episodes = np.arange(1, len(avg_delays) + 1)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(episodes, avg_delays, label='Avg Delay')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Average Delay')\n",
        "        plt.title('Average Delay per Episode')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(episodes, avg_energies, label='Avg Energy')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Average Energy')\n",
        "        plt.title('Average Energy per Episode')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def save_q_table(self, filename):\n",
        "        def convert_keys_to_str(d):\n",
        "            if isinstance(d, dict):\n",
        "                return {str(k): convert_keys_to_str(v) for k, v in d.items()}\n",
        "            elif isinstance(d, np.ndarray):\n",
        "                return d.tolist()\n",
        "            else:\n",
        "                return d\n",
        "\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(convert_keys_to_str(self.q_table), f)\n",
        "\n",
        "    def load_q_table(self, filename):\n",
        "        def convert_keys_to_tuple(d):\n",
        "            if isinstance(d, dict):\n",
        "                return {eval(k): convert_keys_to_tuple(v) for k, v in d.items()}\n",
        "            else:\n",
        "                return d\n",
        "\n",
        "        with open(filename, 'r') as f:\n",
        "            self.q_table = convert_keys_to_tuple(json.load(f))\n",
        "\n",
        "\n",
        "# Assuming you have your EdgeComputingEnvironment defined as per your code\n",
        "env = EdgeComputingEnvironment()\n",
        "\n",
        "# Define the number of users/devices\n",
        "num_users = env.M\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "agent = QLearningAgent(env, num_users)\n",
        "\n",
        "# Train the agent\n",
        "num_episodes = 5  # Adjust the number of episodes as needed\n",
        "agent.train(num_episodes)\n",
        "\n",
        "# Show the Q-table\n",
        "#agent.save_q_table('Q_table.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
