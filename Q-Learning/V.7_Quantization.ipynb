{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import erfcinv\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Edge Computing Environment\n",
        "\n",
        "class EdgeComputingEnvironment:\n",
        "    def __init__(self, M=15, area_size=100, D_m=1354, eta_m_range=(100, 300), F_max_ue=1.5, P_max=23, B=5e6, T_max=10e-3, F_max_es=30, S_max_es=60, epsilon=10e-7, E_max=3, theta=1e-26, L=8, phi=0.02e-3, N0=-174, f_es_dev=0.02, f_ue_dev=0.02):\n",
        "        \"\"\"\n",
        "        Initialize the edge computing environment with given parameters.\n",
        "        \"\"\"\n",
        "        self.M = M  # Number of users\n",
        "        self.area_size = area_size  # Size of the area in which users are distributed\n",
        "        self.D_m = D_m  # Task data size\n",
        "        self.eta_m_range = eta_m_range  # Range of computation requirements\n",
        "        self.F_max_ue = F_max_ue * 1e9  # Maximum frequency of user equipment\n",
        "        self.P_max = 10 ** (P_max / 10)  # Convert maximum transmission power from dB to Watts\n",
        "        self.B = B  # Bandwidth\n",
        "        self.T_max = T_max  # Maximum tolerable delay\n",
        "        self.F_max_es = F_max_es * 1e9  # Maximum frequency of edge server\n",
        "        self.S_max_es = S_max_es * 1e3  # Maximum storage size of edge server\n",
        "        self.epsilon = epsilon  # Error tolerance for rate calculation\n",
        "        self.E_max = E_max * 1e-3  # Maximum energy consumption\n",
        "        self.theta = theta  # Energy coefficient\n",
        "        self.L = L  # Number of antennas\n",
        "        self.phi = phi  # Transmission time interval\n",
        "        self.R_min = 1e6  # Minimum data rate\n",
        "        self.N0 = N0  # Noise power in dBm\n",
        "        self.N0 = 10 ** ((N0 - 30) / 10)  # Convert noise power from dBm/Hz to Watts/Hz\n",
        "        self.PL_d = lambda d: 10 ** ((10 ** ((-35.3 - (37.6 * np.log10(d))) / 10)) / 10)  # Path loss model\n",
        "        self.f_es_dev = f_es_dev  #The deviation between the estimated value and the actual value of the processing rate of the ES\n",
        "        self.f_ue_dev = f_ue_dev  #The deviation between the estimated value and the actual value of the processing rate of the UE\n",
        "        self.penalty = 0.25\n",
        "        self.treshhold = -0.6 \n",
        "\n",
        "        self.user_device_params = []  # List to store parameters for each user device\n",
        "        self.initialize_user_device_params()  # Initialize user device parameters\n",
        "\n",
        "        self.server_params = self.initialize_server_params()  # Initialize server parameters\n",
        "\n",
        "        self.cache = []  # Cache to store tasks\n",
        "        self.current_cache_size = 0  # Current size of the cache\n",
        "        self.transmitting_tasks = []  # List to store transmitting tasks\n",
        "        self.processing_tasks = []  # List to store processing tasks\n",
        "        self.current_time = 0  # Current simulation time\n",
        "\n",
        "        # Initialize bandwidth and computation attributes\n",
        "        self.total_bandwidth = 0 # Initialize total bandwidth\n",
        "        self.total_computation = 0 # Initialize total computation\n",
        "\n",
        "    def initialize_user_device_params(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters for each user device.\n",
        "        Randomly generates user-specific parameters such as path loss.\n",
        "        \"\"\"\n",
        "        for device_id in range(self.M):\n",
        "            d = np.random.uniform(1, self.area_size / 2)  # Distance to server\n",
        "            g_m = np.array([self.PL_d(d)])  # Path loss\n",
        "            h_bar = np.random.randn(1, self.L) + 1j * np.random.randn(1, self.L)  # Channel gain\n",
        "\n",
        "            self.user_device_params.append({\n",
        "                'device_id': device_id,  # Assign a unique ID to each device\n",
        "                'd': d,\n",
        "                'g_m': g_m,\n",
        "                'h_bar': h_bar,\n",
        "            })\n",
        "\n",
        "    def initialize_server_params(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters for the edge server.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'S_max_es': self.S_max_es  # Maximum storage size\n",
        "        }\n",
        "\n",
        "    def calculate_gamma_m(self, b_m, p_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the signal-to-noise ratio (SNR) for a given user.\n",
        "\n",
        "        Parameters:\n",
        "        - b_m (float): Bandwidth allocation\n",
        "        - p_m (float): Transmission power\n",
        "        - user_id (int): ID of the user\n",
        "\n",
        "        Returns:\n",
        "        - gamma_m (array): SNR values for the user's communication channel\n",
        "        \"\"\"\n",
        "        h_m = np.sqrt(self.user_device_params[user_id]['g_m'])[:, None] * self.user_device_params[user_id]['h_bar']  # Channel gain\n",
        "        gamma_m = (p_m * np.linalg.norm(h_m, axis=1) ** 2) / (b_m * self.B * self.N0)  # SNR\n",
        "\n",
        "        return gamma_m\n",
        "\n",
        "    def calculate_uplink_rate(self, b_m, p_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the uplink data rate for a given user.\n",
        "\n",
        "        Parameters:\n",
        "        - b_m (float): Bandwidth allocation\n",
        "        - p_m (float): Transmission power\n",
        "        - user_id (int): ID of the user\n",
        "\n",
        "        Returns:\n",
        "        - R_m (float): Uplink data rate in bits/second\n",
        "        \"\"\"\n",
        "        gamma_m = self.calculate_gamma_m(b_m, p_m, user_id)  # Calculate the SINR for the m-th user\n",
        "        V_m = 1 - (1 / (1 + gamma_m) ** 2)  # Intermediate variable for rate calculation\n",
        "        Q_inv = np.sqrt(2) * erfcinv(2 * self.epsilon)  # Calculate the inverse of the Q-function for the outage probability\n",
        "        R_m = (self.B / np.log(2)) * ((b_m * np.log(1 + gamma_m)) - ((np.sqrt((b_m * V_m) / (self.phi * self.B))) * Q_inv))  # Uplink data rate\n",
        "\n",
        "        return R_m\n",
        "\n",
        "    def calculate_delay(self, alpha_m, cache_hit, b_m, p_m, D_m, f_ue_m, f_es_m, f_ue_est, f_es_est, eta_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the end-to-end delay for a given task.\n",
        "\n",
        "        Parameters:\n",
        "        - alpha_m (float): Offloading decision\n",
        "        - cache_hit (int): Split factor (0 or 1)\n",
        "        - b_m (float): Bandwidth allocation\n",
        "        - p_m (float): Transmission power\n",
        "        - D_m (int): Data size\n",
        "        - f_ue_m (float): Computation capability of the user device\n",
        "        - f_es_m (float): Computation capability of the edge server\n",
        "        - f_ue_est (float): Estimation error for the user device's computation capability\n",
        "        - f_es_est (float): Estimation error for the edge server's computation capability\n",
        "        - eta_m (float): Computational intensity\n",
        "        - user_id (int): ID of the user\n",
        "\n",
        "        Returns:\n",
        "        - T_e2e (float): End-to-end delay in seconds\n",
        "        \"\"\"\n",
        "        actual_f_ue_m = f_ue_m - f_ue_est  # Actual processing rate of the user device\n",
        "        actual_f_es_m = f_es_m - f_es_est  # Actual processing rate of the Edge server\n",
        "\n",
        "        if cache_hit == 1:\n",
        "            T_es = (eta_m * D_m) / actual_f_es_m  # Only edge server processing delay\n",
        "            T_e2e = T_es\n",
        "\n",
        "        else:\n",
        "            T_ue = (alpha_m * eta_m * D_m) / actual_f_ue_m  # User device processing delay\n",
        "            R_m = self.calculate_uplink_rate(b_m, p_m, user_id)  # Uplink data rate\n",
        "            T_tr = (D_m * 8) / R_m  # Transmission delay\n",
        "            T_es = ((1 - alpha_m) * eta_m * D_m) / actual_f_es_m  # Edge server processing delay\n",
        "            T_e2e = T_ue + T_tr + T_es  # Total end-to-end delay\n",
        "        return T_e2e\n",
        "\n",
        "    def calculate_transmission_delay(self, b_m, p_m, D_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the transmission delay for a given task.\n",
        "\n",
        "        Parameters:\n",
        "        - b_m (float): Bandwidth allocation\n",
        "        - p_m (float): Transmission power\n",
        "        - D_m (int): Data size\n",
        "        - user_id (int): ID of the user\n",
        "\n",
        "        Returns:\n",
        "        - T_co (float): Transmission delay in seconds\n",
        "        \"\"\"\n",
        "        R_m = self.calculate_uplink_rate(b_m, p_m, user_id)  # Calculate uplink data rate\n",
        "        T_co =  (D_m * 8) / R_m   # Transmission delay calculation based on task size and uplink rate\n",
        "\n",
        "        return T_co\n",
        "\n",
        "    def calculate_server_processing_delay(self, alpha_m, cache_hit, D_m, f_es_m, f_es_est, eta_m):\n",
        "        \"\"\"\n",
        "        Calculate the processing delay at the edge server for a given task.\n",
        "\n",
        "        Parameters:\n",
        "        - alpha_m (float): Offloading decision\n",
        "        - D_m (int): Data size\n",
        "        - cache_hit (0,1): 1 = Exist in cache and 0 not exist in cache\n",
        "        - f_es_m (float): Computation capability of the edge server\n",
        "        - f_es_est (float): Estimation error for the edge server's computation capability\n",
        "        - eta_m (float): Computational intensity\n",
        "\n",
        "        Returns:\n",
        "        - T_es (float): Processing delay at the edge server in seconds\n",
        "        \"\"\"\n",
        "\n",
        "        if cache_hit == 0:\n",
        "            T_es = ((1 - alpha_m) * eta_m * D_m) / (f_es_m - f_es_est)  # Processing delay at the edge server\n",
        "\n",
        "        else:\n",
        "            T_es = (eta_m * D_m) / (f_es_m - f_es_est)\n",
        "\n",
        "        return T_es\n",
        "\n",
        "    def calculate_energy_consumption(self, s_m, b_m, alpha_m, p_m, D_m, f_ue_m, f_ue_est, eta_m, user_id):\n",
        "        \"\"\"\n",
        "        Calculate the energy consumption for a given task.\n",
        "\n",
        "        Parameters:\n",
        "        - alpha_m (float): Offloading decision\n",
        "        - s_m (int): Split factor (0 or 1)\n",
        "        - f_ue_m (float): Computation capability of the user device\n",
        "        - b_m (float): Bandwidth allocation\n",
        "        - p_m (float): Transmission power\n",
        "        - f_ue_est (float): Estimation error for the user device's computation capability\n",
        "        - eta_m (float): Computational intensity\n",
        "\n",
        "        Returns:\n",
        "        - E_total (float): Total energy consumption in Joules\n",
        "        \"\"\"\n",
        "        R_m = self.calculate_uplink_rate(b_m, p_m, user_id)  # Calculate uplink data rate\n",
        "\n",
        "        actual_f_ue_m = f_ue_m - f_ue_est  # Calculate the actual processing rate of the UE\n",
        "\n",
        "        E_ue = alpha_m * (self.theta / 2) * eta_m * D_m * (actual_f_ue_m ** 2)  # Energy consumption at the user device\n",
        "        E_tx = ((1 - alpha_m) * (D_m * 8) * p_m) / R_m  # Transmission energy\n",
        "\n",
        "        if s_m == 1:  # Task is in cache\n",
        "            E_total = 0  # No energy consumed when task is in cache\n",
        "        else:\n",
        "            E_total = E_ue + E_tx  # Total energy consumption\n",
        "\n",
        "        return E_total\n",
        "\n",
        "    def manage_cache(self, task_info, task_delay):\n",
        "        \"\"\"\n",
        "        Manage the cache for storing and retrieving tasks.\n",
        "\n",
        "        Parameters:\n",
        "        - task_info (tuple): Task parameters to identify the task\n",
        "        - task_delay (float): Delay of the task\n",
        "\n",
        "        Returns:\n",
        "        - bool: True if the task is found in the cache, False otherwise\n",
        "        \"\"\"\n",
        "        if task_delay == 0:\n",
        "            for task in self.cache:\n",
        "                if task_info == task[0]:  # Check if the task is already in cache\n",
        "                    return True\n",
        "            return False\n",
        "\n",
        "        task_size = task_info['D_m'] * 8  # Task size\n",
        "        Server_Max_Capacity = self.server_params['S_max_es']  # Server maximum capacity\n",
        "\n",
        "        if (task_size + self.current_cache_size) <= Server_Max_Capacity:\n",
        "            self.cache.append((task_info, task_delay))  # Add task to cache\n",
        "            self.current_cache_size += task_size  # Update cache size\n",
        "            return True\n",
        "        else:\n",
        "            sorted_cache = sorted(self.cache, key=lambda x: x[1], reverse=True)  # Sort tasks by delay in descending order\n",
        "\n",
        "            while (task_size + self.current_cache_size) > Server_Max_Capacity:\n",
        "                if not sorted_cache:\n",
        "                    break  # Exit loop if sorted_cache is empty\n",
        "                last_task = sorted_cache.pop()  # Remove the last task from sorted_cache\n",
        "                self.cache.remove(last_task)  # Remove the task from the cache\n",
        "                self.current_cache_size -= last_task[0]['D_m'] * 8  # Update current cache size\n",
        "\n",
        "            self.cache.append((task_info, task_delay))  # Add task to cache\n",
        "            self.current_cache_size += task_size  # Update cache size\n",
        "\n",
        "            return True\n",
        "\n",
        "    def step(self, actions, tasks, users_id):\n",
        "        \"\"\"\n",
        "        Perform a simulation step for the given action.\n",
        "\n",
        "        Parameters:\n",
        "        - action (array): Array of action for each user\n",
        "        - tasks (array): Array of task for each user\n",
        "\n",
        "        Returns:\n",
        "        - tuple: (task_rewards, next_state, done)\n",
        "        \"\"\"\n",
        "        # Initialize cumulative metrics for the step\n",
        "        task_rewards = []  # List to store reward for each task\n",
        "        state_info = []  # List to store individual task and device state information\n",
        "        done = False\n",
        "\n",
        "        for action, task, user_id in zip(actions, tasks, users_id):\n",
        "\n",
        "            # Determine if the task is a cache hit or miss\n",
        "            cache_hit = 1 if self.manage_cache(task, 0) else 0\n",
        "\n",
        "            f_es_est = action['f_es_m'] * self.f_es_dev  # initialize f_es_est\n",
        "            f_ue_est = action['f_ue_m'] * self.f_ue_dev  # initialize f_ue_est\n",
        "\n",
        "            # Calculate the end-to-end delay for the task\n",
        "            delay = self.calculate_delay(\n",
        "                action['alpha_m'], cache_hit, action['b_m'], action['p_m'],\n",
        "                task['D_m'], action['f_ue_m'], action['f_es_m'], f_ue_est,\n",
        "                f_es_est, task['eta_m'], user_id\n",
        "            )\n",
        "\n",
        "            # Calculate the energy consumption for the task\n",
        "            energy = self.calculate_energy_consumption(\n",
        "                cache_hit, action['b_m'], action['alpha_m'], action['p_m'], task['D_m'], action['f_ue_m'],\n",
        "                f_es_est, task['eta_m'], user_id\n",
        "            )\n",
        "\n",
        "            # Calculate the uplink data rate for the user\n",
        "            R_m = self.calculate_uplink_rate(action['b_m'], action['p_m'], user_id)\n",
        "            print(R_m)\n",
        "            # Manage task transmission and processing times\n",
        "            if cache_hit == 0:\n",
        "                transmission_end_time = self.current_time + self.calculate_transmission_delay(action['b_m'], action['p_m'],task['D_m'], user_id)\n",
        "                processing_end_time = transmission_end_time + self.calculate_server_processing_delay(action['alpha_m'], cache_hit, task['D_m'], action['f_es_m'], f_es_est, task['eta_m'])\n",
        "\n",
        "                self.transmitting_tasks.append((self.current_time, transmission_end_time, action['b_m']))\n",
        "                self.processing_tasks.append((transmission_end_time, processing_end_time, action['f_es_m']))\n",
        "\n",
        "                # Update cache with the task if it becomes eligible\n",
        "                self.manage_cache(task, delay)\n",
        "            else:\n",
        "                # For cache hit, only processing delay is considered\n",
        "                processing_end_time = self.current_time + self.calculate_server_processing_delay(action['alpha_m'], cache_hit, task['D_m'], action['f_es_m'], f_es_est, task['eta_m'])\n",
        "                process = action['f_es_m'] * (1 - action['alpha_m'])\n",
        "                self.processing_tasks.append((self.current_time, processing_end_time, process))\n",
        "\n",
        "            # Calculate total bandwidth and computation resource usage at current time\n",
        "            self.total_bandwidth = sum(b for _, end_time, b in self.transmitting_tasks if end_time > self.current_time)\n",
        "            self.total_computation = sum(f for _, end_time, f in self.processing_tasks if end_time > self.current_time)\n",
        "\n",
        "            # Free resources for tasks that have completed transmission or processing\n",
        "            self.transmitting_tasks = [(start_time, end_time, b) for start_time, end_time, b in self.transmitting_tasks if end_time > self.current_time]\n",
        "            self.processing_tasks = [(start_time, end_time, f) for start_time, end_time, f in self.processing_tasks if end_time > self.current_time]\n",
        "\n",
        "            # Calculate reward\n",
        "            task_reward  = -delay - energy\n",
        "\n",
        "            # Apply penalties for exceeding resource limits\n",
        "            if delay > task['T_max']:\n",
        "                task_reward -= self.penalty\n",
        "            if energy > self.E_max:\n",
        "                task_reward -= self.penalty\n",
        "            if R_m < self.R_min:\n",
        "                task_reward -= self.penalty\n",
        "            if self.total_bandwidth > 1:\n",
        "                task_reward -= self.penalty\n",
        "            if self.total_computation > self.F_max_es:\n",
        "                task_reward -= self.penalty\n",
        "\n",
        "            # Check if the cumulative reward is below a certain threshold\n",
        "            if task_reward < self.treshhold:\n",
        "                done = True\n",
        "\n",
        "            # Store metrics and state information for the task\n",
        "            task_rewards.append(task_reward)\n",
        "\n",
        "            state_info.append({\n",
        "                'device_id': user_id,\n",
        "                'task': task,  # Include task information directly\n",
        "                'delay': delay,\n",
        "                'energy': energy,\n",
        "                'Occupied bandwidth': self.total_bandwidth,\n",
        "                'Occupied computation': self.total_computation,\n",
        "                'cache_size': self.current_cache_size  # Add cache size\n",
        "            })\n",
        "\n",
        "        # Increment current simulation time\n",
        "        self.current_time += 0.060 \n",
        "\n",
        "        # Prepare the next state\n",
        "        next_state = state_info\n",
        "\n",
        "        return task_rewards, next_state, done\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the environment to its initial state.\n",
        "        \"\"\"\n",
        "        self.cache = []  # Clear cache\n",
        "        self.current_cache_size = 0  # Reset cache size\n",
        "        self.transmitting_tasks = []  # Clear transmitting tasks\n",
        "        self.processing_tasks = []  # Clear processing tasks\n",
        "        self.current_time = 0  # Reset current time\n",
        "        self.initialize_user_device_params()  # Reinitialize user device parameters\n",
        "        self.total_bandwidth = 0  # Reinitialize total bandwidth\n",
        "        self.total_computation = 0  # Reinitialize total computation\n",
        "        self.server_params = self.initialize_server_params()  # Reinitialize server parameters\n",
        "\n",
        "        device_state_info = {user_id: {\n",
        "            'Occupied bandwidth':  self.total_bandwidth,\n",
        "            'Occupied computation': self.total_computation,\n",
        "            'cache_size': self.current_cache_size , # Add cache size\n",
        "            'device_id' : None,\n",
        "            'task' : None\n",
        "        } for user_id in range(self.M)}\n",
        "\n",
        "        return device_state_info\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Total Bandwidth Used: {self.total_bandwidth}\")\n",
        "        print(f\"Total Computation Used: {self.total_computation}\")\n",
        "        print(f\"Current Cache Size: {self.current_cache_size}\")\n",
        "        print(f\"Number of Transmitting Tasks: {len(self.transmitting_tasks)}\")\n",
        "        print(f\"Number of Processing Tasks (Not Exist In Cache): {len(self.processing_tasks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q-Learning Algorithm\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, env, num_users, alpha=0.1, gamma=0.9, epsilon=1, max_steps_per_episode=20):\n",
        "        self.env = env  # Environment for the agent\n",
        "        self.num_users = num_users  # Number of users/devices in the environment\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor for future rewards\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.q_table = {}  # Q-table to store Q-values for state-action pairs\n",
        "        self.max_steps_per_episode = max_steps_per_episode  # Maximum steps per episode\n",
        "        self.S_max_es = env.S_max_es  # Max cache size from environment\n",
        "        self.F_max_es = env.F_max_es  # Max computation from environment\n",
        "\n",
        "    def quantize_value(self, value, value_range, num_bins):\n",
        "        \"\"\"Quantize a value to one of the specified number of bins within the value range.\"\"\"\n",
        "        bin_edges = np.linspace(value_range[0], value_range[1], num_bins + 1)\n",
        "        bin_index = np.digitize([value], bin_edges, right=True)\n",
        "        bin_index = np.clip(bin_index[0] - 1, 0, num_bins - 1)  # Ensure the bin index is within range\n",
        "        return bin_index\n",
        "\n",
        "    def quantize_state(self, state):\n",
        "        \"\"\"Quantize the state parameters.\"\"\"\n",
        "        state['cache_size'] = self.quantize_value(state['cache_size'], (0, self.S_max_es), 10)\n",
        "        state['Occupied computation'] = self.quantize_value(state['Occupied computation'], (0, (self.F_max_es * 2)), 10)\n",
        "        state['Occupied bandwidth'] = self.quantize_value(state['Occupied bandwidth'], (0, 1), 10)\n",
        "        state['task']['eta_m'] = self.quantize_value(state['task']['eta_m'], (self.env.eta_m_range[0], self.env.eta_m_range[1]), 10)\n",
        "        return state\n",
        "\n",
        "    def make_hashable(self, d):\n",
        "        # Convert a dictionary or list into a hashable type (tuple)\n",
        "        if isinstance(d, dict):\n",
        "            return tuple(sorted((k, self.make_hashable(v)) for k, v in d.items()))\n",
        "        if isinstance(d, list):\n",
        "            return tuple(self.make_hashable(e) for e in d)\n",
        "        if isinstance(d, np.ndarray):\n",
        "            return tuple(d.tolist())\n",
        "        return d\n",
        "\n",
        "    def update_epsilon(self, episode, total_episodes):\n",
        "        min_epsilon=0.06\n",
        "        k = np.log(self.epsilon / min_epsilon) / total_episodes\n",
        "        self.epsilon = min_epsilon + (self.epsilon - min_epsilon) * np.exp(-k * episode)  # Decay the exploration rate\n",
        "\n",
        "    def get_action(self, state):\n",
        "        state_copy = copy.deepcopy(state)\n",
        "        state = self.quantize_state(state_copy)  # Quantize the state\n",
        "        state_key = self.make_hashable(state)  # Convert state to a hashable key\n",
        "\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = self.initialize_q_values()  # Initialize Q-values for unseen states\n",
        "\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            action = self.generate_random_action()  # Explore: select a random action\n",
        "            action_key = tuple(action.items())\n",
        "            if action_key not in self.q_table[state_key]:\n",
        "                self.q_table[state_key][action_key] = -1  # Initialize unseen actions with a low Q-value\n",
        "        else:\n",
        "            numerical_q_values = {k: v for k, v in self.q_table[state_key].items() if isinstance(v, (int, float))}\n",
        "            if numerical_q_values:\n",
        "                action_key = max(numerical_q_values, key=numerical_q_values.get)  # Exploit: select action with highest Q-value\n",
        "                action = dict(action_key)\n",
        "            else:\n",
        "                action = self.generate_random_action()\n",
        "                action_key = tuple(action.items())\n",
        "                if action_key not in self.q_table[state_key]:\n",
        "                    self.q_table[state_key][action_key] = -1\n",
        "        return action\n",
        "\n",
        "\n",
        "    def initialize_q_values(self):\n",
        "        q_values = {}\n",
        "        random_action = self.generate_random_action()  # Generate a random action\n",
        "        q_values[tuple(random_action.items())] = -1  # Initialize its Q-value with a low value\n",
        "        return q_values\n",
        "\n",
        "    \n",
        "    def generate_random_action(self):\n",
        "        # Generate random values for the action parameters\n",
        "        alpha = np.round(np.random.choice(np.linspace(0, 1, 20)),2) \n",
        "        b = np.round(np.random.choice(np.linspace(0.01, 2/self.num_users, 10)),2) \n",
        "        p = np.round(np.random.choice(np.linspace(self.env.P_max / 10, self.env.P_max, 30))) \n",
        "        f_ue = np.round(np.random.choice(np.linspace(self.env.F_max_ue / 1000, self.env.F_max_ue, 100))) \n",
        "        f_es = np.round(np.random.choice(np.linspace(self.env.F_max_es / 1000, ((3 * self.env.F_max_es) / self.num_users), 100)))\n",
        "        # Space Actions = 60000000\n",
        "        action = {\n",
        "            'alpha_m': alpha,\n",
        "            'b_m': b,\n",
        "            'p_m': p,\n",
        "            'f_ue_m': f_ue,\n",
        "            'f_es_m': f_es\n",
        "        }\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "\n",
        "        state_copy = copy.deepcopy(state)\n",
        "        next_state_copy = copy.deepcopy(next_state)\n",
        "\n",
        "        state = self.quantize_state(state_copy)  # Quantize the state\n",
        "        next_state = self.quantize_state(next_state_copy)  # Quantize the next state\n",
        "\n",
        "        state_key = self.make_hashable(state)  # Convert state to a hashable key\n",
        "        action_key = tuple(action.items())  # Convert action to a hashable key\n",
        "\n",
        "        next_state_key = self.make_hashable(next_state)  # Convert next state to a hashable key\n",
        "\n",
        "        if isinstance(reward, list) or isinstance(reward, np.ndarray):\n",
        "            reward = reward[0]\n",
        "\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = self.initialize_q_values()  # Initialize Q-values for unseen states\n",
        "\n",
        "        if action_key not in self.q_table[state_key]:\n",
        "            self.q_table[state_key][action_key] = -1  # Initialize unseen actions with a low Q-value\n",
        "\n",
        "        if next_state_key not in self.q_table:\n",
        "            self.q_table[next_state_key] = self.initialize_q_values()  # Initialize Q-values for unseen next states\n",
        "\n",
        "        current_q = self.q_table[state_key][action_key]  # Current Q-value\n",
        "        max_next_q = max(self.q_table[next_state_key].values())  # Maximum Q-value for the next state\n",
        "\n",
        "        # Update the Q-value using the Q-learning update rule\n",
        "        self.q_table[state_key][action_key] = current_q + (self.alpha * (reward + (self.gamma * max_next_q) - current_q))\n",
        "\n",
        "    def create_task(self):\n",
        "        # Create a new task with random parameters within specified ranges\n",
        "        eta_m =  np.round(np.random.choice(np.linspace(self.env.eta_m_range[0], self.env.eta_m_range[1], 100)))\n",
        "        T_max_task = 10e-3  # Static according to article\n",
        "        task_info = {\n",
        "            'eta_m': eta_m,\n",
        "            'T_max': T_max_task,\n",
        "            'D_m': 1354  # Task data size\n",
        "        }\n",
        "        return task_info\n",
        "\n",
        "    def train(self, num_episodes):\n",
        "        # Lists to store average delay and energy values for each episode\n",
        "        avg_delays = []\n",
        "        avg_energies = []\n",
        "        avg_rewards = []\n",
        "\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            # Initialize device state information for all users at the beginning of each episode\n",
        "            device_state_info = self.env.reset()\n",
        "\n",
        "            # Initialize total delay and energy for this episode\n",
        "            total_delay = 0\n",
        "            total_energy = 0\n",
        "            total_reward = 0\n",
        "\n",
        "            # Initialize the number of tasks in this episode\n",
        "            num_all_tasks = 0\n",
        "            actual_steps = 0\n",
        "\n",
        "            for step in range(self.max_steps_per_episode):\n",
        "                # Initialize lists for actions, tasks, and user IDs\n",
        "                actions = []\n",
        "                tasks = []\n",
        "                users_id = []\n",
        "\n",
        "                # Generate a random number of tasks and assign them to devices\n",
        "                num_tasks = np.random.randint(self.num_users / 2, self.num_users + 1)\n",
        "                num_all_tasks += num_tasks\n",
        "                \n",
        "                # Randomly distribute tasks to users\n",
        "                task_distribution = np.random.choice(range(self.num_users), num_tasks, replace=True)\n",
        "\n",
        "                # Initialize a list to store state representations for action selection\n",
        "                states_choose_actions = []\n",
        "\n",
        "                for user_id in task_distribution:\n",
        "                    # Create a new task\n",
        "                    task = self.create_task()\n",
        "                    # Append the task to the tasks list\n",
        "                    tasks.append(task)\n",
        "                    # Append the user ID to the users_id list\n",
        "                    users_id.append(user_id)\n",
        "\n",
        "                    # Update device state information with the new task\n",
        "                    device_state_info[user_id]['task'] = task\n",
        "                    device_state_info[user_id]['device_id'] = user_id\n",
        "\n",
        "                    # Create the state representation for action selection\n",
        "                    state_choose_actions = {\n",
        "                        'cache_size': device_state_info[user_id]['cache_size'],\n",
        "                        'device_id': user_id,\n",
        "                        'task': device_state_info[user_id]['task'],\n",
        "                        'Occupied bandwidth': device_state_info[user_id]['Occupied bandwidth'],\n",
        "                        'Occupied computation': device_state_info[user_id]['Occupied computation']\n",
        "                    }\n",
        "\n",
        "\n",
        "                    # Append the state representation to the list\n",
        "                    states_choose_actions.append(state_choose_actions)\n",
        "\n",
        "                # Select actions for each device with a task using the Q-table\n",
        "                actions = [self.get_action(state) for state in states_choose_actions]\n",
        "\n",
        "                # Execute the actions in the environment\n",
        "                rewards, next_state_info, done = self.env.step(actions, tasks, users_id)\n",
        "\n",
        "                # List of state representations used for action selection\n",
        "                state_info_list = states_choose_actions\n",
        "\n",
        "                counter_Users = 0\n",
        "                # Update Q-table and device state information for each device\n",
        "                for user_id in task_distribution:\n",
        "                    # Get the current device information\n",
        "                    device_info = state_info_list[counter_Users]\n",
        "                    # Get the next device information\n",
        "                    next_device_info = next_state_info[counter_Users]\n",
        "                    # Get the action taken by the user\n",
        "                    action = actions[counter_Users]\n",
        "                    # Get the reward received by the user\n",
        "                    reward = rewards[counter_Users]\n",
        "\n",
        "                    # Extract delay and energy values from the next device information\n",
        "                    delay = next_device_info.pop('delay', 0)\n",
        "                    energy = next_device_info.pop('energy', 0)\n",
        "\n",
        "                    # Update the Q-table with the new state-action pair\n",
        "                    self.update_q_table(device_info, action, reward, next_device_info)\n",
        "                    \n",
        "                    # Accumulate the total delay and energy for the episode\n",
        "                    total_delay += delay\n",
        "                    total_energy += energy\n",
        "                    total_reward += reward\n",
        "\n",
        "                    # Update device state information with the combined next state\n",
        "                    device_state_info[user_id].update(next_device_info)\n",
        "                    # Increment the counter for the number of users\n",
        "                    counter_Users += 1\n",
        "                    \n",
        "                actual_steps += 1\n",
        "\n",
        "                if done:\n",
        "                    # Exit the loop if the episode is done\n",
        "                    break\n",
        "\n",
        "            # Calculate and store average delay and energy for the episode\n",
        "            avg_delay = total_delay / num_all_tasks * 1000  # Convert to milliseconds\n",
        "            avg_energy = total_energy / num_all_tasks\n",
        "            avg_reward = total_reward / num_all_tasks\n",
        "            avg_delays.append(avg_delay)\n",
        "            avg_energies.append(avg_energy)\n",
        "            avg_rewards.append(avg_reward)\n",
        "\n",
        "            # Update epsilon for the epsilon-greedy strategy\n",
        "            self.update_epsilon(episode, num_episodes)\n",
        "\n",
        "            # Print the episode's results\n",
        "            print(f\"Train : Episode {episode + 1}/{num_episodes} - Steps Count {actual_steps} - Avg Delay: {avg_delay}, Avg Energy: {avg_energy}, Avg Reward: {avg_reward}\")\n",
        "            print(\"-\" * 100)\n",
        "\n",
        "\n",
        "        # Optionally plot the results\n",
        "        #self.plot_results(avg_delays, avg_energies, avg_rewards)\n",
        "\n",
        "    def test(self, num_test_steps):\n",
        "\n",
        "        # Initialize total delay and alpha values for this test\n",
        "        total_delay = 0\n",
        "        total_alpha = 0\n",
        "        total_reward = 0\n",
        "        # Counter for number of all tasks\n",
        "        num_all_tasks = 0\n",
        "        actual_steps = 0\n",
        "\n",
        "        # Set epsilon to 0 for testing (no exploration)\n",
        "        self.epsilon = 0\n",
        "\n",
        "        # Initialize device state information for all users\n",
        "        device_state_info =  self.env.reset()\n",
        "\n",
        "        for step in range(num_test_steps):\n",
        "            # Initialize lists for actions, tasks, and user IDs\n",
        "            actions = []\n",
        "            tasks = []\n",
        "            users_id = []\n",
        "\n",
        "            # Generate a random number of tasks and assign them to devices\n",
        "            num_tasks = np.random.randint(self.num_users / 2, self.num_users + 1)\n",
        "            num_all_tasks += num_tasks\n",
        "\n",
        "            # Randomly distribute tasks to users\n",
        "            task_distribution = np.random.choice(range(self.num_users), num_tasks, replace=True)\n",
        "\n",
        "            # Initialize a list to store state representations for action selection\n",
        "            states_choose_actions = []\n",
        "\n",
        "            for user_id in task_distribution:\n",
        "                # Create a new task\n",
        "                task = self.create_task()\n",
        "                # Append the task to the tasks list\n",
        "                tasks.append(task)\n",
        "                # Append the user ID to the users_id list\n",
        "                users_id.append(user_id)\n",
        "\n",
        "                # Update device state information with the new task\n",
        "                device_state_info[user_id]['task'] = task\n",
        "                device_state_info[user_id]['device_id'] = user_id\n",
        "\n",
        "                # Create the state representation for action selection\n",
        "                state_choose_actions = {\n",
        "                    'cache_size': device_state_info[user_id]['cache_size'],\n",
        "                    'device_id': user_id,\n",
        "                    'task': device_state_info[user_id]['task'],\n",
        "                    'Occupied bandwidth': device_state_info[user_id]['Occupied bandwidth'],\n",
        "                    'Occupied computation': device_state_info[user_id]['Occupied computation']\n",
        "                }\n",
        "\n",
        "\n",
        "                # Append the state representation to the list\n",
        "                states_choose_actions.append(state_choose_actions)\n",
        "\n",
        "            # Select actions for each device with a task using the Q-table\n",
        "            actions = [self.get_action(state) for state in states_choose_actions]\n",
        "\n",
        "            # Execute the actions in the environment\n",
        "            rewards, next_state_info, done = self.env.step(actions, tasks, users_id)\n",
        "\n",
        "            total_reward = sum(rewards)\n",
        "\n",
        "            counter_Users = 0\n",
        "\n",
        "            for user_id in task_distribution:\n",
        "                # Get the next device information\n",
        "                next_device_info = next_state_info[counter_Users]\n",
        "                # Extract delay and energy values from the next device information\n",
        "                delay = next_device_info.pop('delay', 0)\n",
        "                next_device_info.pop('energy', 0)\n",
        "\n",
        "                # Accumulate the total delay and alpha values for the test\n",
        "                total_delay += delay\n",
        "                total_alpha += actions[counter_Users]['alpha_m']\n",
        "\n",
        "                # Update device state information with the combined next state\n",
        "                device_state_info[user_id].update(next_device_info)\n",
        "                counter_Users += 1\n",
        "\n",
        "            # Increment the counter for actual iterations\n",
        "            actual_steps += 1\n",
        "\n",
        "            if done:\n",
        "                # Exit the loop if the test is done\n",
        "                break\n",
        "\n",
        "        # Calculate and return the average delay and alpha for the test\n",
        "        avg_delay = (total_delay / num_all_tasks) * 1000  # Convert to milliseconds\n",
        "        avg_alpha = total_alpha / num_all_tasks\n",
        "        avg_reward = total_reward / num_all_tasks\n",
        "\n",
        "\n",
        "        # Print the episode's results\n",
        "        print(f\"Test : Steps Count {actual_steps} - Avg Delay: {avg_delay}, Avg Alpha: {avg_alpha}, Avg Reward: {avg_reward}\")\n",
        "        print(\"-\" * 100)\n",
        "        \n",
        "        return avg_delay, avg_alpha\n",
        "\n",
        "    def plot_results(self, avg_delays, avg_energies, avg_rewards):\n",
        "        episodes = np.arange(1, len(avg_delays) + 1)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(episodes, avg_delays, label='Avg Delay')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Average Delay')\n",
        "        plt.title('Average Delay per Episode')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(episodes, avg_energies, label='Avg Energy')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Average Energy')\n",
        "        plt.title('Average Energy per Episode')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(episodes, avg_rewards, label='Avg Reward')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Average Reward')\n",
        "        plt.title('Average Reward per Episode')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def save_q_table(self, filename):\n",
        "        def convert_keys_to_str(d):\n",
        "            if isinstance(d, dict):\n",
        "                return {str(k): convert_keys_to_str(v) for k, v in d.items()}\n",
        "            elif isinstance(d, np.ndarray):\n",
        "                return d.tolist()\n",
        "            else:\n",
        "                return d\n",
        "\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(convert_keys_to_str(self.q_table), f)\n",
        "\n",
        "    def load_q_table(self, filename):\n",
        "        def convert_keys_to_tuple(d):\n",
        "            if isinstance(d, dict):\n",
        "                return {eval(k): convert_keys_to_tuple(v) for k, v in d.items()}\n",
        "            else:\n",
        "                return d\n",
        "\n",
        "        with open(filename, 'r') as f:\n",
        "            self.q_table = convert_keys_to_tuple(json.load(f))\n",
        "\n",
        "# Assuming you have your EdgeComputingEnvironment defined as per your code\n",
        "#env = EdgeComputingEnvironment()\n",
        "\n",
        "# Define the number of users/devices\n",
        "#num_users = env.M\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "#agent = QLearningAgent(env, num_users)\n",
        "\n",
        "# Train the agent\n",
        "#num_episodes = 5  # Adjust the number of episodes as needed\n",
        "#agent.train(num_episodes)\n",
        "\n",
        "# Show the Q-table\n",
        "#agent.save_q_table('Q_table.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[26574799.42437796]\n",
            "[37848750.39140202]\n",
            "[32343970.22020715]\n",
            "[22980465.22738296]\n",
            "[25315066.64835401]\n",
            "[17504191.77596872]\n",
            "[14521153.26697739]\n",
            "[11386597.17056477]\n",
            "[2804822.34374014]\n",
            "[11221736.17059497]\n",
            "[5706312.38003419]\n",
            "[25334336.92915022]\n",
            "[36074522.76710299]\n",
            "[37812108.95400804]\n",
            "[34701005.4874596]\n",
            "[31620840.06118387]\n",
            "[25861605.1523819]\n",
            "[32090717.05251335]\n",
            "[33279192.54172947]\n",
            "[26283172.93470039]\n",
            "[11699083.91316881]\n",
            "[17655510.5977482]\n",
            "[33674885.60827759]\n",
            "[14280183.47701686]\n",
            "[11252112.10217047]\n",
            "[14597916.97157885]\n",
            "[31313169.95350116]\n",
            "[37778272.54885509]\n",
            "[5850179.7197879]\n",
            "[5761131.06467284]\n",
            "[5832780.6332666]\n",
            "[25662022.41853548]\n",
            "Train : Episode 1/100 - Steps Count 3 - Avg Delay: [1.15817203], Avg Energy: [0.05028876], Avg Reward: [-0.34832193]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17063306.10921269]\n",
            "[33943804.7209083]\n",
            "[25982266.94607214]\n",
            "[37200167.87253886]\n",
            "[33648692.86311049]\n",
            "[23292152.48267613]\n",
            "[34488297.18594754]\n",
            "[35251281.97755257]\n",
            "[35046126.93959493]\n",
            "[5642657.45967246]\n",
            "[26567322.34726613]\n",
            "Train : Episode 2/100 - Steps Count 1 - Avg Delay: [1.13445728], Avg Energy: [0.03614412], Avg Reward: [-0.37818767]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34854356.17907484]\n",
            "[17532185.46528647]\n",
            "[11489374.01031773]\n",
            "[34646599.35141378]\n",
            "[14431673.62542464]\n",
            "[16531965.66543013]\n",
            "[36430389.83404962]\n",
            "[34646599.35141378]\n",
            "[5780813.52921966]\n",
            "[38217261.2560164]\n",
            "[11460554.89758033]\n",
            "[23000597.89760301]\n",
            "[5687624.56656184]\n",
            "[22415433.53481824]\n",
            "[22702682.64962032]\n",
            "[2770899.42814936]\n",
            "[34661903.17859264]\n",
            "[22259957.12761804]\n",
            "[14591374.45590355]\n",
            "[2780551.00238162]\n",
            "[5756767.73032286]\n",
            "[26090439.12576047]\n",
            "[2846502.33635746]\n",
            "Train : Episode 3/100 - Steps Count 2 - Avg Delay: [1.90318745], Avg Energy: [0.03792871], Avg Reward: [-0.3224406]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35123033.73971204]\n",
            "[32165767.20379479]\n",
            "[11252112.10217047]\n",
            "[32273151.89032693]\n",
            "[17446791.21619075]\n",
            "[14737038.61329479]\n",
            "[37259552.22174835]\n",
            "[17741753.7815203]\n",
            "[34261253.56237753]\n",
            "[2798706.4384385]\n",
            "[31720285.90138654]\n",
            "[34574890.25488228]\n",
            "[34137319.68551484]\n",
            "[11593870.15083529]\n",
            "[34976840.60914297]\n",
            "[31868878.75867447]\n",
            "[5793863.27608868]\n",
            "[37465986.72707561]\n",
            "[34581446.17411707]\n",
            "[26480439.43609966]\n",
            "[23056420.95966795]\n",
            "[25061151.55594452]\n",
            "[11066278.56683374]\n",
            "[11312909.23811608]\n",
            "[16651149.04730407]\n",
            "Train : Episode 4/100 - Steps Count 3 - Avg Delay: [5.27611378], Avg Energy: [0.03535097], Avg Reward: [-0.32062709]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22882266.5017997]\n",
            "[2882660.35241701]\n",
            "[17669179.37096233]\n",
            "[5676175.96355681]\n",
            "[26261472.23116552]\n",
            "[2787336.74578412]\n",
            "[5644588.47726692]\n",
            "[34950026.44309427]\n",
            "[16593400.56020298]\n",
            "[32345411.63045254]\n",
            "[34706480.19401085]\n",
            "[11657767.21577616]\n",
            "[2865074.21223803]\n",
            "[37730386.27881299]\n",
            "Train : Episode 5/100 - Steps Count 1 - Avg Delay: [8.41875365], Avg Energy: [0.12412343], Avg Reward: [-0.54325647]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[11780883.34012542]\n",
            "[14724879.91948207]\n",
            "[32089534.32276857]\n",
            "[17699814.78494262]\n",
            "[33823966.9946847]\n",
            "[14638472.37650424]\n",
            "[25933140.26689425]\n",
            "[17385902.08795409]\n",
            "[35542073.74453196]\n",
            "[5844734.94138567]\n",
            "[5629893.67374407]\n",
            "[23420923.72063107]\n",
            "[5706312.38003419]\n",
            "[2871207.33546653]\n",
            "[11774477.80485787]\n",
            "[11327071.05931666]\n",
            "Train : Episode 6/100 - Steps Count 2 - Avg Delay: [1.43661324], Avg Energy: [0.11147732], Avg Reward: [-0.36291393]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[38208021.40237062]\n",
            "[23222556.13659091]\n",
            "[5687624.56656184]\n",
            "[5750878.36141751]\n",
            "[14487206.84233879]\n",
            "[16741017.13186174]\n",
            "[38175054.12120932]\n",
            "[23202528.20564891]\n",
            "[26261472.23116552]\n",
            "[37304545.43385452]\n",
            "[2758585.43140971]\n",
            "[26187004.9226388]\n",
            "[37688179.14400591]\n",
            "[25690377.3152509]\n",
            "[11686803.80423598]\n",
            "[26045379.7827893]\n",
            "[37417257.39953274]\n",
            "[37187951.84150085]\n",
            "[14076530.85563372]\n",
            "[25847039.4272273]\n",
            "[2848677.0061836]\n",
            "[23505879.76592173]\n",
            "[11454961.86116047]\n",
            "[14018589.56285975]\n",
            "[5608202.33493837]\n",
            "[23542924.22599568]\n",
            "[5808202.33493837]\n",
            "[38013948.72626778]\n",
            "[25307589.57124217]\n",
            "[2782589.78190077]\n",
            "[37290065.79361222]\n",
            "[30892294.56359821]\n",
            "[2827704.491887]\n",
            "[11772152.42506972]\n",
            "[22904390.50335282]\n",
            "[23216551.16594313]\n",
            "[2757298.0397184]\n",
            "[23563903.71715401]\n",
            "[31596173.84471251]\n",
            "[25163186.4129853]\n",
            "Train : Episode 7/100 - Steps Count 4 - Avg Delay: [2.03571841], Avg Energy: [0.05457223], Avg Reward: [-0.36910795]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[13921872.52263781]\n",
            "[37102710.53811362]\n",
            "[34502713.71465165]\n",
            "[14428224.35831604]\n",
            "[24936935.97687987]\n",
            "[22922802.04220884]\n",
            "[14226559.25224595]\n",
            "[24900703.84036184]\n",
            "[2833506.12909399]\n",
            "[36304040.54945454]\n",
            "[17342097.58087246]\n",
            "[23546022.05688695]\n",
            "[23473726.56994763]\n",
            "[5608202.33493837]\n",
            "[11584600.03229857]\n",
            "Train : Episode 8/100 - Steps Count 1 - Avg Delay: [1.20945382], Avg Energy: [0.06464272], Avg Reward: [-0.31585218]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[11793299.14188276]\n",
            "[2665877.97473288]\n",
            "[2880228.61365446]\n",
            "[38036174.96273796]\n",
            "[33873769.3609361]\n",
            "[5794793.19474555]\n",
            "[14421833.78208244]\n",
            "[5511146.47596452]\n",
            "[17329271.7453731]\n",
            "[17598609.71808302]\n",
            "[2729853.17218764]\n",
            "[23292255.12495328]\n",
            "Train : Episode 9/100 - Steps Count 1 - Avg Delay: [1.871499], Avg Energy: [0.08170331], Avg Reward: [-0.39607481]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[11734828.14598196]\n",
            "[17561899.97627941]\n",
            "[16769389.6788867]\n",
            "[38053071.95052882]\n",
            "[25786991.15054536]\n",
            "[5770392.17969133]\n",
            "[31098114.48020989]\n",
            "[17598609.71808302]\n",
            "[37837950.16890715]\n",
            "[17690174.15497406]\n",
            "[26182523.91349731]\n",
            "[31829106.68319524]\n",
            "[34188566.5552081]\n",
            "[25454279.41954689]\n",
            "[22648751.3771502]\n",
            "[2825545.65829375]\n",
            "[31754516.82126588]\n",
            "[34693573.05495118]\n",
            "[14235040.4156064]\n",
            "[23078019.7894775]\n",
            "[5819750.05668037]\n",
            "[25029204.57184953]\n",
            "[17358419.64159417]\n",
            "Train : Episode 10/100 - Steps Count 2 - Avg Delay: [1.05984242], Avg Energy: [0.04341875], Avg Reward: [-0.37056555]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[11388403.32696347]\n",
            "[16735856.59222415]\n",
            "[34650913.50389992]\n",
            "[32163955.14335004]\n",
            "[14272465.8452502]\n",
            "[24936935.97687987]\n",
            "[23646721.49995521]\n",
            "[2837254.54481181]\n",
            "[33279192.54172947]\n",
            "[33237599.04058475]\n",
            "[5686196.07413953]\n",
            "[31437139.55123051]\n",
            "[14481835.27537127]\n",
            "[34639150.02650416]\n",
            "[25434481.38071117]\n",
            "[26289945.41309165]\n",
            "[35126563.34656636]\n",
            "[37907018.71935158]\n",
            "[26470822.69656669]\n",
            "[2812263.49455599]\n",
            "[22363381.24472118]\n",
            "[31299852.780574]\n",
            "[14689507.5556993]\n",
            "[32007654.70021261]\n",
            "[22547600.28940337]\n",
            "[5761680.00929367]\n",
            "[5848780.22168646]\n",
            "Train : Episode 11/100 - Steps Count 2 - Avg Delay: [4.3221534], Avg Energy: [0.05217505], Avg Reward: [-0.3990898]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26503214.44784123]\n",
            "[2802075.95480968]\n",
            "[26398704.78074069]\n",
            "[22914615.42532658]\n",
            "[32247659.06435096]\n",
            "[37302561.64371715]\n",
            "[16531965.66543013]\n",
            "[23473726.56994763]\n",
            "[5770392.17969133]\n",
            "[2812708.78651149]\n",
            "[11414817.0192753]\n",
            "[32314023.93899484]\n",
            "[2848375.01785388]\n",
            "[5796738.36234439]\n",
            "Train : Episode 12/100 - Steps Count 1 - Avg Delay: [2.01906503], Avg Energy: [0.08727277], Avg Reward: [-0.42857755]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17699814.78494262]\n",
            "[14642866.99726397]\n",
            "[23005112.41646588]\n",
            "[36944836.95078126]\n",
            "[11634792.34700521]\n",
            "[11540343.09621799]\n",
            "[33279192.54172947]\n",
            "[14403631.34286353]\n",
            "[2861384.57040405]\n",
            "[34272403.638897]\n",
            "[35349807.69653126]\n",
            "[14799535.18541547]\n",
            "[14602071.04594252]\n",
            "[37093918.51265074]\n",
            "[16987943.70654025]\n",
            "[34026664.94283239]\n",
            "[23420923.72063107]\n",
            "[14076530.85563372]\n",
            "[11366688.00179099]\n",
            "[13894725.36543085]\n",
            "[11286313.75195133]\n",
            "[17020228.14805055]\n",
            "[31057052.7186206]\n",
            "[36304040.54945454]\n",
            "[31675379.51119284]\n",
            "[24936935.97687987]\n",
            "[5503929.83308738]\n",
            "[14657270.92626803]\n",
            "Train : Episode 13/100 - Steps Count 2 - Avg Delay: [1.16826348], Avg Energy: [0.02094339], Avg Reward: [-0.32568308]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[33943804.7209083]\n",
            "[31170012.1558245]\n",
            "[34502713.71465165]\n",
            "[2847846.3484989]\n",
            "[17669179.37096233]\n",
            "[17329271.7453731]\n",
            "[5770392.17969133]\n",
            "[5707691.69220864]\n",
            "[26365867.79250467]\n",
            "[31437139.55123051]\n",
            "[24766605.74641569]\n",
            "[17669179.37096233]\n",
            "[37177088.49476156]\n",
            "[5848780.22168646]\n",
            "[17234651.61732796]\n",
            "[32343970.22020715]\n",
            "[11761490.994148]\n",
            "[35349807.69653126]\n",
            "[36309472.29891665]\n",
            "[37700269.46924694]\n",
            "[14698056.10818783]\n",
            "[14016500.42845125]\n",
            "[2878518.90315676]\n",
            "[31797490.40963772]\n",
            "[31839342.92795276]\n",
            "[11657002.01738397]\n",
            "[14651153.40546064]\n",
            "[17262534.26133412]\n",
            "[11642070.90592349]\n",
            "[14298645.6258367]\n",
            "[22027265.09229972]\n",
            "[26224240.87933321]\n",
            "[23001961.36842202]\n",
            "[11657900.95529877]\n",
            "[31795781.73434934]\n",
            "[5818012.57086846]\n",
            "[34026664.94283239]\n",
            "[25315066.64835401]\n",
            "[2811364.89047437]\n",
            "[23589457.50841808]\n",
            "[5726956.20000288]\n",
            "[31752551.50081792]\n",
            "[22146463.39802964]\n",
            "[5464358.49088281]\n",
            "[11255828.79434363]\n",
            "[25236770.75900814]\n",
            "[14659776.67648282]\n",
            "[31731875.29902563]\n",
            "[11796622.2872658]\n",
            "[11470385.70542257]\n",
            "[2778049.91468234]\n",
            "[14570463.73433464]\n",
            "[11717803.25476199]\n",
            "Train : Episode 14/100 - Steps Count 5 - Avg Delay: [2.94140085], Avg Energy: [0.05298243], Avg Reward: [-0.32950873]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30378229.82719098]\n",
            "[35349807.69653126]\n",
            "[37700269.46924694]\n",
            "[26319084.30880911]\n",
            "[32511173.6229967]\n",
            "[32051677.74912093]\n",
            "[31868878.75867447]\n",
            "[33237599.04058475]\n",
            "[37200167.87253886]\n",
            "[34646599.35141378]\n",
            "[17436867.31390178]\n",
            "[11774477.80485787]\n",
            "[36642059.04011621]\n",
            "[37321127.9754575]\n",
            "[33440528.83275421]\n",
            "[16769389.6788867]\n",
            "[30221258.60681675]\n",
            "[22260686.27046314]\n",
            "[32247659.06435096]\n",
            "[14470011.31965134]\n",
            "[11781617.40438339]\n",
            "[14215341.1320262]\n",
            "[17160789.48009614]\n",
            "[22260686.27046314]\n",
            "[14315132.64083159]\n",
            "[35028608.65673333]\n",
            "[17620501.0435737]\n",
            "[2847846.3484989]\n",
            "[31313169.95350116]\n",
            "[38310315.24226423]\n",
            "[17699814.78494262]\n",
            "[17621367.11263501]\n",
            "[11689813.79463209]\n",
            "[38258921.28852317]\n",
            "[31731875.29902563]\n",
            "[22412090.91976463]\n",
            "[5690514.55872996]\n",
            "[5464358.49088281]\n",
            "[17290479.35713657]\n",
            "[31588448.53220441]\n",
            "[2716513.62894976]\n",
            "[14272465.8452502]\n",
            "[33713846.0404072]\n",
            "[36419896.95513665]\n",
            "[17732912.75459065]\n",
            "[2848706.4384385]\n",
            "[34052148.06829339]\n",
            "[37688179.14400591]\n",
            "[11473816.99352611]\n",
            "[23148786.30813593]\n",
            "[30613492.64818003]\n",
            "[5594435.477381]\n",
            "[5844734.94138567]\n",
            "[2738294.23267901]\n",
            "[2847898.00491131]\n",
            "Train : Episode 15/100 - Steps Count 6 - Avg Delay: [1.75482207], Avg Energy: [0.04585035], Avg Reward: [-0.28851427]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32058151.14794896]\n",
            "[26362767.92763823]\n",
            "[14638472.37650424]\n",
            "[14257484.14092473]\n",
            "[38083653.52285169]\n",
            "[25315066.64835401]\n",
            "[25847039.4272273]\n",
            "[32247659.06435096]\n",
            "[14272465.8452502]\n",
            "[26348039.13649368]\n",
            "[14657270.92626803]\n",
            "[17329271.7453731]\n",
            "[23193671.13491063]\n",
            "[2810478.84068923]\n",
            "[14278538.13190967]\n",
            "[35375508.65175438]\n",
            "[14708625.59872242]\n",
            "[5750878.36141751]\n",
            "[16707500.90431293]\n",
            "[23070849.20754829]\n",
            "[22716700.24743054]\n",
            "[37351076.86429744]\n",
            "[5770392.17969133]\n",
            "[5762137.88136317]\n",
            "[26218939.85724816]\n",
            "Train : Episode 16/100 - Steps Count 2 - Avg Delay: [1.73527966], Avg Energy: [0.06778253], Avg Reward: [-0.33951781]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[2781046.25554743]\n",
            "[32304355.77332344]\n",
            "[5750878.36141751]\n",
            "[23473726.56994763]\n",
            "[16531965.66543013]\n",
            "[17621367.11263501]\n",
            "[25774112.89472518]\n",
            "[31849110.68578724]\n",
            "[32004823.61178265]\n",
            "[32185745.72291903]\n",
            "[22716700.24743054]\n",
            "[31241015.59553809]\n",
            "[14257484.14092473]\n",
            "[11327071.05931666]\n",
            "[33713846.0404072]\n",
            "[23646721.49995521]\n",
            "[32237438.16087478]\n",
            "[25953636.34165993]\n",
            "[11554298.9574503]\n",
            "[31313169.95350116]\n",
            "[37309907.61640116]\n",
            "[37290065.79361222]\n",
            "Train : Episode 17/100 - Steps Count 2 - Avg Delay: [1.6450451], Avg Energy: [0.03393498], Avg Reward: [-0.37648911]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14024980.13909335]\n",
            "[14016500.42845125]\n",
            "[32163955.14335004]\n",
            "[31299852.780574]\n",
            "[26416524.16276715]\n",
            "[5673809.97735141]\n",
            "[34112470.78122822]\n",
            "[36944836.95078126]\n",
            "[2825545.65829375]\n",
            "[26365867.79250467]\n",
            "[11766688.00179099]\n",
            "[2738294.23267901]\n",
            "[17632380.63159134]\n",
            "[11604122.19162386]\n",
            "[25129349.02341048]\n",
            "[26496503.53503208]\n",
            "[37700269.46924694]\n",
            "[14015834.49251713]\n",
            "[37133986.68293777]\n",
            "Train : Episode 18/100 - Steps Count 2 - Avg Delay: [10.73862098], Avg Energy: [0.04852189], Avg Reward: [-0.3355763]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[5770392.17969133]\n",
            "[14689204.81347981]\n",
            "[5546725.95629666]\n",
            "[11450931.46840366]\n",
            "[14657270.92626803]\n",
            "[17669179.37096233]\n",
            "[11558513.28386452]\n",
            "[2817971.8190316]\n",
            "[26362767.92763823]\n",
            "[11506358.09592953]\n",
            "[26416524.16276715]\n",
            "[14493174.1080605]\n",
            "[32379106.68319525]\n",
            "[25129349.02341048]\n",
            "[2878518.90315676]\n",
            "Train : Episode 19/100 - Steps Count 1 - Avg Delay: [2.13841451], Avg Energy: [0.09441042], Avg Reward: [-0.4132155]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17003880.6955012]\n",
            "[25933317.38626134]\n",
            "[26362767.92763823]\n",
            "[5843916.74416137]\n",
            "[22648751.3771502]\n",
            "[17532185.46528647]\n",
            "[5484680.33738702]\n",
            "[11697875.84026965]\n",
            "[5690514.55872996]\n",
            "[5707691.69220864]\n",
            "[31839342.92795276]\n",
            "Train : Episode 20/100 - Steps Count 1 - Avg Delay: [1.35597726], Avg Energy: [0.06986725], Avg Reward: [-0.36667777]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32247659.06435096]\n",
            "[17234651.61732796]\n",
            "[34672450.268416]\n",
            "[32511173.6229967]\n",
            "[2847846.3484989]\n",
            "[5591886.05966529]\n",
            "[36944836.95078126]\n",
            "[34706480.19401085]\n",
            "[34854356.17907484]\n",
            "[26561308.17124327]\n",
            "[2822136.43643962]\n",
            "[11619864.58682666]\n",
            "[11384488.00150703]\n",
            "[26348039.13649368]\n",
            "[37393298.32851019]\n",
            "[2843858.35194414]\n",
            "[25707396.15760753]\n",
            "[2781429.92653357]\n",
            "[37313742.81293193]\n",
            "[37259552.22174835]\n",
            "[11384488.00150703]\n",
            "[14716526.46571698]\n",
            "Train : Episode 21/100 - Steps Count 2 - Avg Delay: [1.77520702], Avg Energy: [0.05103004], Avg Reward: [-0.31416889]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14521153.26697739]\n",
            "[13892954.24898995]\n",
            "[36074522.76710299]\n",
            "[26348039.13649368]\n",
            "[11662513.39465112]\n",
            "[23478019.7894775]\n",
            "[37876904.27274705]\n",
            "[2871529.07039381]\n",
            "[34672450.268416]\n",
            "[31620840.06118387]\n",
            "[23251399.84753379]\n",
            "[22922802.04220884]\n",
            "[25079478.91317276]\n",
            "[34039129.83311161]\n",
            "[26349521.73140302]\n",
            "[38065285.09427478]\n",
            "[26502801.27648859]\n",
            "[14610766.75970551]\n",
            "Train : Episode 22/100 - Steps Count 2 - Avg Delay: [1.21504243], Avg Energy: [0.04661566], Avg Reward: [-0.35338626]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[2758585.43140971]\n",
            "[37970043.84377819]\n",
            "[17699814.78494262]\n",
            "[2880228.61365446]\n",
            "[31731875.29902563]\n",
            "[34188566.5552081]\n",
            "[5749158.18153831]\n",
            "[11558513.28386452]\n",
            "[5690514.55872996]\n",
            "[31731875.29902563]\n",
            "[5546725.95629666]\n",
            "[32130184.84378477]\n",
            "[32090717.05251335]\n",
            "[2797010.70644203]\n",
            "Train : Episode 23/100 - Steps Count 1 - Avg Delay: [2.25570211], Avg Energy: [0.1046847], Avg Reward: [-0.42836897]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14134004.91779502]\n",
            "[2820064.43373502]\n",
            "[11414817.0192753]\n",
            "[37194120.77763453]\n",
            "[32343392.9537431]\n",
            "[26182523.91349731]\n",
            "[14430778.50007049]\n",
            "[33648692.86311049]\n",
            "[38154236.13158979]\n",
            "[33151005.97165]\n",
            "[31459055.52726715]\n",
            "[25061151.55594452]\n",
            "[37907018.71935158]\n",
            "[37452351.4383614]\n",
            "[17202233.24772744]\n",
            "[2758585.43140971]\n",
            "[26426335.02583956]\n",
            "[33237599.04058475]\n",
            "[38279733.66994136]\n",
            "[36788331.36003278]\n",
            "[26261472.23116552]\n",
            "[14799535.18541547]\n",
            "[30724513.89434461]\n",
            "[26338404.54747577]\n",
            "[2804822.34374014]\n",
            "[32058151.14794896]\n",
            "Train : Episode 24/100 - Steps Count 3 - Avg Delay: [1.25169346], Avg Energy: [0.03989044], Avg Reward: [-0.32960367]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36940902.34998875]\n",
            "[11460554.89758033]\n",
            "[2748968.51480219]\n",
            "[31437139.55123051]\n",
            "[26348039.13649368]\n",
            "[14642866.99726397]\n",
            "[14430778.50007049]\n",
            "[14000266.91506391]\n",
            "[32130184.84378477]\n",
            "[23488902.32336152]\n",
            "[37700269.46924694]\n",
            "[11496681.72107886]\n",
            "[26261472.23116552]\n",
            "[11766688.00179099]\n",
            "[25441910.16093062]\n",
            "Train : Episode 25/100 - Steps Count 1 - Avg Delay: [1.69660881], Avg Energy: [0.0349585], Avg Reward: [-0.38665511]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31437139.55123051]\n",
            "[2837254.54481181]\n",
            "[37907018.71935158]\n",
            "[23324132.35781662]\n",
            "[2665877.97473288]\n",
            "[34502713.71465165]\n",
            "[32090717.05251335]\n",
            "[37302561.64371715]\n",
            "[34646599.35141378]\n",
            "[34488297.18594754]\n",
            "[32036285.50457279]\n",
            "[17063306.10921269]\n",
            "[23340133.01487448]\n",
            "[5560298.5733754]\n",
            "[22547600.28940337]\n",
            "[31715473.47136634]\n",
            "[22547600.28940337]\n",
            "[26055945.1638218]\n",
            "[2845858.43407637]\n",
            "[11205186.85650856]\n",
            "[33943804.7209083]\n",
            "[34474280.34688262]\n",
            "[11441521.34911098]\n",
            "[30409049.04912506]\n",
            "[22574344.71065016]\n",
            "[5546725.95629666]\n",
            "[2831904.53560065]\n",
            "[22146463.39802964]\n",
            "[17663306.10921269]\n",
            "[17621367.11263501]\n",
            "[14153724.76610502]\n",
            "[25340479.80593681]\n",
            "[13696624.44117743]\n",
            "[14783749.92031063]\n",
            "[11610736.90816268]\n",
            "[14737038.61329479]\n",
            "[5830608.91956315]\n",
            "[5867464.7444928]\n",
            "[34978960.7144741]\n",
            "[23634548.36159952]\n",
            "[14590941.60442753]\n",
            "[26190653.41893147]\n",
            "[14091390.49891597]\n",
            "[2857629.49764201]\n",
            "[14356397.12239896]\n",
            "[36899494.078433]\n",
            "[37548042.8688339]\n",
            "[26538178.55261528]\n",
            "Train : Episode 26/100 - Steps Count 5 - Avg Delay: [1.79842705], Avg Energy: [0.04818368], Avg Reward: [-0.32081544]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17234651.61732796]\n",
            "[36642059.04011621]\n",
            "[17699814.78494262]\n",
            "[2847846.3484989]\n",
            "[38036174.96273796]\n",
            "[5673809.97735141]\n",
            "[25315066.64835401]\n",
            "[5502209.65320819]\n",
            "[32247659.06435096]\n",
            "[14638472.37650424]\n",
            "[14392964.47772745]\n",
            "[31952197.77035223]\n",
            "[22914615.42532658]\n",
            "[22716700.24743054]\n",
            "[32165767.20379479]\n",
            "[38279733.66994136]\n",
            "[25061151.55594452]\n",
            "[2871938.16900596]\n",
            "[37876904.27274705]\n",
            "Train : Episode 27/100 - Steps Count 2 - Avg Delay: [1.54501542], Avg Energy: [0.05597313], Avg Reward: [-0.36014972]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23615094.45149916]\n",
            "[37102710.53811362]\n",
            "[37290065.79361222]\n",
            "[17755422.55473444]\n",
            "[32511173.6229967]\n",
            "[31459055.52726715]\n",
            "[31513372.43225674]\n",
            "[32511173.6229967]\n",
            "[14000266.91506391]\n",
            "[2664024.25196186]\n",
            "[34828163.43390775]\n",
            "[32051677.74912093]\n",
            "[11558513.28386452]\n",
            "Train : Episode 28/100 - Steps Count 1 - Avg Delay: [2.16840046], Avg Energy: [0.02958457], Avg Reward: [-0.43559912]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14493174.1080605]\n",
            "[31513372.43225674]\n",
            "[22716700.24743054]\n",
            "[23193671.13491063]\n",
            "[23646721.49995521]\n",
            "[32004823.61178265]\n",
            "[5673809.97735141]\n",
            "[23038871.23682514]\n",
            "[26283172.93470039]\n",
            "[16418412.17845401]\n",
            "[23105944.50882491]\n",
            "[34854356.17907484]\n",
            "[25991081.157537]\n",
            "[23193671.13491063]\n",
            "[37543392.1164386]\n",
            "[17110628.46152668]\n",
            "[35349807.69653126]\n",
            "[22863523.23558135]\n",
            "[38053071.95052882]\n",
            "Train : Episode 29/100 - Steps Count 2 - Avg Delay: [1.44617534], Avg Energy: [0.02588617], Avg Reward: [-0.31680602]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25655815.27405952]\n",
            "[2847846.3484989]\n",
            "[14431673.62542464]\n",
            "[36430389.83404962]\n",
            "[23214355.38745984]\n",
            "[14421833.78208244]\n",
            "[2665877.97473288]\n",
            "[13892954.24898995]\n",
            "[25883490.80124479]\n",
            "[34272403.638897]\n",
            "[22648751.3771502]\n",
            "[36430389.83404962]\n",
            "[38083653.52285169]\n",
            "[23646721.49995521]\n",
            "Train : Episode 30/100 - Steps Count 1 - Avg Delay: [1.42683621], Avg Energy: [0.04174434], Avg Reward: [-0.41817117]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14788144.54107036]\n",
            "[37700269.46924694]\n",
            "[5644588.47726692]\n",
            "[14245218.95246914]\n",
            "[23473726.56994763]\n",
            "[32089534.32276857]\n",
            "[14424157.41953326]\n",
            "[14272465.8452502]\n",
            "[34706480.19401085]\n",
            "[26319084.30880911]\n",
            "[13921872.52263781]\n",
            "[2797010.70644203]\n",
            "Train : Episode 31/100 - Steps Count 1 - Avg Delay: [1.76785327], Avg Energy: [0.04051241], Avg Reward: [-0.35478026]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34661903.17859264]\n",
            "[11066278.56683374]\n",
            "[2861384.57040405]\n",
            "[17063306.10921269]\n",
            "[25774112.89472518]\n",
            "[5629893.67374407]\n",
            "[14689507.5556993]\n",
            "[5750878.36141751]\n",
            "[5686196.07413953]\n",
            "[14235040.4156064]\n",
            "[2729853.17218764]\n",
            "[14024980.13909335]\n",
            "[2729853.17218764]\n",
            "[11066278.56683374]\n",
            "[35542073.74453196]\n",
            "[34983547.7835889]\n",
            "[2730270.99906935]\n",
            "[32325777.73175735]\n",
            "[14091390.49891597]\n",
            "[2820488.40280911]\n",
            "[30448734.49315763]\n",
            "[30439273.50382205]\n",
            "[26261472.23116552]\n",
            "[26261472.23116552]\n",
            "[22363381.24472118]\n",
            "[17342097.58087246]\n",
            "Train : Episode 32/100 - Steps Count 2 - Avg Delay: [7.70815789], Avg Energy: [0.05005354], Avg Reward: [-0.38468477]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[14788144.54107036]\n",
            "[34650913.50389992]\n",
            "[14591374.45590355]\n",
            "[32379106.68319525]\n",
            "[34272403.638897]\n",
            "[26187004.9226388]\n",
            "[24936935.97687987]\n",
            "[2848375.01785388]\n",
            "[11558513.28386452]\n",
            "[11355610.01964]\n",
            "[17561899.97627941]\n",
            "[14689204.81347981]\n",
            "[13921872.52263781]\n",
            "[14000266.91506391]\n",
            "Train : Episode 33/100 - Steps Count 1 - Avg Delay: [2.2824583], Avg Energy: [0.04465243], Avg Reward: [-0.36836346]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23473726.56994763]\n",
            "[17446791.21619075]\n",
            "[17532185.46528647]\n",
            "[2760324.22288967]\n",
            "[25163186.4129853]\n",
            "[17329271.7453731]\n",
            "[31459055.52726715]\n",
            "[38017119.23143917]\n",
            "[22882266.5017997]\n",
            "[2725814.46226227]\n",
            "[22305374.57386156]\n",
            "[5687624.56656184]\n",
            "[14000266.91506391]\n",
            "[31062121.16663506]\n",
            "[25557448.06874863]\n",
            "[25655815.27405952]\n",
            "[35123033.73971204]\n",
            "[22949351.19379972]\n",
            "[23185066.37553751]\n",
            "[22716700.24743054]\n",
            "[2741584.48360312]\n",
            "[5708820.32192436]\n",
            "[5707691.69220864]\n",
            "[17504191.77596872]\n",
            "[25933140.26689425]\n",
            "[11286313.75195133]\n",
            "Train : Episode 34/100 - Steps Count 2 - Avg Delay: [3.5047671], Avg Energy: [0.03597543], Avg Reward: [-0.36640327]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32379106.68319525]\n",
            "[33943804.7209083]\n",
            "[14257484.14092473]\n",
            "[25883490.80124479]\n",
            "[25334336.92915022]\n",
            "[14403631.34286353]\n",
            "[22305374.57386156]\n",
            "[36304040.54945454]\n",
            "[17234651.61732796]\n",
            "[11752760.0790923]\n",
            "[33078802.20911973]\n",
            "[35041119.57454816]\n",
            "[17315123.10712679]\n",
            "[5864517.73551624]\n",
            "[17329271.7453731]\n",
            "[11619798.68413395]\n",
            "[38208021.40237062]\n",
            "[36677559.91934137]\n",
            "[11752760.0790923]\n",
            "[17044573.22694054]\n",
            "[17329271.7453731]\n",
            "[2848375.01785388]\n",
            "Train : Episode 35/100 - Steps Count 2 - Avg Delay: [1.32413489], Avg Energy: [0.07329825], Avg Reward: [-0.3587133]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26348039.13649368]\n",
            "[14428224.35831604]\n",
            "[2738294.23267901]\n",
            "[2788625.11994203]\n",
            "[5608874.46831452]\n",
            "[26253952.61060319]\n",
            "[37304545.43385452]\n",
            "[14788144.54107036]\n",
            "[32130184.84378477]\n",
            "[34213580.04890604]\n",
            "[16893090.90390802]\n",
            "[37700269.46924694]\n",
            "[22922802.04220884]\n",
            "[34844232.77950998]\n",
            "[25676716.66253832]\n",
            "[38203979.46294539]\n",
            "[26286613.2365365]\n",
            "[5394763.39051414]\n",
            "[5484680.33738702]\n",
            "[34272403.638897]\n",
            "[17307454.41564647]\n",
            "Train : Episode 36/100 - Steps Count 2 - Avg Delay: [1.47501477], Avg Energy: [0.04162784], Avg Reward: [-0.31691238]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22563134.25471732]\n",
            "[2738294.23267901]\n",
            "[38053071.95052882]\n",
            "[37876904.27274705]\n",
            "[5690514.55872996]\n",
            "[36941779.37110038]\n",
            "[2798706.4384385]\n",
            "[31047384.5529492]\n",
            "[34213580.04890604]\n",
            "[5824505.97622339]\n",
            "[17669179.37096233]\n",
            "[23120103.32816203]\n",
            "[22774911.54787705]\n",
            "[17178048.79155083]\n",
            "[17329271.7453731]\n",
            "[2758585.43140971]\n",
            "[14361164.78348368]\n",
            "[36940902.34998875]\n",
            "[33823966.9946847]\n",
            "[31071582.15597064]\n",
            "[11327071.05931666]\n",
            "[5661960.608137]\n",
            "[14504662.62920872]\n",
            "[22833482.65348506]\n",
            "[35924731.13493899]\n",
            "[22833482.65348506]\n",
            "[32004823.61178265]\n",
            "[17626805.59333161]\n",
            "[22108552.47831654]\n",
            "[2837254.54481181]\n",
            "[5546725.95629666]\n",
            "[5677280.27924264]\n",
            "[17518754.24304217]\n",
            "[34052148.06829339]\n",
            "[26561308.17124327]\n",
            "[17690174.15497406]\n",
            "[17254391.08702125]\n",
            "[17690174.15497406]\n",
            "[37576107.70554619]\n",
            "[31834900.4196225]\n",
            "[14590941.60442753]\n",
            "[14356477.01236331]\n",
            "[2817324.68908704]\n",
            "[36549485.96875266]\n",
            "[2848677.0061836]\n",
            "[36935831.20494431]\n",
            "[26217840.61066581]\n",
            "[22943002.03386823]\n",
            "[2767929.33814588]\n",
            "[5739686.69785075]\n",
            "[25981099.58668883]\n",
            "[11591674.58439501]\n",
            "[14360766.75970551]\n",
            "[34778143.06224616]\n",
            "[5762137.88136317]\n",
            "[33873769.3609361]\n",
            "[30613492.64818003]\n",
            "[2767106.31146289]\n",
            "Train : Episode 37/100 - Steps Count 6 - Avg Delay: [1.75132559], Avg Energy: [0.05501052], Avg Reward: [-0.32831357]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30770463.86855427]\n",
            "[34213580.04890604]\n",
            "[25616070.56632978]\n",
            "[31047384.5529492]\n",
            "[31299852.780574]\n",
            "[14431673.62542464]\n",
            "[35123033.73971204]\n",
            "[37479109.60100897]\n",
            "[26319084.30880911]\n",
            "[37848750.39140202]\n",
            "[36944836.95078126]\n",
            "[24900703.84036184]\n",
            "[34026664.94283239]\n",
            "[17669179.37096233]\n",
            "[26174783.10404092]\n",
            "[2738294.23267901]\n",
            "[37375374.74024308]\n",
            "[2788625.11994203]\n",
            "[16735856.59222415]\n",
            "Train : Episode 38/100 - Steps Count 2 - Avg Delay: [1.57498604], Avg Energy: [0.02831231], Avg Reward: [-0.34567677]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m env\u001b[39m.\u001b[39mE_max \u001b[39m=\u001b[39m E_max \u001b[39m*\u001b[39m \u001b[39m1e-3\u001b[39m  \u001b[39m# Convert mJ to J\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# Train the agent\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(num_train_episodes)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Save the Q-table for this configuration\u001b[39;00m\n\u001b[0;32m     38\u001b[0m q_table_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(q_table_folder, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mQ_table_S\u001b[39m\u001b[39m{\u001b[39;00mS_max_es\u001b[39m}\u001b[39;00m\u001b[39m_E\u001b[39m\u001b[39m{\u001b[39;00mE_max\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[10], line 147\u001b[0m, in \u001b[0;36mQLearningAgent.train\u001b[1;34m(self, num_episodes)\u001b[0m\n\u001b[0;32m    142\u001b[0m avg_rewards \u001b[39m=\u001b[39m []\n\u001b[0;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_episodes):\n\u001b[0;32m    146\u001b[0m     \u001b[39m# Initialize device state information for all users at the beginning of each episode\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     device_state_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset()\n\u001b[0;32m    149\u001b[0m     \u001b[39m# Initialize total delay and energy for this episode\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     total_delay \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "Cell \u001b[1;32mIn[1], line 374\u001b[0m, in \u001b[0;36mEdgeComputingEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessing_tasks \u001b[39m=\u001b[39m []  \u001b[39m# Clear processing tasks\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_time \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reset current time\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_user_device_params()  \u001b[39m# Reinitialize user device parameters\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_bandwidth \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reinitialize total bandwidth\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_computation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reinitialize total computation\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[1], line 62\u001b[0m, in \u001b[0;36mEdgeComputingEnvironment.initialize_user_device_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marea_size \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)  \u001b[39m# Distance to server\u001b[39;00m\n\u001b[0;32m     61\u001b[0m g_m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPL_d(d)])  \u001b[39m# Path loss\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m h_bar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39mj \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)  \u001b[39m# Channel gain\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_device_params\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     65\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdevice_id\u001b[39m\u001b[39m'\u001b[39m: device_id,  \u001b[39m# Assign a unique ID to each device\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m: d,\n\u001b[0;32m     67\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mg_m\u001b[39m\u001b[39m'\u001b[39m: g_m,\n\u001b[0;32m     68\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mh_bar\u001b[39m\u001b[39m'\u001b[39m: h_bar,\n\u001b[0;32m     69\u001b[0m })\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# learning and test for S_max_es and E_max\n",
        "\n",
        "# Assuming you have the QLearningAgent and EdgeComputingEnvironment classes defined as before\n",
        "env = EdgeComputingEnvironment()\n",
        "\n",
        "# Define your parameter ranges\n",
        "S_max_es_values = [0, 20, 40, 60]  # in KB\n",
        "E_max_values = [1.5, 2, 2.5, 3, 3.5, 4]  # in mJ\n",
        "\n",
        "# Define the number of users/devices\n",
        "num_users = env.M\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "agent = QLearningAgent(env, num_users)\n",
        "\n",
        "# Define the number of episodes for training and testing steps\n",
        "num_train_episodes = 100  # or any suitable number for training\n",
        "num_test_steps = 20  # or any suitable number for testing\n",
        "\n",
        "# Create the folder for Q-table files if it doesn't exist\n",
        "q_table_folder = 'Q-Tables_Test1'\n",
        "os.makedirs(q_table_folder, exist_ok=True)\n",
        "\n",
        "# Storage for results\n",
        "results = []\n",
        "\n",
        "# Training phase\n",
        "for S_max_es in S_max_es_values:\n",
        "    for E_max in E_max_values:\n",
        "        # Set the environment parameters\n",
        "        env.S_max_es = S_max_es * 1e3  # Convert KB to bytes\n",
        "        env.E_max = E_max * 1e-3  # Convert mJ to J\n",
        "\n",
        "        # Train the agent\n",
        "        agent.train(num_train_episodes)\n",
        "\n",
        "        # Save the Q-table for this configuration\n",
        "        q_table_filename = os.path.join(q_table_folder, f'Q_table_S{S_max_es}_E{E_max}.json')\n",
        "        agent.save_q_table(q_table_filename)\n",
        "\n",
        "# Testing phase\n",
        "for S_max_es in S_max_es_values:\n",
        "    for E_max in E_max_values:\n",
        "        # Load the Q-table for this configuration\n",
        "        q_table_filename = os.path.join(q_table_folder, f'Q_table_S{S_max_es}_E{E_max}.json')\n",
        "        agent.load_q_table(q_table_filename)\n",
        "\n",
        "        # Set the environment parameters\n",
        "        env.S_max_es = S_max_es * 1e3  # Convert KB to bytes\n",
        "        env.E_max = E_max * 1e-3  # Convert mJ to J\n",
        "\n",
        "        total_delay = 0\n",
        "\n",
        "        # Test the agent and get the average delay\n",
        "        avg_delay, avg_alpha = agent.test(num_test_steps)\n",
        "\n",
        "        # Store the results\n",
        "        results.append({\n",
        "            'S_max_es': S_max_es,\n",
        "            'E_max': E_max,\n",
        "            'avg_delay': avg_delay,\n",
        "        })\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for S_max_es in S_max_es_values:\n",
        "    # Extract delays and inspect for any non-numerical values or sequences\n",
        "    delays = [result['avg_delay'] for result in results if result['S_max_es'] == S_max_es]\n",
        "    \n",
        "    # Ensure all delays are numerical values (Optional)\n",
        "    cleaned_delays = []\n",
        "    for delay in delays:\n",
        "        if isinstance(delay, (int, float, np.number)):  # Check if delay is a numerical value\n",
        "            cleaned_delays.append(delay)\n",
        "        elif isinstance(delay, (list, np.ndarray)):  # Check if delay is a list or array\n",
        "            if len(delay) == 1:\n",
        "                cleaned_delays.append(delay[0])  # Extract single element if it's a list/array of one element\n",
        "            else:\n",
        "                print(f\"Warning: Found non-scalar delay value for S_max_es = {S_max_es}: {delay}\")\n",
        "        else:\n",
        "            print(f\"Warning: Found non-numerical delay value for S_max_es = {S_max_es}: {delay}\")\n",
        "\n",
        "    # Plot the cleaned delays\n",
        "    plt.plot(E_max_values, cleaned_delays, marker='o', label=f'S_max_es = {S_max_es} KB')\n",
        "\n",
        "plt.xlabel('Maximum energy requirement, $E_{max}$ (mJ)')\n",
        "plt.ylabel('The total e2e latency (ms)')\n",
        "plt.title('The impact of edge caching capacity ($S_{max}^{es}$) and UE\\'s energy consumption budget ($E_{max}$) on e2e latency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36215213.62534444]\n",
            "[25735785.87920674]\n",
            "[32000836.85163995]\n",
            "[29119679.57029104]\n",
            "[36347484.43972605]\n",
            "[22916575.62589505]\n",
            "[23298834.56303016]\n",
            "[28488922.1027994]\n",
            "[19764479.95508612]\n",
            "[37351917.85212491]\n",
            "[28304404.55035065]\n",
            "[26369998.45279995]\n",
            "[28124245.4947768]\n",
            "[25389971.26622317]\n",
            "Train : Episode 1/100 - Steps Count 1 - Avg Delay: [0.72881996], Avg Energy: [0.01488462], Avg Reward: [-0.33704201]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19955573.88327515]\n",
            "[25599308.61501873]\n",
            "[30952051.13526261]\n",
            "[36745956.36260124]\n",
            "[17391361.80924979]\n",
            "[34643190.92813012]\n",
            "[21875591.72601535]\n",
            "[35626943.54282025]\n",
            "[23099028.99463775]\n",
            "[37788845.25186591]\n",
            "[25615378.26428022]\n",
            "[22894131.58299772]\n",
            "[27621685.46767512]\n",
            "[30775326.29289488]\n",
            "[28195681.11701357]\n",
            "[23091831.89019085]\n",
            "[36928338.18491662]\n",
            "[22065043.99434929]\n",
            "[20288604.8359009]\n",
            "[34904698.82736389]\n",
            "[16895778.92344718]\n",
            "[19957620.33945151]\n",
            "[22851716.17534078]\n",
            "[35038134.28016576]\n",
            "[37724935.89229231]\n",
            "[34444220.62083302]\n",
            "[36695450.06617381]\n",
            "[37383343.29322017]\n",
            "[20495837.62961071]\n",
            "[17456595.86925204]\n",
            "[31335450.99164369]\n",
            "[17376226.70035371]\n",
            "[34045987.90776804]\n",
            "[16780057.34939208]\n",
            "[37091585.14394171]\n",
            "[23465582.75147294]\n",
            "[22587320.25508582]\n",
            "[26132026.60761309]\n",
            "[36844139.6648444]\n",
            "[37776611.57367409]\n",
            "[33779643.60638414]\n",
            "[34521241.84326933]\n",
            "[23397612.75089601]\n",
            "[33193275.65228418]\n",
            "[17219082.61077759]\n",
            "[31791848.98308507]\n",
            "[22445425.06945714]\n",
            "[16663439.01231962]\n",
            "[28009882.46605729]\n",
            "[34714824.76537866]\n",
            "Train : Episode 2/100 - Steps Count 5 - Avg Delay: [0.85984446], Avg Energy: [0.02123482], Avg Reward: [-0.32209466]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17243911.41408446]\n",
            "[38180159.34832978]\n",
            "[22788474.71116388]\n",
            "[37943794.42292785]\n",
            "[22256809.70046797]\n",
            "[32178832.61118336]\n",
            "[16841105.41756821]\n",
            "[36928338.18491662]\n",
            "[20079567.77026637]\n",
            "[17394646.86375295]\n",
            "[22529642.75031909]\n",
            "[36332585.58501162]\n",
            "[33101571.21500776]\n",
            "[36996744.64037579]\n",
            "[36417247.53567225]\n",
            "Train : Episode 3/100 - Steps Count 1 - Avg Delay: [1.10383614], Avg Energy: [0.01784422], Avg Reward: [-0.41894805]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31410969.99922127]\n",
            "[25387519.56456906]\n",
            "[20109628.80572335]\n",
            "[37334828.07263988]\n",
            "[23055105.21767381]\n",
            "[19701279.66911148]\n",
            "[23345893.69738015]\n",
            "[21724187.07671386]\n",
            "[37217609.14064145]\n",
            "[31101353.56779106]\n",
            "[23357914.51627679]\n",
            "[35956997.56386171]\n",
            "[19925373.97661472]\n",
            "[37151265.98678192]\n",
            "[20496761.18986945]\n",
            "[35067315.14531628]\n",
            "[23124779.70104489]\n",
            "[25683644.42345658]\n",
            "[28902442.16903898]\n",
            "[25893347.99273708]\n",
            "[37494422.05144375]\n",
            "[31740174.69805712]\n",
            "[37855234.05936348]\n",
            "[24730775.33618228]\n",
            "[20217155.58502783]\n",
            "[22473165.84318379]\n",
            "[23366671.54124705]\n",
            "[22757137.61600199]\n",
            "[32729361.08066793]\n",
            "[23016186.64503101]\n",
            "[26348639.83748724]\n",
            "[37162841.06320513]\n",
            "[17159525.58096745]\n",
            "[37644995.79078849]\n",
            "[22920554.71971906]\n",
            "[31966101.65881851]\n",
            "[30995129.06980862]\n",
            "[17373239.08396531]\n",
            "[28007659.45550874]\n",
            "[27979293.99517548]\n",
            "[37725012.25101001]\n",
            "[17273038.80580893]\n",
            "[22579124.72017131]\n",
            "[32111234.24371191]\n",
            "[17391361.80924979]\n",
            "[22914352.17637786]\n",
            "[29574809.78172462]\n",
            "[20182943.3988153]\n",
            "[33800922.05084571]\n",
            "[37282424.94174721]\n",
            "[17352765.25137783]\n",
            "[17242528.32095441]\n",
            "[25554807.5401361]\n",
            "[27814193.98448152]\n",
            "[36717508.73248485]\n",
            "[37220218.27042358]\n",
            "[22971181.82095769]\n",
            "[17268003.17935445]\n",
            "[36525624.54530405]\n",
            "[19787418.71197018]\n",
            "[26120912.08464884]\n",
            "Train : Episode 4/100 - Steps Count 7 - Avg Delay: [1.0463538], Avg Energy: [0.01977277], Avg Reward: [-0.25852404]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[33234137.86801706]\n",
            "[36475792.47012598]\n",
            "[37905513.52504303]\n",
            "[19741483.1253228]\n",
            "[23181274.29148512]\n",
            "[22192157.07729078]\n",
            "[23056124.95495202]\n",
            "[28195681.11701357]\n",
            "[36321884.43111597]\n",
            "[36665563.87996457]\n",
            "[34445070.91529737]\n",
            "[37220218.27042358]\n",
            "[31871931.91032086]\n",
            "Train : Episode 5/100 - Steps Count 1 - Avg Delay: [0.5911839], Avg Energy: [0.01560503], Avg Reward: [-0.34311929]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26119229.00670706]\n",
            "[29064163.91409667]\n",
            "[25108604.72222977]\n",
            "[22594303.98029579]\n",
            "[37637223.18933047]\n",
            "[34691788.17508804]\n",
            "[23341135.84376071]\n",
            "[23144114.20183729]\n",
            "[30571518.3977119]\n",
            "[38088349.49679654]\n",
            "[19571583.73581321]\n",
            "[24963111.73385957]\n",
            "[26174472.14698986]\n",
            "[32138916.66526449]\n",
            "[20278517.54607985]\n",
            "[28968567.4833934]\n",
            "[30724609.86682729]\n",
            "[34879247.34760421]\n",
            "[29007659.45550874]\n",
            "[26067793.53016085]\n",
            "[25033615.83983283]\n",
            "[37127140.65888032]\n",
            "[23028656.9592804]\n",
            "[36717508.73248485]\n",
            "[23265532.74234084]\n",
            "[17470260.59920975]\n",
            "[19767530.8677337]\n",
            "[23148337.17666633]\n",
            "[25998497.61105239]\n",
            "[37617872.88807394]\n",
            "[25876877.84313171]\n",
            "[22722176.1513122]\n",
            "[17476887.48431465]\n",
            "[21935358.50239303]\n",
            "[17304814.77047622]\n",
            "[22878740.09075803]\n",
            "[22781549.38936101]\n",
            "[19936673.78227786]\n",
            "[20182051.12869687]\n",
            "[36332585.58501162]\n",
            "[37210577.3887867]\n",
            "[16994838.92986356]\n",
            "[19857368.28664379]\n",
            "[32125401.8197655]\n",
            "[32894344.89927928]\n",
            "[22955767.61327179]\n",
            "[22432511.00584212]\n",
            "[33895410.96364811]\n",
            "[23179444.74265852]\n",
            "Train : Episode 6/100 - Steps Count 5 - Avg Delay: [4.00757226], Avg Energy: [0.02626289], Avg Reward: [-0.2853725]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[29402521.36604876]\n",
            "[36713280.21575145]\n",
            "[29425302.65473899]\n",
            "[33396526.42198326]\n",
            "[33779643.60638414]\n",
            "[31627897.30382799]\n",
            "[28964107.91521946]\n",
            "[29451002.2309923]\n",
            "[23152887.68294346]\n",
            "[34399183.4783781]\n",
            "[25026648.25438679]\n",
            "[25972340.13654597]\n",
            "[17552481.24951209]\n",
            "[25694355.66243868]\n",
            "[37220230.76551127]\n",
            "[23327668.66642797]\n",
            "[23056938.4906387]\n",
            "[20309916.81286342]\n",
            "[26009116.75135473]\n",
            "[31789462.41523342]\n",
            "Train : Episode 7/100 - Steps Count 2 - Avg Delay: [0.62739673], Avg Energy: [0.02328339], Avg Reward: [-0.29891079]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28304404.55035065]\n",
            "[17043932.76723846]\n",
            "[22634566.81546311]\n",
            "[16632501.42049318]\n",
            "[28114251.20996682]\n",
            "[33920834.11421838]\n",
            "[36530741.0630051]\n",
            "[25383685.10363292]\n",
            "[17468661.81478284]\n",
            "[25694355.66243868]\n",
            "[22975900.28349184]\n",
            "Train : Episode 8/100 - Steps Count 1 - Avg Delay: [1.69856672], Avg Energy: [0.01915885], Avg Reward: [-0.40722105]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22753342.94408209]\n",
            "[17543569.96823049]\n",
            "[20479370.62912916]\n",
            "[37653310.00221647]\n",
            "[34814272.60515618]\n",
            "[26273192.54575916]\n",
            "[20447009.26497448]\n",
            "[19871526.11101412]\n",
            "[36525624.54530405]\n",
            "[36655344.37576871]\n",
            "[28443957.43490734]\n",
            "[28693689.93472963]\n",
            "[22299028.99463775]\n",
            "[21821197.61484814]\n",
            "[36934117.37109922]\n",
            "[37696944.62243893]\n",
            "[30932689.83176234]\n",
            "[28738015.84607025]\n",
            "[17140763.97171424]\n",
            "[22518024.11275874]\n",
            "[37865603.17101134]\n",
            "[34695453.66995613]\n",
            "[26240178.90761231]\n",
            "[25472984.40504406]\n",
            "[36154991.81270356]\n",
            "[24963111.73385957]\n",
            "[36371413.08071175]\n",
            "Train : Episode 9/100 - Steps Count 3 - Avg Delay: [4.82311592], Avg Energy: [0.01737329], Avg Reward: [-0.25367789]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30775326.29289488]\n",
            "[26119229.00670706]\n",
            "[29223201.79879255]\n",
            "[37381803.7129907]\n",
            "[28304404.55035065]\n",
            "[36777189.57532506]\n",
            "[19930348.80568579]\n",
            "[20147997.37763443]\n",
            "[34643190.92813012]\n",
            "[17141952.75056796]\n",
            "[35812454.98508071]\n",
            "[34310785.16803114]\n",
            "[21889458.19665842]\n",
            "[22684039.11247029]\n",
            "[36879822.96433632]\n",
            "[22995354.19359219]\n",
            "[17541775.60123834]\n",
            "[34019011.24523446]\n",
            "[35812454.98508071]\n",
            "[37422249.46500327]\n",
            "[33970862.81824926]\n",
            "[34695453.66995613]\n",
            "[34904698.82736389]\n",
            "[25679099.1729515]\n",
            "[16632501.42049318]\n",
            "Train : Episode 10/100 - Steps Count 2 - Avg Delay: [0.77751487], Avg Energy: [0.01705396], Avg Reward: [-0.32783148]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[16900504.28603463]\n",
            "[28908130.30188541]\n",
            "[17199417.92088686]\n",
            "[25108604.72222977]\n",
            "[37183179.85403487]\n",
            "[16906321.079408]\n",
            "[21889458.19665842]\n",
            "[28190926.59842022]\n",
            "[22505652.12100479]\n",
            "[23019398.28243497]\n",
            "[29179807.46749961]\n",
            "[25026648.25438679]\n",
            "[37710678.98549479]\n",
            "[25430340.31943722]\n",
            "[17210503.08140014]\n",
            "[36904703.3278506]\n",
            "[36172697.10044441]\n",
            "[37488796.33542117]\n",
            "[37520408.93933424]\n",
            "[36064379.82587105]\n",
            "[33580523.22492369]\n",
            "[22065043.99434929]\n",
            "[22767445.41994687]\n",
            "[17468661.81478284]\n",
            "[35882218.0810269]\n",
            "[20388998.02510427]\n",
            "[33315517.96730074]\n",
            "[26434825.61201202]\n",
            "[26211621.60055092]\n",
            "[23043123.41433281]\n",
            "[17092991.6749332]\n",
            "[25449820.18497451]\n",
            "Train : Episode 11/100 - Steps Count 3 - Avg Delay: [3.63417222], Avg Energy: [0.02047582], Avg Reward: [-0.27410999]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[27603991.60608585]\n",
            "[25033615.83983283]\n",
            "[17552481.24951209]\n",
            "[31925387.00006223]\n",
            "[25033615.83983283]\n",
            "[31377987.62431901]\n",
            "[19677731.64264556]\n",
            "[28443957.43490734]\n",
            "[36717508.73248485]\n",
            "[35626943.54282025]\n",
            "[37187515.17640367]\n",
            "[25922925.88746154]\n",
            "[22453838.24388145]\n",
            "Train : Episode 12/100 - Steps Count 1 - Avg Delay: [1.40977596], Avg Energy: [0.02316417], Avg Reward: [-0.40918933]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35626943.54282025]\n",
            "[37329468.35312783]\n",
            "[22973052.53303035]\n",
            "[17199417.92088686]\n",
            "[20236714.72203723]\n",
            "[33396526.42198326]\n",
            "[22842410.58300274]\n",
            "[29179807.46749961]\n",
            "[33364516.98360154]\n",
            "[36254507.99147719]\n",
            "[26159656.85271195]\n",
            "[33393498.66909074]\n",
            "[22806703.64776391]\n",
            "[16785150.0139871]\n",
            "[36465943.70246384]\n",
            "[23269262.6569858]\n",
            "[28858789.94542358]\n",
            "[16790613.43675935]\n",
            "[31204720.5499108]\n",
            "[20171567.05077349]\n",
            "[37653310.00221647]\n",
            "[20221526.11101412]\n",
            "[34012051.61278963]\n",
            "[28517748.6331097]\n",
            "[28191006.30597337]\n",
            "[31699229.51192079]\n",
            "[17196690.97050977]\n",
            "[29026593.96682601]\n",
            "[36828660.17992719]\n",
            "[17560195.76463758]\n",
            "[37256528.42986225]\n",
            "[34627730.59679951]\n",
            "[22766418.55969188]\n",
            "[36828660.17992719]\n",
            "[33779643.60638414]\n",
            "[34693183.18453411]\n",
            "[23122280.0830879]\n",
            "[31822711.49426882]\n",
            "[28425043.89782093]\n",
            "[33634083.62778194]\n",
            "Train : Episode 13/100 - Steps Count 4 - Avg Delay: [1.15063217], Avg Energy: [0.02020645], Avg Reward: [-0.30885708]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28285967.23983448]\n",
            "[17603315.11472093]\n",
            "[31377987.62431901]\n",
            "[35343838.92896523]\n",
            "[17440763.97171424]\n",
            "[35114347.61885431]\n",
            "[37537220.01035793]\n",
            "[26150861.14477431]\n",
            "[36172697.10044441]\n",
            "[32072475.97689674]\n",
            "[28531935.30360627]\n",
            "[25946877.54878111]\n",
            "[23346538.87102699]\n",
            "Train : Episode 14/100 - Steps Count 1 - Avg Delay: [1.00146433], Avg Energy: [0.02177197], Avg Reward: [-0.36892728]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37841003.8937868]\n",
            "[37869490.96616099]\n",
            "[35882218.0810269]\n",
            "[22975900.28349184]\n",
            "[37905513.52504303]\n",
            "[36817582.25267707]\n",
            "[19948749.43550069]\n",
            "[25945678.53091567]\n",
            "[37747458.27893293]\n",
            "[26240178.90761231]\n",
            "[31930132.15414155]\n",
            "[37726693.8202557]\n",
            "[23397501.0965972]\n",
            "Train : Episode 15/100 - Steps Count 1 - Avg Delay: [0.90745435], Avg Energy: [0.02487495], Avg Reward: [-0.37193625]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30104720.5499108]\n",
            "[25783707.83748036]\n",
            "[22370970.58801287]\n",
            "[37710678.98549479]\n",
            "[37443692.82621977]\n",
            "[19861855.72672921]\n",
            "[19832096.64237217]\n",
            "[22594303.98029579]\n",
            "[22664420.18757814]\n",
            "[26240178.90761231]\n",
            "[22942795.21241603]\n",
            "[21821197.61484814]\n",
            "[28949920.84679877]\n",
            "[25996841.63935604]\n",
            "[37381803.7129907]\n",
            "[19274530.55993979]\n",
            "[37869490.96616099]\n",
            "[37998938.78355695]\n",
            "[17510388.10402471]\n",
            "[19483542.55114176]\n",
            "[25892264.86611029]\n",
            "Train : Episode 16/100 - Steps Count 2 - Avg Delay: [1.20111338], Avg Energy: [0.02149665], Avg Reward: [-0.27269777]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35114347.61885431]\n",
            "[23181274.29148512]\n",
            "[35114347.61885431]\n",
            "[37334828.07263988]\n",
            "[22863385.83933584]\n",
            "[31258779.31047771]\n",
            "[23082773.89107458]\n",
            "[20150807.56036289]\n",
            "[33779643.60638414]\n",
            "[19484946.30297206]\n",
            "[16798193.21068411]\n",
            "[36915664.21047833]\n",
            "[25045136.34460792]\n",
            "[23394641.18879384]\n",
            "[20259933.98983992]\n",
            "[16758415.08478418]\n",
            "[34393295.41979598]\n",
            "[23489994.52483196]\n",
            "[24963111.73385957]\n",
            "[28394690.67317156]\n",
            "[20495837.62961071]\n",
            "[31291695.32889345]\n",
            "[31899939.83027377]\n",
            "[34081622.09051604]\n",
            "[25727569.28193847]\n",
            "[37018431.58976579]\n",
            "[23314352.17637786]\n",
            "[23277699.19699224]\n",
            "[16747835.17761863]\n",
            "[20124039.88882665]\n",
            "[37905332.08680747]\n",
            "[20167333.72659649]\n",
            "Train : Episode 17/100 - Steps Count 3 - Avg Delay: [0.74271556], Avg Energy: [0.01952964], Avg Reward: [-0.29370986]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28488922.1027994]\n",
            "[22894131.58299772]\n",
            "[22256809.70046797]\n",
            "[26150861.14477431]\n",
            "[17210503.08140014]\n",
            "[25616270.32937485]\n",
            "[25616270.32937485]\n",
            "[23161759.90100849]\n",
            "[17199417.92088686]\n",
            "[22981335.38921884]\n",
            "[37537220.01035793]\n",
            "[20479370.62912916]\n",
            "Train : Episode 18/100 - Steps Count 1 - Avg Delay: [0.69378323], Avg Energy: [0.02842321], Avg Reward: [-0.38328366]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17210503.08140014]\n",
            "[25679099.1729515]\n",
            "[22370970.58801287]\n",
            "[23089191.28723542]\n",
            "[20109628.80572335]\n",
            "[38088349.49679654]\n",
            "[34664002.31938358]\n",
            "[36717508.73248485]\n",
            "[20217155.58502783]\n",
            "[28908130.30188541]\n",
            "[37869490.96616099]\n",
            "[28907421.52968631]\n",
            "[31101353.56779106]\n",
            "[34592340.33531052]\n",
            "[31288479.46918773]\n",
            "[25045136.34460792]\n",
            "[37334828.07263988]\n",
            "[37381803.7129907]\n",
            "[17260664.18224645]\n",
            "[25708020.05673523]\n",
            "[22651506.12396312]\n",
            "[36893237.99735022]\n",
            "[17574226.5957548]\n",
            "[37996574.52270168]\n",
            "[34592340.33531052]\n",
            "[21889458.19665842]\n",
            "[28693689.93472963]\n",
            "[28573718.32557052]\n",
            "[22726383.98885095]\n",
            "[31803687.16763807]\n",
            "[28114251.20996682]\n",
            "[36722991.81262495]\n",
            "[36786943.69734495]\n",
            "[36695450.06617381]\n",
            "[36968738.75556932]\n",
            "[19845002.75973348]\n",
            "[31979500.13328685]\n",
            "[34280338.58110063]\n",
            "[36579115.4417682]\n",
            "[20522097.4391033]\n",
            "[37614015.63608373]\n",
            "[31274177.36127323]\n",
            "[24803472.36492909]\n",
            "[22445425.06945714]\n",
            "[19930348.80568579]\n",
            "[22857273.75326393]\n",
            "[37965529.33442763]\n",
            "[37996574.52270168]\n",
            "[34963013.47071811]\n",
            "[31821432.73560992]\n",
            "[31606897.70177034]\n",
            "[26139548.45933644]\n",
            "[34587361.5138652]\n",
            "[31668514.99334907]\n",
            "[17455271.95292944]\n",
            "[19704315.34525182]\n",
            "[27122254.5440984]\n",
            "[23226229.54487954]\n",
            "[28252368.06046123]\n",
            "[37646744.64037579]\n",
            "[16985259.1910752]\n",
            "[36371879.95114437]\n",
            "[24878058.24476222]\n",
            "[22886943.31495726]\n",
            "[19704315.34525182]\n",
            "Train : Episode 19/100 - Steps Count 7 - Avg Delay: [2.62491875], Avg Energy: [0.02005335], Avg Reward: [-0.28421673]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23141171.40343641]\n",
            "[37841003.8937868]\n",
            "[34712478.15206096]\n",
            "[36968738.75556932]\n",
            "[25989473.53424372]\n",
            "[29014983.64862052]\n",
            "[33920834.11421838]\n",
            "[36911435.69374493]\n",
            "[34695453.66995613]\n",
            "[36354321.68255569]\n",
            "[20027731.64264556]\n",
            "[35821200.09834924]\n",
            "[34664002.31938358]\n",
            "[23386125.4513474]\n",
            "[28932646.71117977]\n",
            "[36911435.69374493]\n",
            "[36208573.11680238]\n",
            "[20111335.16712698]\n",
            "[28679470.37816738]\n",
            "[25219296.75000708]\n",
            "[25045461.04056482]\n",
            "[37773828.19691648]\n",
            "[23327668.66642797]\n",
            "[20444750.37978619]\n",
            "[32244997.59643629]\n",
            "[34393295.41979598]\n",
            "[29018236.35380007]\n",
            "[28650771.53891646]\n",
            "[23452503.05353018]\n",
            "[36172697.10044441]\n",
            "[32138916.66526449]\n",
            "[30933952.98995384]\n",
            "[31018924.79733403]\n",
            "Train : Episode 20/100 - Steps Count 3 - Avg Delay: [0.77086233], Avg Energy: [0.02399233], Avg Reward: [-0.33536925]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37334828.07263988]\n",
            "[31373600.70003401]\n",
            "[36717508.73248485]\n",
            "[37537220.01035793]\n",
            "[19738728.07732992]\n",
            "[36465943.70246384]\n",
            "[36817582.25267707]\n",
            "[31562214.62530965]\n",
            "[29119679.57029104]\n",
            "[20386788.00394927]\n",
            "[32111234.24371191]\n",
            "[22839955.39880319]\n",
            "[22840972.52447518]\n",
            "[19393893.48118206]\n",
            "[37744998.96976101]\n",
            "[17142422.96240774]\n",
            "[23269262.6569858]\n",
            "[36145398.9198353]\n",
            "[31737771.83267663]\n",
            "[19787418.71197018]\n",
            "[34160368.81048299]\n",
            "[27703379.16036777]\n",
            "[31805791.22339144]\n",
            "[19527736.53580739]\n",
            "[29574809.78172462]\n",
            "[23131719.3189122]\n",
            "[29090563.90199378]\n",
            "[17383306.12722194]\n",
            "[16720290.17323084]\n",
            "[25764578.71600359]\n",
            "[32099525.10472307]\n",
            "[20318399.51281383]\n",
            "Train : Episode 21/100 - Steps Count 3 - Avg Delay: [1.34911526], Avg Energy: [0.02174223], Avg Reward: [-0.29652884]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37018431.58976579]\n",
            "[28285967.23983448]\n",
            "[16895778.92344718]\n",
            "[20236714.72203723]\n",
            "[25946744.39415146]\n",
            "[20236714.72203723]\n",
            "[28190926.59842022]\n",
            "[23124779.70104489]\n",
            "[37905513.52504303]\n",
            "[36872252.64397582]\n",
            "[30571518.3977119]\n",
            "[36817582.25267707]\n",
            "[36321884.43111597]\n",
            "[17210503.08140014]\n",
            "[30775326.29289488]\n",
            "[23327668.66642797]\n",
            "[16900504.28603463]\n",
            "[16900504.28603463]\n",
            "[21889458.19665842]\n",
            "[22445425.06945714]\n",
            "[36745956.36260124]\n",
            "[31606897.70177034]\n",
            "Train : Episode 22/100 - Steps Count 2 - Avg Delay: [1.80702418], Avg Energy: [0.01430114], Avg Reward: [-0.26610817]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17383306.12722194]\n",
            "[23221850.92200008]\n",
            "[28964107.91521946]\n",
            "[34879247.34760421]\n",
            "[26273192.54575916]\n",
            "[25946744.39415146]\n",
            "[37381803.7129907]\n",
            "[32101176.86387233]\n",
            "[20345943.32335969]\n",
            "[35114347.61885431]\n",
            "[36300348.09089724]\n",
            "[37537220.01035793]\n",
            "[28615288.27823939]\n",
            "[37537220.01035793]\n",
            "[28190926.59842022]\n",
            "[26119229.00670706]\n",
            "[36817582.25267707]\n",
            "[27365174.27568388]\n",
            "[20217737.33253852]\n",
            "[20217737.33253852]\n",
            "[26329293.10901235]\n",
            "[28531935.30360627]\n",
            "[34440253.45919144]\n",
            "[23394898.93245357]\n",
            "[30788305.2421533]\n",
            "[37334828.07263988]\n",
            "[34007806.85505503]\n",
            "[29179807.46749961]\n",
            "[28577968.87779301]\n",
            "[25389971.26622317]\n",
            "[17304814.77047622]\n",
            "Train : Episode 23/100 - Steps Count 3 - Avg Delay: [0.84988237], Avg Energy: [0.01745458], Avg Reward: [-0.25217543]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22664420.18757814]\n",
            "[35012392.61798893]\n",
            "[28908130.30188541]\n",
            "[25108604.72222977]\n",
            "[37943794.42292785]\n",
            "[24534779.83428265]\n",
            "[36465943.70246384]\n",
            "[34330166.31026895]\n",
            "[26273192.54575916]\n",
            "[37765943.70246385]\n",
            "[34627730.59679951]\n",
            "[30932689.83176234]\n",
            "[17391361.80924979]\n",
            "[23144114.20183729]\n",
            "[22423071.77001782]\n",
            "[33881678.94844089]\n",
            "[16871041.26953409]\n",
            "[29051025.92703869]\n",
            "[31507783.07736909]\n",
            "[20192317.30255387]\n",
            "[23187185.22622897]\n",
            "[28764877.36015494]\n",
            "[34344735.28505097]\n",
            "[31377987.62431901]\n",
            "[37334828.07263988]\n",
            "[22916575.62589505]\n",
            "[31822711.49426882]\n",
            "[34889908.18792079]\n",
            "[37217234.0637295]\n",
            "[36717508.73248485]\n",
            "[25969637.84741799]\n",
            "[19929450.30296268]\n",
            "[23123032.16258636]\n",
            "[36081020.55499063]\n",
            "[20241487.20549535]\n",
            "[37204879.51220907]\n",
            "[37646744.64037579]\n",
            "Train : Episode 24/100 - Steps Count 4 - Avg Delay: [0.78170992], Avg Energy: [0.02137394], Avg Reward: [-0.25864213]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[27621685.46767512]\n",
            "[20345943.32335969]\n",
            "[31456696.94715703]\n",
            "[34393295.41979598]\n",
            "[37943794.42292785]\n",
            "[29143440.50290697]\n",
            "[25108604.72222977]\n",
            "[34330166.31026895]\n",
            "[22781549.38936101]\n",
            "[22975900.28349184]\n",
            "[20043476.09198097]\n",
            "[17551580.28997612]\n",
            "[23181274.29148512]\n",
            "Train : Episode 25/100 - Steps Count 1 - Avg Delay: [0.81477811], Avg Energy: [0.02442474], Avg Reward: [-0.39062413]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23346538.87102699]\n",
            "[28114251.20996682]\n",
            "[26119229.00670706]\n",
            "[37217609.14064145]\n",
            "[37443692.82621977]\n",
            "[37943794.42292785]\n",
            "[35812454.98508071]\n",
            "[36817582.25267707]\n",
            "[36817582.25267707]\n",
            "[30645388.8952045]\n",
            "[34695453.66995613]\n",
            "[25831745.69681176]\n",
            "[22505652.12100479]\n",
            "[22842410.58300274]\n",
            "[36840363.77229214]\n",
            "[25518808.14954366]\n",
            "[16900504.28603463]\n",
            "[28812515.17732009]\n",
            "[36573449.46113697]\n",
            "[19871526.11101412]\n",
            "[34193547.75465608]\n",
            "[32973493.95373362]\n",
            "[37285696.10301242]\n",
            "[26393174.74034771]\n",
            "[23343011.95093407]\n",
            "[16174462.84106788]\n",
            "[22735358.50239303]\n",
            "[31833633.44885039]\n",
            "[23089191.28723542]\n",
            "[25292342.71723189]\n",
            "[20438728.07732992]\n",
            "[16841105.41756821]\n",
            "[29041370.14451685]\n",
            "[34613552.47001322]\n",
            "[22909576.72630381]\n",
            "[36975345.05331853]\n",
            "[23331202.53674552]\n",
            "[22808081.88785036]\n",
            "[36982487.73357826]\n",
            "[22808081.88785036]\n",
            "[24907503.86263305]\n",
            "[36964015.63608373]\n",
            "[25523679.43615515]\n",
            "[36915664.21047833]\n",
            "[22798612.88710769]\n",
            "[26393174.74034771]\n",
            "[34681294.81621967]\n",
            "[31962588.29434368]\n",
            "[36621598.71399559]\n",
            "[29034883.34751992]\n",
            "[23277699.19699224]\n",
            "[31997222.59942001]\n",
            "[16604785.063147]\n",
            "[22781549.38936101]\n",
            "[33893232.6775896]\n",
            "[31606897.70177034]\n",
            "[37873719.4828944]\n",
            "[17036853.34037023]\n",
            "[22256809.70046797]\n",
            "[31004805.45505445]\n",
            "[25882117.86446958]\n",
            "[22781549.38936101]\n",
            "[31400439.0049847]\n",
            "Train : Episode 26/100 - Steps Count 7 - Avg Delay: [1.14747349], Avg Energy: [0.02305955], Avg Reward: [-0.27023877]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25045136.34460792]\n",
            "[27860102.32512784]\n",
            "[16834229.02308463]\n",
            "[36928338.18491662]\n",
            "[22942795.21241603]\n",
            "[22256809.70046797]\n",
            "[36915664.21047833]\n",
            "[19655691.13485715]\n",
            "[23341135.84376071]\n",
            "[22136985.5877244]\n",
            "[37943794.42292785]\n",
            "[32244871.45813281]\n",
            "[25989473.53424372]\n",
            "[26240178.90761231]\n",
            "[22517784.40940859]\n",
            "[36321884.43111597]\n",
            "[21875591.72601535]\n",
            "[31562214.62530965]\n",
            "[37257278.27234986]\n",
            "[25679099.1729515]\n",
            "[25108604.72222977]\n",
            "[34316164.12113251]\n",
            "[23286535.04379877]\n",
            "[37996574.52270168]\n",
            "[22722176.1513122]\n",
            "[20081844.66389205]\n",
            "[27864958.34607761]\n",
            "[23052214.43490182]\n",
            "[31547814.3765922]\n",
            "[17574226.5957548]\n",
            "[25482854.5712885]\n",
            "[23394898.93245357]\n",
            "Train : Episode 27/100 - Steps Count 3 - Avg Delay: [0.93713376], Avg Energy: [0.02397989], Avg Reward: [-0.29835452]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22192157.07729078]\n",
            "[19741483.1253228]\n",
            "[22909576.72630381]\n",
            "[23005497.67703338]\n",
            "[23364693.31938214]\n",
            "[37183179.85403487]\n",
            "[31101353.56779106]\n",
            "[17219082.61077759]\n",
            "[26119229.00670706]\n",
            "[28828509.80725035]\n",
            "[20150807.56036289]\n",
            "[17360017.44078583]\n",
            "[24959274.27382637]\n",
            "[28752368.06046123]\n",
            "[23308849.2373062]\n",
            "[22109576.72630381]\n",
            "[22974286.97587965]\n",
            "[17141952.75056796]\n",
            "[28127027.47376122]\n",
            "[32973493.95373362]\n",
            "[16906321.079408]\n",
            "[28734737.72659854]\n",
            "[28968567.4833934]\n",
            "[22861370.92014445]\n",
            "[33268605.81153142]\n",
            "[34330166.31026895]\n",
            "[33657853.75784943]\n",
            "[26059923.51100958]\n",
            "[25329938.61557813]\n",
            "[29051025.92703869]\n",
            "[23421170.22651744]\n",
            "Train : Episode 28/100 - Steps Count 3 - Avg Delay: [0.856749], Avg Energy: [0.02493239], Avg Reward: [-0.29998269]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37018431.58976579]\n",
            "[25026648.25438679]\n",
            "[37905513.52504303]\n",
            "[23089191.28723542]\n",
            "[23222791.65811059]\n",
            "[30933952.98995384]\n",
            "[17176004.77788424]\n",
            "[36347484.43972605]\n",
            "[23269262.6569858]\n",
            "[22806321.84884968]\n",
            "[31377987.62431901]\n",
            "[37381803.7129907]\n",
            "[26119229.00670706]\n",
            "[17219082.61077759]\n",
            "[37943794.42292785]\n",
            "Train : Episode 29/100 - Steps Count 1 - Avg Delay: [1.75526041], Avg Energy: [0.01194478], Avg Reward: [-0.3303667]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26240178.90761231]\n",
            "[37381803.7129907]\n",
            "[25893347.99273708]\n",
            "[37494422.05144375]\n",
            "[21889458.19665842]\n",
            "[37905513.52504303]\n",
            "[31456696.94715703]\n",
            "[31288479.46918773]\n",
            "[22664420.18757814]\n",
            "[22664420.18757814]\n",
            "Train : Episode 30/100 - Steps Count 1 - Avg Delay: [0.81962029], Avg Energy: [0.02300708], Avg Reward: [-0.2738267]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30989899.09935594]\n",
            "[25383685.10363292]\n",
            "[16634281.69064251]\n",
            "[22594303.98029579]\n",
            "[21767118.21268075]\n",
            "[37234824.89366734]\n",
            "[36817582.25267707]\n",
            "[17219082.61077759]\n",
            "[25831745.69681176]\n",
            "[28594674.15539626]\n",
            "[22734933.76928626]\n",
            "[35529350.37122569]\n",
            "[37290915.01379385]\n",
            "[24959274.27382637]\n",
            "[35895509.11273015]\n",
            "[34879247.34760421]\n",
            "[34948942.01984465]\n",
            "[28971553.06201597]\n",
            "[19832096.64237217]\n",
            "[29007659.45550874]\n",
            "[22040862.84595991]\n",
            "[36172697.10044441]\n",
            "[22752320.66518419]\n",
            "[37943794.42292785]\n",
            "[22752320.66518419]\n",
            "[32023590.90493482]\n",
            "[30905556.1720572]\n",
            "[32786432.50921661]\n",
            "Train : Episode 31/100 - Steps Count 3 - Avg Delay: [1.21917536], Avg Energy: [0.01639935], Avg Reward: [-0.29440424]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[24890041.30376846]\n",
            "[36904703.3278506]\n",
            "[25783022.24361547]\n",
            "[16846055.00355843]\n",
            "[31456696.94715703]\n",
            "[20324784.81851898]\n",
            "[20150807.56036289]\n",
            "[37653310.00221647]\n",
            "[19871526.11101412]\n",
            "[20217155.58502783]\n",
            "[17176004.77788424]\n",
            "[17503581.52471655]\n",
            "[22551598.92810344]\n",
            "[17355570.97724924]\n",
            "[25518808.14954366]\n",
            "[30989899.09935594]\n",
            "[34280338.58110063]\n",
            "[31698058.22156641]\n",
            "[31698058.22156641]\n",
            "[27621685.46767512]\n",
            "[35012392.61798893]\n",
            "[37495375.11244632]\n",
            "[25599308.61501873]\n",
            "[29425302.65473899]\n",
            "[16852364.88437666]\n",
            "[19592742.24065392]\n",
            "[32115166.61694153]\n",
            "[31377987.62431901]\n",
            "[37710678.98549479]\n",
            "[20179774.23507119]\n",
            "[20109628.80572335]\n",
            "[20474039.88882665]\n",
            "[22192157.07729078]\n",
            "[19722271.46976149]\n",
            "[36133783.11104792]\n",
            "[36593087.07730455]\n",
            "[25682026.60761308]\n",
            "[22201937.08113873]\n",
            "[17521890.35473581]\n",
            "[37558192.04523374]\n",
            "[16837703.26217629]\n",
            "[22838825.62147018]\n",
            "[23208329.77823527]\n",
            "[22817521.12367465]\n",
            "[19606701.46227572]\n",
            "[36492401.61305869]\n",
            "[28517748.6331097]\n",
            "[19606701.46227572]\n",
            "[20412336.47722148]\n",
            "[23057104.75868086]\n",
            "[34814272.60515618]\n",
            "[22381609.34562472]\n",
            "[22600234.31870084]\n",
            "[34464571.47214413]\n",
            "[31795962.36788084]\n",
            "[29061480.05373486]\n",
            "[36693090.25627708]\n",
            "[17574226.5957548]\n",
            "[31553211.76362581]\n",
            "[29078383.47065892]\n",
            "[17456595.86925204]\n",
            "[17110945.86679634]\n",
            "[23229596.87922539]\n",
            "[26244710.3418093]\n",
            "[37650973.15710919]\n",
            "[34845776.05734305]\n",
            "[22752320.66518419]\n",
            "[37352188.03769341]\n",
            "[22995354.19359219]\n",
            "[19767530.8677337]\n",
            "[31562214.62530965]\n",
            "[37408157.28463072]\n",
            "[29245983.08748277]\n",
            "[37905513.52504303]\n",
            "[17333404.64871889]\n",
            "[23267204.18306609]\n",
            "[21889458.19665842]\n",
            "[22689167.61542506]\n",
            "[24809107.01122145]\n",
            "[21549968.85280308]\n",
            "[37266050.00963596]\n",
            "[37696944.62243893]\n",
            "[17333404.64871889]\n",
            "[23300347.98405902]\n",
            "[37000339.12021171]\n",
            "[22700219.48317924]\n",
            "[29090563.90199378]\n",
            "[29090563.90199378]\n",
            "[36944665.80921774]\n",
            "[23341135.84376071]\n",
            "[16288016.328044]\n",
            "[22840972.52447518]\n",
            "[26283308.16772587]\n",
            "[22481756.75743707]\n",
            "[17101390.61173077]\n",
            "[22703707.7605507]\n",
            "[29179807.46749961]\n",
            "[37696944.62243893]\n",
            "[34174211.92385018]\n",
            "Train : Episode 32/100 - Steps Count 10 - Avg Delay: [0.9784521], Avg Energy: [0.01999773], Avg Reward: [-0.27097618]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30933952.98995384]\n",
            "[20345943.32335969]\n",
            "[25518808.14954366]\n",
            "[37537220.01035793]\n",
            "[17141952.75056796]\n",
            "[25996841.63935604]\n",
            "[26051904.23504078]\n",
            "[31566178.90721865]\n",
            "[31288479.46918773]\n",
            "[17391361.80924979]\n",
            "[23055105.21767381]\n",
            "[17244968.86356172]\n",
            "[30905885.76416366]\n",
            "[20162182.88519016]\n",
            "[23222791.65811059]\n",
            "[22695889.45063569]\n",
            "[36974466.4237968]\n",
            "[25694355.66243868]\n",
            "[22549269.19981421]\n",
            "[37729660.21154652]\n",
            "[23203625.89104791]\n",
            "[37073099.72041079]\n",
            "[37166435.02501307]\n",
            "[17242528.32095441]\n",
            "[21889458.19665842]\n",
            "[34600521.73552445]\n",
            "[22364218.41669537]\n",
            "[20182051.12869687]\n",
            "[23014173.62271396]\n",
            "[37813738.55094817]\n",
            "[28938121.80201838]\n",
            "[25600653.36644475]\n",
            "[22438825.62147018]\n",
            "[22752320.66518419]\n",
            "[37791854.38778247]\n",
            "[17390214.14247523]\n",
            "[17275532.74776749]\n",
            "[26077176.10213316]\n",
            "[32178832.61118336]\n",
            "[34866495.46773344]\n",
            "[28517748.6331097]\n",
            "[33328678.18895999]\n",
            "[30041607.62952571]\n",
            "[37266050.00963596]\n",
            "[23357914.51627679]\n",
            "[23032398.65366614]\n",
            "[34802544.99457265]\n",
            "[23315956.46418392]\n",
            "[22864077.81258375]\n",
            "Train : Episode 33/100 - Steps Count 5 - Avg Delay: [0.937281], Avg Energy: [0.02450337], Avg Reward: [-0.27544065]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34695453.66995613]\n",
            "[34445070.91529737]\n",
            "[34393295.41979598]\n",
            "[25831745.69681176]\n",
            "[30104720.5499108]\n",
            "[37151265.98678192]\n",
            "[23141171.40343641]\n",
            "[38088349.49679654]\n",
            "[34712478.15206096]\n",
            "[26150861.14477431]\n",
            "[22664420.18757814]\n",
            "[23291615.95642512]\n",
            "Train : Episode 34/100 - Steps Count 1 - Avg Delay: [1.04513934], Avg Energy: [0.02415412], Avg Reward: [-0.3585326]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31377987.62431901]\n",
            "[26150861.14477431]\n",
            "[36300348.09089724]\n",
            "[31566178.90721865]\n",
            "[17260664.18224645]\n",
            "[23346538.87102699]\n",
            "[19787418.71197018]\n",
            "[22942795.21241603]\n",
            "[25946744.39415146]\n",
            "[17141952.75056796]\n",
            "[17468661.81478284]\n",
            "[21889458.19665842]\n",
            "[37381803.7129907]\n",
            "[31925387.00006223]\n",
            "Train : Episode 35/100 - Steps Count 1 - Avg Delay: [0.89616975], Avg Energy: [0.02039401], Avg Reward: [-0.36057589]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19055062.49932794]\n",
            "[33393498.66909074]\n",
            "[31589140.8642997]\n",
            "[22973052.53303035]\n",
            "[35343838.92896523]\n",
            "[34814272.60515618]\n",
            "[20324784.81851898]\n",
            "[19871526.11101412]\n",
            "[36772249.46500327]\n",
            "[25033615.83983283]\n",
            "[37905513.52504303]\n",
            "[21875591.72601535]\n",
            "[22863385.83933584]\n",
            "[25026648.25438679]\n",
            "[36982487.73357826]\n",
            "Train : Episode 36/100 - Steps Count 1 - Avg Delay: [2.50608689], Avg Energy: [0.01608587], Avg Reward: [-0.46859195]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37329468.35312783]\n",
            "[20345943.32335969]\n",
            "[21767118.21268075]\n",
            "[19930348.80568579]\n",
            "[21767118.21268075]\n",
            "[34393295.41979598]\n",
            "[37173268.89776052]\n",
            "[31101353.56779106]\n",
            "[20236714.72203723]\n",
            "[28304404.55035065]\n",
            "[28966063.42631754]\n",
            "[20447009.26497448]\n",
            "[17480698.16878441]\n",
            "[32101176.86387233]\n",
            "[31377987.62431901]\n",
            "[17383306.12722194]\n",
            "[25946877.54878111]\n",
            "[34695453.66995613]\n",
            "[22806321.84884968]\n",
            "[34695453.66995613]\n",
            "[17275532.74776749]\n",
            "Train : Episode 37/100 - Steps Count 2 - Avg Delay: [0.71527601], Avg Energy: [0.02103985], Avg Reward: [-0.25985036]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37761715.18573044]\n",
            "[31377987.62431901]\n",
            "[20345943.32335969]\n",
            "[31566178.90721865]\n",
            "[17543569.96823049]\n",
            "[23221850.92200008]\n",
            "[31268233.01949177]\n",
            "[19527736.53580739]\n",
            "[16704593.47681655]\n",
            "[21767118.21268075]\n",
            "[20182943.3988153]\n",
            "[27359069.87951583]\n",
            "[36276203.74346998]\n",
            "[34564516.98360153]\n",
            "[34257170.86614149]\n",
            "[20342408.1285224]\n",
            "[37943794.42292785]\n",
            "[33523428.88509949]\n",
            "[21935358.50239303]\n",
            "[20199747.62916119]\n",
            "[23052838.10766977]\n",
            "[36276203.74346998]\n",
            "Train : Episode 38/100 - Steps Count 2 - Avg Delay: [1.0323883], Avg Energy: [0.01441315], Avg Reward: [-0.33362736]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23124779.70104489]\n",
            "[27603991.60608585]\n",
            "[33393498.66909074]\n",
            "[17503581.52471655]\n",
            "[32178832.61118336]\n",
            "[25679099.1729515]\n",
            "[37729660.21154652]\n",
            "[31018924.79733403]\n",
            "[33393498.66909074]\n",
            "[22109576.72630381]\n",
            "[17603315.11472093]\n",
            "[30989899.09935594]\n",
            "[37729660.21154652]\n",
            "[37726693.8202557]\n",
            "[20236714.72203723]\n",
            "Train : Episode 39/100 - Steps Count 1 - Avg Delay: [2.66115966], Avg Energy: [0.01268007], Avg Reward: [-0.44867456]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36817582.25267707]\n",
            "[37220230.76551127]\n",
            "[19677731.64264556]\n",
            "[35186196.80449704]\n",
            "[36817582.25267707]\n",
            "[20447009.26497448]\n",
            "[31589140.8642997]\n",
            "[31101353.56779106]\n",
            "[28908130.30188541]\n",
            "[22607511.32871297]\n",
            "[36136372.9888555]\n",
            "[37801334.76207839]\n",
            "[25831745.69681176]\n",
            "[17176004.77788424]\n",
            "[33495254.13641609]\n",
            "[36154991.81270356]\n",
            "[26119229.00670706]\n",
            "[28444182.63898576]\n",
            "[29143440.50290697]\n",
            "[17244968.86356172]\n",
            "[28657655.52604446]\n",
            "[37506913.88576131]\n",
            "Train : Episode 40/100 - Steps Count 2 - Avg Delay: [0.87783735], Avg Energy: [0.01525817], Avg Reward: [-0.27749965]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35012392.61798893]\n",
            "[29119679.57029104]\n",
            "[23019398.28243497]\n",
            "[17244968.86356172]\n",
            "[37537220.01035793]\n",
            "[20447009.26497448]\n",
            "[23082773.89107458]\n",
            "[28285967.23983448]\n",
            "[29143440.50290697]\n",
            "[16900504.28603463]\n",
            "[36525624.54530405]\n",
            "[22894131.58299772]\n",
            "[22505652.12100479]\n",
            "[16900504.28603463]\n",
            "Train : Episode 41/100 - Steps Count 1 - Avg Delay: [0.83331877], Avg Energy: [0.01518076], Avg Reward: [-0.35529979]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[16895778.92344718]\n",
            "[25831745.69681176]\n",
            "[35186196.80449704]\n",
            "[20043476.09198097]\n",
            "[32178832.61118336]\n",
            "[33445986.08730524]\n",
            "[30933952.98995384]\n",
            "[31566178.90721865]\n",
            "[23183876.45562875]\n",
            "[37183179.85403487]\n",
            "[19527736.53580739]\n",
            "[37888798.74227113]\n",
            "[29223201.79879255]\n",
            "[25470510.62158091]\n",
            "[32191542.50669491]\n",
            "[33779643.60638414]\n",
            "[27810580.50601654]\n",
            "[34845776.05734305]\n",
            "[31288479.46918773]\n",
            "[35626943.54282025]\n",
            "[24534779.83428265]\n",
            "[22973052.53303035]\n",
            "[33144735.28505097]\n",
            "[19861855.72672921]\n",
            "[37334828.07263988]\n",
            "[28908130.30188541]\n",
            "[20406614.11154681]\n",
            "[35186196.80449704]\n",
            "[17283478.92092587]\n",
            "[22643803.63786399]\n",
            "[33912884.58798402]\n",
            "[20174453.05358768]\n",
            "[22712725.09104648]\n",
            "[30775326.29289488]\n",
            "[16841105.41756821]\n",
            "[25910128.28655551]\n",
            "[32000836.85163995]\n",
            "[22432511.00584212]\n",
            "[25793641.38391782]\n",
            "[25910128.28655551]\n",
            "[37344241.26155248]\n",
            "[23218229.43461335]\n",
            "[29145785.63687367]\n",
            "[17406148.59116868]\n",
            "[33827240.48471436]\n",
            "[37289993.86145746]\n",
            "[20107548.83920519]\n",
            "[20308445.82322025]\n",
            "[37961300.81769423]\n",
            "[34174211.92385018]\n",
            "[16758415.08478418]\n",
            "[25183190.60206291]\n",
            "[37773828.19691648]\n",
            "[27949754.56884873]\n",
            "[26283811.68606151]\n",
            "Train : Episode 42/100 - Steps Count 5 - Avg Delay: [1.13810693], Avg Energy: [0.01953068], Avg Reward: [-0.29339605]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28114251.20996682]\n",
            "[31566178.90721865]\n",
            "[23346538.87102699]\n",
            "[34627730.59679951]\n",
            "[28908130.30188541]\n",
            "[19369376.29548629]\n",
            "[31101353.56779106]\n",
            "[26273192.54575916]\n",
            "[33560459.13488301]\n",
            "[36321884.43111597]\n",
            "[37166435.02501307]\n",
            "[24890041.30376846]\n",
            "[23327668.66642797]\n",
            "[24890041.30376846]\n",
            "[16634281.69064251]\n",
            "[22981335.38921884]\n",
            "[37494422.05144375]\n",
            "[25035590.87432038]\n",
            "[37905513.52504303]\n",
            "[19974784.81851898]\n",
            "[31789462.41523342]\n",
            "[28475400.25791096]\n",
            "[19974784.81851898]\n",
            "[28452614.08716094]\n",
            "[22974286.97587965]\n",
            "[37707189.96702443]\n",
            "[37707189.96702443]\n",
            "[31334298.31805529]\n",
            "[25876877.84313171]\n",
            "[31668514.99334907]\n",
            "[17037150.81385]\n",
            "[37344710.26682355]\n",
            "[17306488.02662431]\n",
            "[17290700.19863489]\n",
            "[31533247.20095491]\n",
            "[22537517.98010324]\n",
            "[20597217.53024061]\n",
            "[17442715.59482196]\n",
            "[35979070.87924019]\n",
            "[37710653.9999494]\n",
            "[36300348.09089724]\n",
            "[16634281.69064251]\n",
            "[22429657.09549207]\n",
            "[17378603.58678089]\n",
            "[31269571.04576036]\n",
            "[23453047.19823602]\n",
            "[28226409.85909729]\n",
            "[33965707.76945423]\n",
            "[37404328.64659457]\n",
            "[23298834.56303016]\n",
            "[25165243.03140631]\n",
            "[34645305.01606011]\n",
            "[20147997.37763443]\n",
            "[20390902.51418559]\n",
            "[17294783.38078358]\n",
            "[20150311.55525868]\n",
            "[19617425.37111087]\n",
            "[35098631.31815562]\n",
            "[20398311.05123295]\n",
            "[22753342.94408209]\n",
            "[36714075.60965148]\n",
            "[20197414.67137782]\n",
            "[22409818.63757552]\n",
            "[23257714.33528516]\n",
            "[24803472.36492909]\n",
            "[36714075.60965148]\n",
            "[22643803.63786399]\n",
            "[22154353.62051403]\n",
            "[31274177.36127323]\n",
            "[34845776.05734305]\n",
            "[17355570.97724924]\n",
            "[34693183.18453411]\n",
            "[31305682.03825948]\n",
            "Train : Episode 43/100 - Steps Count 8 - Avg Delay: [0.81600264], Avg Energy: [0.01974478], Avg Reward: [-0.24658818]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30775326.29289488]\n",
            "[23141171.40343641]\n",
            "[25108604.72222977]\n",
            "[25996841.63935604]\n",
            "[23089191.28723542]\n",
            "[20109628.80572335]\n",
            "[35012392.61798893]\n",
            "[31288479.46918773]\n",
            "[20613684.53072216]\n",
            "[22909576.72630381]\n",
            "[31825982.29518522]\n",
            "[31762713.28884543]\n",
            "[19399435.15209783]\n",
            "[17412914.27257797]\n",
            "[28195681.11701357]\n",
            "[31001176.86387233]\n",
            "[37583148.35138191]\n",
            "[31527297.25707781]\n",
            "[17434183.86088461]\n",
            "[23122280.0830879]\n",
            "[19974784.81851898]\n",
            "[23386125.4513474]\n",
            "[28292248.84245216]\n",
            "[23386125.4513474]\n",
            "[37494422.05144375]\n",
            "[28907421.52968631]\n",
            "[20054713.69874813]\n",
            "[26329293.10901235]\n",
            "[17141952.75056796]\n",
            "[24959274.27382637]\n",
            "[34600521.73552445]\n",
            "[31993270.31041641]\n",
            "[28190926.59842022]\n",
            "[20211876.43956328]\n",
            "[31395744.46178966]\n",
            "[37117919.80443277]\n",
            "[37038519.25028561]\n",
            "Train : Episode 44/100 - Steps Count 4 - Avg Delay: [0.8176977], Avg Energy: [0.02645616], Avg Reward: [-0.29078737]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26159656.85271195]\n",
            "[31288479.46918773]\n",
            "[37234824.89366734]\n",
            "[23269262.6569858]\n",
            "[36915664.21047833]\n",
            "[31930132.15414155]\n",
            "[24890041.30376846]\n",
            "[31018924.79733403]\n",
            "[33495254.13641609]\n",
            "[36777189.57532506]\n",
            "[34691788.17508804]\n",
            "[34600521.73552445]\n",
            "[37060653.9999494]\n",
            "[20236714.72203723]\n",
            "[37060653.9999494]\n",
            "[31160584.49184104]\n",
            "[30856018.15059636]\n",
            "[28610816.73491503]\n",
            "[23221850.92200008]\n",
            "[37352188.03769341]\n",
            "[22753342.94408209]\n",
            "[31084219.9051888]\n",
            "[23247658.61489594]\n",
            "[19583433.32774355]\n",
            "[31589140.8642997]\n",
            "[26129099.1729515]\n",
            "[37943794.42292785]\n",
            "[30616163.63745268]\n",
            "[30921861.39080913]\n",
            "[22198526.00555366]\n",
            "[29143440.50290697]\n",
            "[28190926.59842022]\n",
            "[19994343.61766482]\n",
            "[22528005.42044411]\n",
            "[21889458.19665842]\n",
            "[19583433.32774355]\n",
            "Train : Episode 45/100 - Steps Count 3 - Avg Delay: [0.77330987], Avg Energy: [0.01187872], Avg Reward: [-0.2418187]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37537220.01035793]\n",
            "[29179807.46749961]\n",
            "[30775326.29289488]\n",
            "[22914352.17637786]\n",
            "[26009116.75135473]\n",
            "[29143440.50290697]\n",
            "[20236714.72203723]\n",
            "[20309916.81286342]\n",
            "[25694355.66243868]\n",
            "[34695453.66995613]\n",
            "[30989899.09935594]\n",
            "[37151265.98678192]\n",
            "[31101353.56779106]\n",
            "[37841003.8937868]\n",
            "[32138916.66526449]\n",
            "[25681587.65899175]\n",
            "[28565327.24962986]\n",
            "[34664002.31938358]\n",
            "[28226409.85909729]\n",
            "[20150807.56036289]\n",
            "[32138916.66526449]\n",
            "[28226409.85909729]\n",
            "[31530565.77589206]\n",
            "[22443033.15551919]\n",
            "[35626943.54282025]\n",
            "[22525779.83725657]\n",
            "[20138644.53063649]\n",
            "[17043932.76723846]\n",
            "[31535454.92615516]\n",
            "[37572611.06997248]\n",
            "[36904410.56254864]\n",
            "[20479370.62912916]\n",
            "[19443844.12375488]\n",
            "[17352765.25137783]\n",
            "[17383756.95090085]\n",
            "[25744757.98311253]\n",
            "[35067315.14531628]\n",
            "[27489444.26493109]\n",
            "[33495465.20388322]\n",
            "[25719503.12430791]\n",
            "[22931355.83991276]\n",
            "[31590859.24603803]\n",
            "[34326848.80706163]\n",
            "[28565445.81165361]\n",
            "[19443844.12375488]\n",
            "[30173776.39945189]\n",
            "[37312040.6170445]\n",
            "[19845002.75973348]\n",
            "[30634109.46193054]\n",
            "[19337730.84591443]\n",
            "[22700219.48317924]\n",
            "[24638776.78075727]\n",
            "[17141105.41756821]\n",
            "[17098148.24348633]\n",
            "[19592742.24065392]\n",
            "[22264385.97554751]\n",
            "[16852364.88437666]\n",
            "[34572969.239888]\n",
            "[35977982.91723611]\n",
            "[23141171.40343641]\n",
            "[20162182.88519016]\n",
            "[22394960.57762029]\n",
            "[37355813.42601428]\n",
            "[19840365.53609677]\n",
            "[17319194.11918087]\n",
            "[34572969.239888]\n",
            "[20316122.61918814]\n",
            "[16893827.30033946]\n",
            "[37905513.52504303]\n",
            "[34853397.42628258]\n",
            "Train : Episode 46/100 - Steps Count 6 - Avg Delay: [0.73199457], Avg Energy: [0.02138665], Avg Reward: [-0.27211865]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36817582.25267707]\n",
            "[34399183.4783781]\n",
            "[34330166.31026895]\n",
            "[21767118.21268075]\n",
            "[34521241.84326933]\n",
            "[20109628.80572335]\n",
            "[23089191.28723542]\n",
            "[28964107.91521946]\n",
            "[22493842.96436937]\n",
            "[35812454.98508071]\n",
            "[23346538.87102699]\n",
            "[23327668.66642797]\n",
            "[37943794.42292785]\n",
            "[17243911.41408446]\n",
            "[17503581.52471655]\n",
            "[27788032.82379104]\n",
            "[19677731.64264556]\n",
            "[28114251.20996682]\n",
            "[35036551.03400792]\n",
            "[31966521.18402843]\n",
            "[31921631.1851596]\n",
            "[19369376.29548629]\n",
            "[22509121.46516518]\n",
            "[22357428.19723534]\n",
            "[31377987.62431901]\n",
            "[22357428.19723534]\n",
            "[37813738.55094817]\n",
            "[28346655.39889446]\n",
            "[22864077.81258375]\n",
            "[25478637.84739997]\n",
            "[29152583.57548841]\n",
            "[25180263.16740132]\n",
            "[23200438.35867127]\n",
            "Train : Episode 47/100 - Steps Count 3 - Avg Delay: [0.72423128], Avg Energy: [0.01385613], Avg Reward: [-0.28730764]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26273192.54575916]\n",
            "[22664420.18757814]\n",
            "[37220218.27042358]\n",
            "[23269262.6569858]\n",
            "[30989899.09935594]\n",
            "[36777189.57532506]\n",
            "[37183179.85403487]\n",
            "[34600521.73552445]\n",
            "[25679099.1729515]\n",
            "[37204879.51220907]\n",
            "[23221850.92200008]\n",
            "Train : Episode 48/100 - Steps Count 1 - Avg Delay: [0.92103623], Avg Energy: [0.01459019], Avg Reward: [-0.31096577]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26329293.10901235]\n",
            "[16632501.42049318]\n",
            "[37334828.07263988]\n",
            "[23298834.56303016]\n",
            "[23056124.95495202]\n",
            "[33495254.13641609]\n",
            "[32000836.85163995]\n",
            "[37334828.07263988]\n",
            "[37905513.52504303]\n",
            "[28906368.56194376]\n",
            "[36964015.63608373]\n",
            "[36136372.9888555]\n",
            "[31373600.70003401]\n",
            "[20236714.72203723]\n",
            "[23046421.7032633]\n",
            "[34996963.58773793]\n",
            "[23008022.63718517]\n",
            "[17260664.18224645]\n",
            "[23099028.99463775]\n",
            "[37266050.00963596]\n",
            "[32191542.50669491]\n",
            "[16841105.41756821]\n",
            "[37312040.6170445]\n",
            "[20395314.30588368]\n",
            "[16653801.27876259]\n",
            "[26236123.10336099]\n",
            "[37634918.84616083]\n",
            "[31084219.9051888]\n",
            "[23181274.29148512]\n",
            "[30381957.79224144]\n",
            "[30546715.94726384]\n",
            "[29354679.6920211]\n",
            "[16810158.25778851]\n",
            "[23218229.43461335]\n",
            "[19527736.53580739]\n",
            "[20436491.04843992]\n",
            "[32178730.7712034]\n",
            "[34853397.42628258]\n",
            "[21549968.85280308]\n",
            "[31979500.13328685]\n",
            "[36864741.43084024]\n",
            "[31453894.09472608]\n",
            "[28514983.64862052]\n",
            "[37506913.88576131]\n",
            "[22975900.28349184]\n",
            "[37523229.42861345]\n",
            "[37580606.18695441]\n",
            "[35839685.52188017]\n",
            "[27799974.42791928]\n",
            "[17452703.79105388]\n",
            "[23491831.89019086]\n",
            "[37285696.10301242]\n",
            "[31553211.76362581]\n",
            "[28296934.09121719]\n",
            "[22184868.10709285]\n",
            "[22838825.62147018]\n",
            "[28283218.59154208]\n",
            "[37828178.49937137]\n",
            "[23491831.89019086]\n",
            "[36507859.52250478]\n",
            "[36693090.25627708]\n",
            "[37710678.98549479]\n",
            "[36745956.36260124]\n",
            "[34600521.73552445]\n",
            "[32191542.50669491]\n",
            "[20147997.37763443]\n",
            "[19891885.55899165]\n",
            "[28444182.63898576]\n",
            "[37537220.01035793]\n",
            "[28114550.83915451]\n",
            "[29306110.98469133]\n",
            "[37344710.26682355]\n",
            "[28201179.11161693]\n",
            "[22642066.88813881]\n",
            "[33887555.99644681]\n",
            "[17242528.32095441]\n",
            "[37344710.26682355]\n",
            "[33887555.99644681]\n",
            "Train : Episode 49/100 - Steps Count 8 - Avg Delay: [0.90507028], Avg Energy: [0.02195913], Avg Reward: [-0.2728642]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23269262.6569858]\n",
            "[23221850.92200008]\n",
            "[37602157.21120273]\n",
            "[36717508.73248485]\n",
            "[31562214.62530965]\n",
            "[27860102.32512784]\n",
            "[19955573.88327515]\n",
            "[17244968.86356172]\n",
            "[26009116.75135473]\n",
            "[20217155.58502783]\n",
            "[25683644.42345658]\n",
            "[36136372.9888555]\n",
            "[26009116.75135473]\n",
            "[28190926.59842022]\n",
            "[28195681.11701357]\n",
            "Train : Episode 50/100 - Steps Count 1 - Avg Delay: [0.91095788], Avg Energy: [0.01592113], Avg Reward: [-0.33349875]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35812454.98508071]\n",
            "[34530566.86658172]\n",
            "[31373600.70003401]\n",
            "[37234824.89366734]\n",
            "[21724187.07671386]\n",
            "[36915664.21047833]\n",
            "[35012392.61798893]\n",
            "[30571518.3977119]\n",
            "[24959274.27382637]\n",
            "[31589140.8642997]\n",
            "[25859468.61047201]\n",
            "Train : Episode 51/100 - Steps Count 1 - Avg Delay: [1.53086397], Avg Energy: [0.01331637], Avg Reward: [-0.31030178]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25045136.34460792]\n",
            "[26051904.23504078]\n",
            "[34399183.4783781]\n",
            "[22684039.11247029]\n",
            "[17141952.75056796]\n",
            "[20324784.81851898]\n",
            "[25274515.11968128]\n",
            "[24963111.73385957]\n",
            "[29223201.79879255]\n",
            "[36465943.70246384]\n",
            "[16790613.43675935]\n",
            "[25387519.56456906]\n",
            "[28949920.84679877]\n",
            "[17487247.18950984]\n",
            "[30447796.25637305]\n",
            "[19930348.80568579]\n",
            "[17543569.96823049]\n",
            "[26150861.14477431]\n",
            "[37943794.42292785]\n",
            "[36354321.68255569]\n",
            "[23076277.2236204]\n",
            "[31645774.42217942]\n",
            "[28831810.56094465]\n",
            "[31969574.54920492]\n",
            "[17246036.12027198]\n",
            "[22981335.38921884]\n",
            "[22493842.96436937]\n",
            "[37506913.88576131]\n",
            "[28642750.12772002]\n",
            "[28828509.80725035]\n",
            "[36772249.46500327]\n",
            "[25311621.60055093]\n",
            "[22256809.70046797]\n",
            "[37600443.89589233]\n",
            "[34540134.32825678]\n",
            "[22862798.75598498]\n",
            "[30575493.22402338]\n",
            "[23345893.69738015]\n",
            "Train : Episode 52/100 - Steps Count 4 - Avg Delay: [0.86855345], Avg Energy: [0.01892008], Avg Reward: [-0.26978864]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31377987.62431901]\n",
            "[36136372.9888555]\n",
            "[16798193.21068411]\n",
            "[25430340.31943722]\n",
            "[19055062.49932794]\n",
            "[17383306.12722194]\n",
            "[37494422.05144375]\n",
            "[37943794.42292785]\n",
            "[31704767.47674729]\n",
            "[37619900.55308715]\n",
            "[19677731.64264556]\n",
            "[26159656.85271195]\n",
            "[37355813.42601428]\n",
            "[29064163.91409667]\n",
            "[26159656.85271195]\n",
            "[37355813.42601428]\n",
            "[25616270.32937485]\n",
            "[35977982.91723611]\n",
            "Train : Episode 53/100 - Steps Count 2 - Avg Delay: [6.10477798], Avg Energy: [0.0136994], Avg Reward: [-0.20035973]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25518808.14954366]\n",
            "[20309916.81286342]\n",
            "[16906321.079408]\n",
            "[37943794.42292785]\n",
            "[24963111.73385957]\n",
            "[25518808.14954366]\n",
            "[25045136.34460792]\n",
            "[22918614.06402665]\n",
            "[20460255.02963385]\n",
            "[28189371.97228298]\n",
            "[28737254.00449485]\n",
            "[26329293.10901235]\n",
            "[23221850.92200008]\n",
            "[22594303.98029579]\n",
            "[25946744.39415146]\n",
            "[25909446.35870291]\n",
            "[26273192.54575916]\n",
            "[20306795.11514165]\n",
            "[23394641.18879384]\n",
            "[37707189.96702443]\n",
            "[20562579.27246025]\n",
            "[25356481.31169487]\n",
            "[23144114.20183729]\n",
            "[34387976.57547317]\n",
            "[22909576.72630381]\n",
            "[21767118.21268075]\n",
            "[23226229.54487954]\n",
            "[17125127.04422157]\n",
            "[37344241.26155248]\n",
            "[28752841.89730657]\n",
            "[30173776.39945189]\n",
            "Train : Episode 54/100 - Steps Count 3 - Avg Delay: [0.88238301], Avg Energy: [0.02104248], Avg Reward: [-0.25579583]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35812454.98508071]\n",
            "[23346538.87102699]\n",
            "[32178832.61118336]\n",
            "[20324784.81851898]\n",
            "[25783707.83748036]\n",
            "[31589140.8642997]\n",
            "[29064163.91409667]\n",
            "[30104720.5499108]\n",
            "[16632501.42049318]\n",
            "[37841003.8937868]\n",
            "[16834229.02308463]\n",
            "[31377987.62431901]\n",
            "[35181164.28422294]\n",
            "Train : Episode 55/100 - Steps Count 1 - Avg Delay: [1.38339249], Avg Energy: [0.02116454], Avg Reward: [-0.34947101]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23089191.28723542]\n",
            "[24890041.30376846]\n",
            "[30952051.13526261]\n",
            "[18865056.80943498]\n",
            "[37943794.42292785]\n",
            "[37776611.57367409]\n",
            "[36817582.25267707]\n",
            "[23141171.40343641]\n",
            "[20345943.32335969]\n",
            "[37726693.8202557]\n",
            "[25946744.39415146]\n",
            "[25783022.24361547]\n",
            "[20236714.72203723]\n",
            "Train : Episode 56/100 - Steps Count 1 - Avg Delay: [1.377201], Avg Energy: [0.01489417], Avg Reward: [-0.30473291]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23327668.66642797]\n",
            "[22109576.72630381]\n",
            "[29402521.36604876]\n",
            "[30775326.29289488]\n",
            "[26173344.11419477]\n",
            "[22198526.00555366]\n",
            "[22109576.72630381]\n",
            "[16634281.69064251]\n",
            "[30921861.39080913]\n",
            "[31768279.94632826]\n",
            "[17328879.66689213]\n",
            "[23124779.70104489]\n",
            "[37334828.07263988]\n",
            "[19677731.64264556]\n",
            "[33393498.66909074]\n",
            "Train : Episode 57/100 - Steps Count 1 - Avg Delay: [1.49886802], Avg Energy: [0.01689087], Avg Reward: [-0.38505641]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20111335.16712698]\n",
            "[34996963.58773793]\n",
            "[34695453.66995613]\n",
            "[37351917.85212491]\n",
            "[29119679.57029104]\n",
            "[26329293.10901235]\n",
            "[36717508.73248485]\n",
            "[31377987.62431901]\n",
            "[36817582.25267707]\n",
            "[37865603.17101134]\n",
            "[23423169.91142135]\n",
            "[37865603.17101134]\n",
            "[22753342.94408209]\n",
            "[20324784.81851898]\n",
            "[25311621.60055093]\n",
            "[29245983.08748277]\n",
            "[22840972.52447518]\n",
            "[37886846.66327654]\n",
            "[31535454.92615516]\n",
            "[36817582.25267707]\n",
            "[36777189.57532506]\n",
            "[34530566.86658172]\n",
            "[34005549.47492135]\n",
            "[30775326.29289488]\n",
            "[37546824.23979301]\n",
            "[37456080.74631358]\n",
            "[36172697.10044441]\n",
            "[34444220.62083302]\n",
            "[23311748.62664517]\n",
            "[35050728.35877694]\n",
            "[22734933.76928626]\n",
            "[17143794.13871763]\n",
            "[23096626.95985732]\n",
            "[34210171.62562238]\n",
            "[23311748.62664517]\n",
            "[34393295.41979598]\n",
            "[34572969.239888]\n",
            "[30989899.09935594]\n",
            "Train : Episode 58/100 - Steps Count 4 - Avg Delay: [0.59420395], Avg Energy: [0.01755326], Avg Reward: [-0.23525273]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30989899.09935594]\n",
            "[23346538.87102699]\n",
            "[20182943.3988153]\n",
            "[33393498.66909074]\n",
            "[20182943.3988153]\n",
            "[28908130.30188541]\n",
            "[31507783.07736909]\n",
            "[37018431.58976579]\n",
            "[34695453.66995613]\n",
            "[33445986.08730524]\n",
            "[32819011.24523446]\n",
            "[32191542.50669491]\n",
            "[23019398.28243497]\n",
            "[32973493.95373362]\n",
            "[36999320.3278922]\n",
            "[22929207.89836136]\n",
            "[26146859.25180593]\n",
            "[34110384.61171838]\n",
            "[32819011.24523446]\n",
            "[36699023.30895393]\n",
            "[20236714.72203723]\n",
            "[36172697.10044441]\n",
            "[20081496.51482954]\n",
            "[22838825.62147018]\n",
            "Train : Episode 59/100 - Steps Count 2 - Avg Delay: [1.21464046], Avg Energy: [0.0175701], Avg Reward: [-0.31045141]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23089191.28723542]\n",
            "[20120605.18798708]\n",
            "[20324784.81851898]\n",
            "[29143440.50290697]\n",
            "[25108604.72222977]\n",
            "[37000339.12021171]\n",
            "[36292469.48107947]\n",
            "[19741483.1253228]\n",
            "[23394641.18879384]\n",
            "[37416411.61460517]\n",
            "[35012392.61798893]\n",
            "[36717508.73248485]\n",
            "[36717508.73248485]\n",
            "[37905513.52504303]\n",
            "[37905332.08680747]\n",
            "[20167333.72659649]\n",
            "[35882218.0810269]\n",
            "[37637223.18933047]\n",
            "[25808503.57448549]\n",
            "[19867737.33253852]\n",
            "[30546715.94726384]\n",
            "[29064163.91409667]\n",
            "[25430340.31943722]\n",
            "[17304690.0694446]\n",
            "[36777917.91573191]\n",
            "[34883558.93560814]\n",
            "[28474923.00926818]\n",
            "[31748557.39627735]\n",
            "[17273038.80580893]\n",
            "[28577968.87779301]\n",
            "[29138405.57602143]\n",
            "[25694355.66243868]\n",
            "[38088349.49679654]\n",
            "[36817582.25267707]\n",
            "[28703029.02048374]\n",
            "[37321606.46537053]\n",
            "[31748557.39627735]\n",
            "[20479370.62912916]\n",
            "Train : Episode 60/100 - Steps Count 4 - Avg Delay: [3.40141107], Avg Energy: [0.01740389], Avg Reward: [-0.27738425]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[16634281.69064251]\n",
            "[33393498.66909074]\n",
            "[25831745.69681176]\n",
            "[23269262.6569858]\n",
            "[31930132.15414155]\n",
            "[20217155.58502783]\n",
            "[23394641.18879384]\n",
            "[23491831.89019086]\n",
            "[25946877.54878111]\n",
            "[30571915.24832588]\n",
            "[29143440.50290697]\n",
            "[34600521.73552445]\n",
            "[28341799.26304719]\n",
            "[20348078.58640571]\n",
            "[34501630.62966619]\n",
            "[24963111.73385957]\n",
            "[22974056.15931845]\n",
            "[33920834.11421838]\n",
            "Train : Episode 61/100 - Steps Count 2 - Avg Delay: [3.90201258], Avg Energy: [0.01327395], Avg Reward: [-0.2116204]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23221850.92200008]\n",
            "[35731950.36212119]\n",
            "[37776611.57367409]\n",
            "[30933952.98995384]\n",
            "[25045136.34460792]\n",
            "[37905332.08680747]\n",
            "[22995354.19359219]\n",
            "[34530566.86658172]\n",
            "[23221850.92200008]\n",
            "[28189371.97228298]\n",
            "[17199417.92088686]\n",
            "[34627730.59679951]\n",
            "[20324784.81851898]\n",
            "Train : Episode 62/100 - Steps Count 1 - Avg Delay: [0.86696962], Avg Energy: [0.01893491], Avg Reward: [-0.34672496]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34330166.31026895]\n",
            "[37018431.58976579]\n",
            "[22842410.58300274]\n",
            "[20447009.26497448]\n",
            "[29179807.46749961]\n",
            "[29179807.46749961]\n",
            "[31627897.30382799]\n",
            "[37351917.85212491]\n",
            "[36292469.48107947]\n",
            "[17244968.86356172]\n",
            "[25683644.42345658]\n",
            "[37943794.42292785]\n",
            "[25045136.34460792]\n",
            "Train : Episode 63/100 - Steps Count 1 - Avg Delay: [0.816394], Avg Energy: [0.01572233], Avg Reward: [-0.36269257]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28531935.30360627]\n",
            "[37537220.01035793]\n",
            "[23056938.4906387]\n",
            "[17176004.77788424]\n",
            "[20217155.58502783]\n",
            "[37000339.12021171]\n",
            "[33396526.42198326]\n",
            "[36172697.10044441]\n",
            "[37537220.01035793]\n",
            "[23423169.91142135]\n",
            "[32178832.61118336]\n",
            "[31886355.41331746]\n",
            "[37312040.6170445]\n",
            "[34879655.68939269]\n",
            "[33584111.09583062]\n",
            "[33393498.66909074]\n",
            "[34612035.97028542]\n",
            "[37443692.82621977]\n",
            "[32191542.50669491]\n",
            "[37612280.20168089]\n",
            "[34600521.73552445]\n",
            "[17273188.88610883]\n",
            "[20495837.62961071]\n",
            "[17352765.25137783]\n",
            "[23331202.53674552]\n",
            "[17076226.70035371]\n",
            "[37891203.62379798]\n",
            "[23331202.53674552]\n",
            "[22937981.37946752]\n",
            "[23221850.92200008]\n",
            "[34058613.34315765]\n",
            "[37661838.05404293]\n",
            "[33634083.62778194]\n",
            "[19985464.85211075]\n",
            "[35081567.85028093]\n",
            "[37905332.08680747]\n",
            "[27243517.71676625]\n",
            "[22818229.43461336]\n",
            "[34975552.29119044]\n",
            "[37018431.58976579]\n",
            "[34280338.58110063]\n",
            "[17528470.46556544]\n",
            "[23254290.11945107]\n",
            "[37617872.88807394]\n",
            "[25035590.87432038]\n",
            "[23397612.75089601]\n",
            "[28770924.96612208]\n",
            "[37229062.81231763]\n",
            "[37229062.81231763]\n",
            "[37288743.65515783]\n",
            "[17092991.6749332]\n",
            "[32000836.85163995]\n",
            "[37289993.86145746]\n",
            "[37091585.14394171]\n",
            "[22353341.73044022]\n",
            "[17184536.51182159]\n",
            "[25706581.11806161]\n",
            "[34743317.64356495]\n",
            "[31066131.98038216]\n",
            "[21985580.93842291]\n",
            "[20408892.21756292]\n",
            "[26152847.0192582]\n",
            "[17184536.51182159]\n",
            "Train : Episode 64/100 - Steps Count 6 - Avg Delay: [1.16865411], Avg Energy: [0.01946143], Avg Reward: [-0.27856659]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32178832.61118336]\n",
            "[30571518.3977119]\n",
            "[31258779.31047771]\n",
            "[23269262.6569858]\n",
            "[33445986.08730524]\n",
            "[36717508.73248485]\n",
            "[23327668.66642797]\n",
            "[31589140.8642997]\n",
            "[34691788.17508804]\n",
            "[34691788.17508804]\n",
            "[37653310.00221647]\n",
            "[29179807.46749961]\n",
            "[31377987.62431901]\n",
            "Train : Episode 65/100 - Steps Count 1 - Avg Delay: [1.12392657], Avg Energy: [0.01158868], Avg Reward: [-0.32040491]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19677731.64264556]\n",
            "[37173268.89776052]\n",
            "[37865603.17101134]\n",
            "[17244968.86356172]\n",
            "[22942795.21241603]\n",
            "[33495254.13641609]\n",
            "[37381803.7129907]\n",
            "[25989473.53424372]\n",
            "[35812454.98508071]\n",
            "[23346538.87102699]\n",
            "[30989899.09935594]\n",
            "[17242528.32095441]\n",
            "[23489994.52483196]\n",
            "[37183179.85403487]\n",
            "[17283478.92092587]\n",
            "[20274381.21257695]\n",
            "[22825201.38368093]\n",
            "[26009116.75135473]\n",
            "[28304404.55035065]\n",
            "[22357428.19723534]\n",
            "[36016411.15138074]\n",
            "[29451002.2309923]\n",
            "[28488922.1027994]\n",
            "[37816787.22510488]\n",
            "[34238155.84412488]\n",
            "[17488680.76260899]\n",
            "[25341673.73826042]\n",
            "[34238155.84412488]\n",
            "[37917428.23559942]\n",
            "[22594303.98029579]\n",
            "[32000836.85163995]\n",
            "[28488922.1027994]\n",
            "[30775326.29289488]\n",
            "Train : Episode 66/100 - Steps Count 3 - Avg Delay: [8.73053651], Avg Energy: [0.02126839], Avg Reward: [-0.34818074]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34330166.31026895]\n",
            "[37312040.6170445]\n",
            "[20324784.81851898]\n",
            "[37018431.58976579]\n",
            "[34393295.41979598]\n",
            "[19871526.11101412]\n",
            "[36717508.73248485]\n",
            "[28908130.30188541]\n",
            "[16798193.21068411]\n",
            "[37018431.58976579]\n",
            "[31589140.8642997]\n",
            "[17440763.97171424]\n",
            "Train : Episode 67/100 - Steps Count 1 - Avg Delay: [0.8320902], Avg Energy: [0.02824079], Avg Reward: [-0.38323954]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17503581.52471655]\n",
            "[23269262.6569858]\n",
            "[28114251.20996682]\n",
            "[27603991.60608585]\n",
            "[26009116.75135473]\n",
            "[20345943.32335969]\n",
            "[34600521.73552445]\n",
            "[36292469.48107947]\n",
            "[36915664.21047833]\n",
            "[36915664.21047833]\n",
            "[37943794.42292785]\n",
            "[36151711.74707]\n",
            "[23341135.84376071]\n",
            "[36777189.57532506]\n",
            "[36172697.10044441]\n",
            "[36777189.57532506]\n",
            "[16704593.47681655]\n",
            "[23222791.65811059]\n",
            "[20436491.04843992]\n",
            "[36911435.69374493]\n",
            "[36962864.63080834]\n",
            "[30790750.55375671]\n",
            "[19655691.13485715]\n",
            "[23141171.40343641]\n",
            "[36655344.37576871]\n",
            "Train : Episode 68/100 - Steps Count 2 - Avg Delay: [0.61992861], Avg Energy: [0.01615127], Avg Reward: [-0.32677119]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37351917.85212491]\n",
            "[36817582.25267707]\n",
            "[17543569.96823049]\n",
            "[19571583.73581321]\n",
            "[34501630.62966619]\n",
            "[17141952.75056796]\n",
            "[23394641.18879384]\n",
            "[20217155.58502783]\n",
            "[37905332.08680747]\n",
            "[37494422.05144375]\n",
            "[20043476.09198097]\n",
            "[32072475.97689674]\n",
            "[19861855.72672921]\n",
            "Train : Episode 69/100 - Steps Count 1 - Avg Delay: [4.12814213], Avg Energy: [0.0278462], Avg Reward: [-0.35889742]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25108604.72222977]\n",
            "[35186196.80449704]\n",
            "[28906368.56194376]\n",
            "[26150861.14477431]\n",
            "[22914352.17637786]\n",
            "[34393295.41979598]\n",
            "[31456696.94715703]\n",
            "[36777189.57532506]\n",
            "[34695453.66995613]\n",
            "[37546824.23979301]\n",
            "[37869490.96616099]\n",
            "[25518808.14954366]\n",
            "[23341135.84376071]\n",
            "[26150861.14477431]\n",
            "[35812454.98508071]\n",
            "Train : Episode 70/100 - Steps Count 1 - Avg Delay: [4.77323122], Avg Energy: [0.01496561], Avg Reward: [-0.46973884]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22684039.11247029]\n",
            "[23089191.28723542]\n",
            "[30933952.98995384]\n",
            "[37841003.8937868]\n",
            "[35626943.54282025]\n",
            "[37888798.74227113]\n",
            "[28949920.84679877]\n",
            "[25998497.61105239]\n",
            "[25946744.39415146]\n",
            "[37841003.8937868]\n",
            "[37217234.0637295]\n",
            "[28594674.15539626]\n",
            "[17468661.81478284]\n",
            "Train : Episode 71/100 - Steps Count 1 - Avg Delay: [0.73135568], Avg Energy: [0.01649877], Avg Reward: [-0.30569166]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30933952.98995384]\n",
            "[31768279.94632826]\n",
            "[23222791.65811059]\n",
            "[33920834.11421838]\n",
            "[37888798.74227113]\n",
            "[17176004.77788424]\n",
            "[37943794.42292785]\n",
            "[17394646.86375295]\n",
            "[37381803.7129907]\n",
            "[19867737.33253852]\n",
            "[25893347.99273708]\n",
            "[19867737.33253852]\n",
            "[23465582.75147294]\n",
            "[26329293.10901235]\n",
            "[37234824.89366734]\n",
            "[17383306.12722194]\n",
            "[33596299.90014467]\n",
            "[25105575.84255641]\n",
            "[17294783.38078358]\n",
            "[28099085.84946207]\n",
            "[22914352.17637786]\n",
            "[19738728.07732992]\n",
            "[25570835.49504744]\n",
            "[30989899.09935594]\n",
            "[25570835.49504744]\n",
            "[23052838.10766977]\n",
            "[17543569.96823049]\n",
            "[37377471.07710729]\n",
            "[37377471.07710729]\n",
            "Train : Episode 72/100 - Steps Count 3 - Avg Delay: [1.19796711], Avg Energy: [0.01448192], Avg Reward: [-0.26567988]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25946744.39415146]\n",
            "[33495254.13641609]\n",
            "[22370970.58801287]\n",
            "[35114347.61885431]\n",
            "[23055105.21767381]\n",
            "[25108604.72222977]\n",
            "[37841003.8937868]\n",
            "[36465943.70246384]\n",
            "[37220218.27042358]\n",
            "[31101353.56779106]\n",
            "[23221850.92200008]\n",
            "[33920834.11421838]\n",
            "[22894131.58299772]\n",
            "[34883558.93560814]\n",
            "[23056124.95495202]\n",
            "[22894131.58299772]\n",
            "[37772822.05913589]\n",
            "[22528005.42044411]\n",
            "[37120215.09145104]\n",
            "[22394960.57762029]\n",
            "[22952507.86227071]\n",
            "[37087356.62720831]\n",
            "[31373600.70003401]\n",
            "[17143794.13871763]\n",
            "[31825982.29518522]\n",
            "[32147711.67058186]\n",
            "[28504016.79723782]\n",
            "[23491831.89019086]\n",
            "[24638776.78075727]\n",
            "[22017938.85338]\n",
            "[30616163.63745268]\n",
            "[28103422.52966256]\n",
            "[19680371.22598973]\n",
            "[30933952.98995384]\n",
            "[16841105.41756821]\n",
            "[34866495.46773344]\n",
            "[28505064.68231817]\n",
            "[30933952.98995384]\n",
            "[23070178.90108295]\n",
            "[23170970.58801287]\n",
            "[23277699.19699224]\n",
            "Train : Episode 73/100 - Steps Count 4 - Avg Delay: [0.99031966], Avg Energy: [0.01746885], Avg Reward: [-0.26236161]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28949920.84679877]\n",
            "[23394641.18879384]\n",
            "[28902442.16903898]\n",
            "[36915664.21047833]\n",
            "[22198526.00555366]\n",
            "[37776611.57367409]\n",
            "[22517784.40940859]\n",
            "[28573718.32557052]\n",
            "[26119229.00670706]\n",
            "[19677731.64264556]\n",
            "[20120605.18798708]\n",
            "[34814272.60515618]\n",
            "[25679099.1729515]\n",
            "[20174453.05358768]\n",
            "[34879247.34760421]\n",
            "[22703259.55106957]\n",
            "[19527736.53580739]\n",
            "[34938648.94438371]\n",
            "[23089191.28723542]\n",
            "[36215213.62534444]\n",
            "[20217155.58502783]\n",
            "[19604424.56865004]\n",
            "[31107437.78076456]\n",
            "[25996841.63935604]\n",
            "[31288479.46918773]\n",
            "[24959274.27382637]\n",
            "[31627897.30382799]\n",
            "Train : Episode 74/100 - Steps Count 2 - Avg Delay: [0.76685088], Avg Energy: [0.0163889], Avg Reward: [-0.34122982]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23181274.29148512]\n",
            "[19787418.71197018]\n",
            "[26240178.90761231]\n",
            "[36817582.25267707]\n",
            "[19527736.53580739]\n",
            "[17244968.86356172]\n",
            "[33393498.66909074]\n",
            "[16632501.42049318]\n",
            "[23181274.29148512]\n",
            "[25694355.66243868]\n",
            "[34399183.4783781]\n",
            "[17176004.77788424]\n",
            "[37473436.69806935]\n",
            "[31627897.30382799]\n",
            "[36465943.70246384]\n",
            "[36321884.43111597]\n",
            "[25472984.40504406]\n",
            "[30775326.29289488]\n",
            "[25033615.83983283]\n",
            "[37351917.85212491]\n",
            "[24837371.23816983]\n",
            "[34643190.92813012]\n",
            "[28189371.97228298]\n",
            "[23131719.3189122]\n",
            "[30559851.7118049]\n",
            "[22972336.84856122]\n",
            "[28741268.5512498]\n",
            "[23131719.3189122]\n",
            "[35008321.89032526]\n",
            "[25764578.71600359]\n",
            "[23240972.52447519]\n",
            "[28505064.68231817]\n",
            "[16798193.21068411]\n",
            "[23218229.43461335]\n",
            "Train : Episode 75/100 - Steps Count 3 - Avg Delay: [1.43780542], Avg Energy: [0.01779295], Avg Reward: [-0.32070135]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22909576.72630381]\n",
            "[37381803.7129907]\n",
            "[22975900.28349184]\n",
            "[34879655.68939269]\n",
            "[36817582.25267707]\n",
            "[23221850.92200008]\n",
            "[16808206.63468079]\n",
            "[22975892.59420711]\n",
            "[36136372.9888555]\n",
            "[37000339.12021171]\n",
            "[31879668.23332975]\n",
            "[24963111.73385957]\n",
            "[36456077.5014698]\n",
            "[20039932.15191915]\n",
            "[35081678.94844089]\n",
            "[16710275.68312621]\n",
            "[37306215.15784387]\n",
            "[20410837.73589046]\n",
            "[33473227.96223246]\n",
            "[20384511.1103236]\n",
            "[24952109.22953063]\n",
            "[31749716.67262466]\n",
            "[31535454.92615516]\n",
            "[31886355.41331746]\n",
            "[20248203.84243925]\n",
            "[22307317.1115144]\n",
            "[31535465.49892167]\n",
            "[36172697.10044441]\n",
            "[23152320.66518418]\n",
            "[19832096.64237217]\n",
            "[19677731.64264556]\n",
            "[23209877.59449557]\n",
            "[23057104.75868086]\n",
            "[31106507.3414326]\n",
            "[20162182.88519016]\n",
            "[31434021.41202958]\n",
            "Train : Episode 76/100 - Steps Count 3 - Avg Delay: [0.97396384], Avg Energy: [0.01822234], Avg Reward: [-0.31086297]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25946744.39415146]\n",
            "[22753342.94408209]\n",
            "[26119229.00670706]\n",
            "[28949920.84679877]\n",
            "[19464536.24983275]\n",
            "[20111335.16712698]\n",
            "[31335450.99164369]\n",
            "[26009116.75135473]\n",
            "[36817582.25267707]\n",
            "[22863385.83933584]\n",
            "[19369376.29548629]\n",
            "[23394641.18879384]\n",
            "[31768279.94632826]\n",
            "Train : Episode 77/100 - Steps Count 1 - Avg Delay: [1.65203322], Avg Energy: [0.02092305], Avg Reward: [-0.29180585]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22842410.58300274]\n",
            "[28190926.59842022]\n",
            "[37943794.42292785]\n",
            "[25946744.39415146]\n",
            "[25735785.87920674]\n",
            "[34879247.34760421]\n",
            "[36655344.37576871]\n",
            "[19930348.80568579]\n",
            "[28152583.57548842]\n",
            "[17036853.34037023]\n",
            "[20462740.08316351]\n",
            "[22981335.38921884]\n",
            "[17498953.54960351]\n",
            "[30905885.76416366]\n",
            "[20138644.53063649]\n",
            "[36659817.61565787]\n",
            "[16808206.63468079]\n",
            "[34879655.68939269]\n",
            "[29223201.79879255]\n",
            "[27979293.99517548]\n",
            "[33101571.21500776]\n",
            "[16893827.30033946]\n",
            "[31291695.32889345]\n",
            "[19871526.11101412]\n",
            "[17182584.88871386]\n",
            "[31168837.97970402]\n",
            "[19577525.17784073]\n",
            "[22357428.19723534]\n",
            "[17266109.4592406]\n",
            "[20278517.54607985]\n",
            "[37901103.57007407]\n",
            "[23089191.28723542]\n",
            "[22453838.24388145]\n",
            "[22256809.70046797]\n",
            "Train : Episode 78/100 - Steps Count 3 - Avg Delay: [1.05735288], Avg Energy: [0.02087239], Avg Reward: [-0.30869445]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19527736.53580739]\n",
            "[31018924.79733403]\n",
            "[37204879.51220907]\n",
            "[19867737.33253852]\n",
            "[36817582.25267707]\n",
            "[19677731.64264556]\n",
            "[36172697.10044441]\n",
            "[19867737.33253852]\n",
            "[37204879.51220907]\n",
            "[33445986.08730524]\n",
            "[25108604.72222977]\n",
            "[22525779.83725657]\n",
            "Train : Episode 79/100 - Steps Count 1 - Avg Delay: [1.03225246], Avg Energy: [0.01158804], Avg Reward: [-0.30428696]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[21724187.07671386]\n",
            "[20496761.18986945]\n",
            "[33779643.60638414]\n",
            "[22757137.61600199]\n",
            "[20167333.72659649]\n",
            "[30775326.29289488]\n",
            "[37943794.42292785]\n",
            "[22423071.77001782]\n",
            "[28371379.97786231]\n",
            "[18865056.80943498]\n",
            "[17181498.84891145]\n",
            "[22808081.88785036]\n",
            "[22808081.88785036]\n",
            "[36525624.54530405]\n",
            "[37220218.27042358]\n",
            "[34045987.90776804]\n",
            "[32101176.86387233]\n",
            "[36717508.73248485]\n",
            "[37710678.98549479]\n",
            "[17316483.86559031]\n",
            "[22808081.88785036]\n",
            "[23203625.89104791]\n",
            "Train : Episode 80/100 - Steps Count 2 - Avg Delay: [0.87085343], Avg Energy: [0.01974247], Avg Reward: [-0.36152242]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22975900.28349184]\n",
            "[37383343.29322017]\n",
            "[34712478.15206096]\n",
            "[34393295.41979598]\n",
            "[16808206.63468079]\n",
            "[32101176.86387233]\n",
            "[19871526.11101412]\n",
            "[30952051.13526261]\n",
            "[36817582.25267707]\n",
            "[37537220.01035793]\n",
            "Train : Episode 81/100 - Steps Count 1 - Avg Delay: [0.96528072], Avg Energy: [0.01552122], Avg Reward: [-0.3664865]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36904703.3278506]\n",
            "[35012392.61798893]\n",
            "[17043932.76723846]\n",
            "[34193547.75465608]\n",
            "[37943794.42292785]\n",
            "[37217234.0637295]\n",
            "[22972336.84856122]\n",
            "[31101353.56779106]\n",
            "[20324784.81851898]\n",
            "[33376949.15891651]\n",
            "[33495254.13641609]\n",
            "[33376949.15891651]\n",
            "[22594303.98029579]\n",
            "Train : Episode 82/100 - Steps Count 1 - Avg Delay: [0.69516062], Avg Energy: [0.02217983], Avg Reward: [-0.42672114]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35012392.61798893]\n",
            "[28152583.57548842]\n",
            "[30775326.29289488]\n",
            "[20496761.18986945]\n",
            "[34712478.15206096]\n",
            "[37729660.21154652]\n",
            "[28964107.91521946]\n",
            "[19738728.07732992]\n",
            "[34530566.86658172]\n",
            "[34695453.66995613]\n",
            "[36928338.18491662]\n",
            "[20109628.80572335]\n",
            "[22617251.37942997]\n",
            "[31740174.69805712]\n",
            "[37888798.74227113]\n",
            "[37816787.22510488]\n",
            "[19527736.53580739]\n",
            "[26246820.96237933]\n",
            "[28195681.11701357]\n",
            "[20309217.62706965]\n",
            "[25989473.53424372]\n",
            "[37123828.19691648]\n",
            "[30559851.7118049]\n",
            "[17070330.90608436]\n",
            "[37145438.78758877]\n",
            "[31815339.13027586]\n",
            "[37947043.91089671]\n",
            "[37073099.72041079]\n",
            "[31094443.80491162]\n",
            "[25478272.72716952]\n",
            "[17033903.28944234]\n",
            "[23289090.21796227]\n",
            "[17274126.18523883]\n",
            "[34399183.4783781]\n",
            "[17039767.0218786]\n",
            "Train : Episode 83/100 - Steps Count 3 - Avg Delay: [0.70844555], Avg Energy: [0.01898003], Avg Reward: [-0.29111704]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20324784.81851898]\n",
            "[25783022.24361547]\n",
            "[37000339.12021171]\n",
            "[34001204.62723239]\n",
            "[17630928.9218197]\n",
            "[33393498.66909074]\n",
            "[37841003.8937868]\n",
            "[22972336.84856122]\n",
            "[29143440.50290697]\n",
            "[37943794.42292785]\n",
            "[32190794.30772438]\n",
            "[22894131.58299772]\n",
            "[25783022.24361547]\n",
            "Train : Episode 84/100 - Steps Count 1 - Avg Delay: [1.74237947], Avg Energy: [0.02712557], Avg Reward: [-0.31732948]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[16808206.63468079]\n",
            "[28189371.97228298]\n",
            "[22109576.72630381]\n",
            "[37183179.85403487]\n",
            "[22981335.38921884]\n",
            "[37943794.42292785]\n",
            "[31566178.90721865]\n",
            "[20496761.18986945]\n",
            "[31507783.07736909]\n",
            "[30933952.98995384]\n",
            "[37329468.35312783]\n",
            "[34712478.15206096]\n",
            "[23019398.28243497]\n",
            "[25108604.72222977]\n",
            "[37905332.08680747]\n",
            "Train : Episode 85/100 - Steps Count 1 - Avg Delay: [0.69249331], Avg Energy: [0.01706251], Avg Reward: [-0.367755]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20345943.32335969]\n",
            "[28195681.11701357]\n",
            "[20120605.18798708]\n",
            "[34393295.41979598]\n",
            "[22942795.21241603]\n",
            "[17552481.24951209]\n",
            "[36915664.21047833]\n",
            "[37018431.58976579]\n",
            "[37943794.42292785]\n",
            "[28190926.59842022]\n",
            "[19592742.24065392]\n",
            "[23259479.55704862]\n",
            "[20236714.72203723]\n",
            "[25045136.34460792]\n",
            "[30775326.29289488]\n",
            "[17141952.75056796]\n",
            "[22909576.72630381]\n",
            "[33396526.42198326]\n",
            "[26053274.42909298]\n",
            "[29152583.57548841]\n",
            "[25229611.34173245]\n",
            "[34349624.91155259]\n",
            "[17241238.83788649]\n",
            "[22734933.76928626]\n",
            "[25153274.42909298]\n",
            "[23181274.29148512]\n",
            "[28023802.0350275]\n",
            "[19655942.52662855]\n",
            "[25470510.62158091]\n",
            "[20182051.12869687]\n",
            "[22381609.34562472]\n",
            "[17370071.85284355]\n",
            "[31372354.01985829]\n",
            "[30403300.9197426]\n",
            "Train : Episode 86/100 - Steps Count 3 - Avg Delay: [0.78843621], Avg Energy: [0.0222632], Avg Reward: [-0.34658105]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34330166.31026895]\n",
            "[22995354.19359219]\n",
            "[37637223.18933047]\n",
            "[37204879.51220907]\n",
            "[23291615.95642512]\n",
            "[17282874.4338201]\n",
            "[23346538.87102699]\n",
            "[26009116.75135473]\n",
            "[37905332.08680747]\n",
            "[17630928.9218197]\n",
            "[21767118.21268075]\n",
            "[19464536.24983275]\n",
            "[26159656.85271195]\n",
            "[19871526.11101412]\n",
            "[17141952.75056796]\n",
            "Train : Episode 87/100 - Steps Count 1 - Avg Delay: [1.53655812], Avg Energy: [0.02343604], Avg Reward: [-0.34163927]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20324784.81851898]\n",
            "[37183179.85403487]\n",
            "[29143440.50290697]\n",
            "[26051904.23504078]\n",
            "[37726693.8202557]\n",
            "[23269262.6569858]\n",
            "[26119229.00670706]\n",
            "[33101571.21500776]\n",
            "[30645388.8952045]\n",
            "[36817582.25267707]\n",
            "[35343838.92896523]\n",
            "[23300347.98405902]\n",
            "Train : Episode 88/100 - Steps Count 1 - Avg Delay: [1.60991678], Avg Energy: [0.01571465], Avg Reward: [-0.26732457]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[33779643.60638414]\n",
            "[34393295.41979598]\n",
            "[31258779.31047771]\n",
            "[36745956.36260124]\n",
            "[30645388.8952045]\n",
            "[22684039.11247029]\n",
            "[37018431.58976579]\n",
            "[23099028.99463775]\n",
            "[31456696.94715703]\n",
            "[16634281.69064251]\n",
            "[36840363.77229214]\n",
            "Train : Episode 89/100 - Steps Count 1 - Avg Delay: [0.7176849], Avg Energy: [0.02123806], Avg Reward: [-0.36286484]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37905332.08680747]\n",
            "[20167333.72659649]\n",
            "[35012392.61798893]\n",
            "[37381803.7129907]\n",
            "[37747458.27893293]\n",
            "[36172697.10044441]\n",
            "[37537220.01035793]\n",
            "[36817582.25267707]\n",
            "[23346538.87102699]\n",
            "[36915664.21047833]\n",
            "[24890041.30376846]\n",
            "[37747458.27893293]\n",
            "[28190926.59842022]\n",
            "Train : Episode 90/100 - Steps Count 1 - Avg Delay: [0.68675742], Avg Energy: [0.01535805], Avg Reward: [-0.36219865]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37905332.08680747]\n",
            "[17244968.86356172]\n",
            "[22799830.5023152]\n",
            "[22617251.37942997]\n",
            "[19948749.43550069]\n",
            "[25946877.54878111]\n",
            "[16906321.079408]\n",
            "[37217234.0637295]\n",
            "[17141952.75056796]\n",
            "[37905513.52504303]\n",
            "[17159525.58096745]\n",
            "[26273192.54575916]\n",
            "[19882468.51789796]\n",
            "[21767118.21268075]\n",
            "[23148337.17666633]\n",
            "[19592742.24065392]\n",
            "[31930132.15414155]\n",
            "[25430340.31943722]\n",
            "[30381957.79224144]\n",
            "[21889458.19665842]\n",
            "[37750564.35398109]\n",
            "[30447796.25637305]\n",
            "Train : Episode 91/100 - Steps Count 2 - Avg Delay: [7.37799291], Avg Energy: [0.01587343], Avg Reward: [-0.27325142]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37543237.99735022]\n",
            "[36817582.25267707]\n",
            "[22799830.5023152]\n",
            "[34879655.68939269]\n",
            "[34051679.91564788]\n",
            "[22972336.84856122]\n",
            "[29223201.79879255]\n",
            "[37234824.89366734]\n",
            "[35012392.61798893]\n",
            "[36154991.81270356]\n",
            "[28609960.9186784]\n",
            "[22955767.61327179]\n",
            "[19484946.30297206]\n",
            "[19936673.78227786]\n",
            "[26240178.90761231]\n",
            "[22878645.24113903]\n",
            "[20211876.43956328]\n",
            "[25026648.25438679]\n",
            "[25545193.50753102]\n",
            "[23434545.55667115]\n",
            "[19955573.88327515]\n",
            "[17499417.92088686]\n",
            "[22842410.58300274]\n",
            "[22445425.06945714]\n",
            "[37234824.89366734]\n",
            "[22669907.08171565]\n",
            "[31979500.13328685]\n",
            "[17202402.24125486]\n",
            "[23148337.17666633]\n",
            "[29145785.63687367]\n",
            "[23327668.66642797]\n",
            "[34372746.22308144]\n",
            "[31822711.49426882]\n",
            "[25867117.40424105]\n",
            "[34760368.81048299]\n",
            "[36085718.0769951]\n",
            "[36492401.61305869]\n",
            "[30985300.21429801]\n",
            "[23186320.11887415]\n",
            "[25383685.10363292]\n",
            "[33634083.62778194]\n",
            "[23217161.47498084]\n",
            "[37455705.9807379]\n",
            "[36254507.99147719]\n",
            "[17519245.16466612]\n",
            "[26173344.11419477]\n",
            "[34428007.44742267]\n",
            "[19888259.2776398]\n",
            "[37344241.26155248]\n",
            "[17519245.16466612]\n",
            "[16656104.00943366]\n",
            "[17443794.13871763]\n",
            "[28881669.84684634]\n",
            "[26498386.27845811]\n",
            "[34627730.59679951]\n",
            "[20166193.72224141]\n",
            "[26498386.27845811]\n",
            "Train : Episode 92/100 - Steps Count 6 - Avg Delay: [1.26854755], Avg Energy: [0.02441594], Avg Reward: [-0.29761432]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28152583.57548842]\n",
            "[31874941.13902245]\n",
            "[23099028.99463775]\n",
            "[22192157.07729078]\n",
            "[22198526.00555366]\n",
            "[34879655.68939269]\n",
            "[37729660.21154652]\n",
            "[37841003.8937868]\n",
            "[23327668.66642797]\n",
            "[20324784.81851898]\n",
            "[19930348.80568579]\n",
            "[26009116.75135473]\n",
            "Train : Episode 93/100 - Steps Count 1 - Avg Delay: [0.78569782], Avg Energy: [0.02769655], Avg Reward: [-0.34098225]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20438728.07732992]\n",
            "[31879668.23332975]\n",
            "[34695453.66995613]\n",
            "[25683644.42345658]\n",
            "[30775326.29289488]\n",
            "[25946877.54878111]\n",
            "[28285967.23983448]\n",
            "[19571583.73581321]\n",
            "[32101176.86387233]\n",
            "[20309916.81286342]\n",
            "[34193547.75465608]\n",
            "[31373600.70003401]\n",
            "[25694355.66243868]\n",
            "Train : Episode 94/100 - Steps Count 1 - Avg Delay: [1.26645823], Avg Energy: [0.02198955], Avg Reward: [-0.35017909]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23394641.18879384]\n",
            "[17199417.92088686]\n",
            "[37018431.58976579]\n",
            "[37776611.57367409]\n",
            "[34521241.84326933]\n",
            "[17141952.75056796]\n",
            "[37422249.46500327]\n",
            "[22689167.61542506]\n",
            "[25081664.2680322]\n",
            "[23089191.28723542]\n",
            "[36465943.70246384]\n",
            "[20398311.05123295]\n",
            "[37344241.26155248]\n",
            "[31348541.28247477]\n",
            "[22307317.1115144]\n",
            "[28573718.32557052]\n",
            "[19882468.51789796]\n",
            "[37726693.8202557]\n",
            "[20051861.41662218]\n",
            "[28906368.56194376]\n",
            "[32178832.61118336]\n",
            "[22154353.62051403]\n",
            "[26127888.43092952]\n",
            "[28703029.02048374]\n",
            "[35012392.61798893]\n",
            "[22842410.58300274]\n",
            "[27930733.93322217]\n",
            "[22857273.75326393]\n",
            "[16688302.36140883]\n",
            "[17304079.91767959]\n",
            "[24865260.64385621]\n",
            "[17283596.51823796]\n",
            "[33887555.99644681]\n",
            "[37661838.05404293]\n",
            "[34643190.92813012]\n",
            "[34316164.12113251]\n",
            "[35626943.54282025]\n",
            "[22753342.94408209]\n",
            "[16954460.48106597]\n",
            "[25679099.1729515]\n",
            "[38088384.37423491]\n",
            "Train : Episode 95/100 - Steps Count 4 - Avg Delay: [1.37519822], Avg Energy: [0.02033761], Avg Reward: [-0.29610306]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20345943.32335969]\n",
            "[23394641.18879384]\n",
            "[33396526.42198326]\n",
            "[16632501.42049318]\n",
            "[37334828.07263988]\n",
            "[37943794.42292785]\n",
            "[35012392.61798893]\n",
            "[26173344.11419477]\n",
            "[20109628.80572335]\n",
            "[37334828.07263988]\n",
            "[32101176.86387233]\n",
            "[30104720.5499108]\n",
            "[36371413.08071175]\n",
            "Train : Episode 96/100 - Steps Count 1 - Avg Delay: [0.88617615], Avg Energy: [0.01475004], Avg Reward: [-0.30409775]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22981335.38921884]\n",
            "[26051904.23504078]\n",
            "[35012392.61798893]\n",
            "[19527736.53580739]\n",
            "[37943794.42292785]\n",
            "[23181274.29148512]\n",
            "[17543569.96823049]\n",
            "[29223201.79879255]\n",
            "[22885358.10189155]\n",
            "[32084839.51485606]\n",
            "[37204879.51220907]\n",
            "[28103422.52966256]\n",
            "[22684039.11247029]\n",
            "[33994988.14491493]\n",
            "[20496761.18986945]\n",
            "[30645388.8952045]\n",
            "[22799830.5023152]\n",
            "[28190926.59842022]\n",
            "[28322069.58879394]\n",
            "[28322069.58879394]\n",
            "[35740089.29565461]\n",
            "[37220218.27042358]\n",
            "Train : Episode 97/100 - Steps Count 2 - Avg Delay: [0.80477221], Avg Energy: [0.01761551], Avg Reward: [-0.31387482]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22767445.41994687]\n",
            "[22975900.28349184]\n",
            "[35731950.36212119]\n",
            "[22617251.37942997]\n",
            "[29223201.79879255]\n",
            "[32138916.66526449]\n",
            "[22955767.61327179]\n",
            "[25989473.53424372]\n",
            "[23394641.18879384]\n",
            "[36817582.25267707]\n",
            "[20172097.4391033]\n",
            "[25045136.34460792]\n",
            "[22942795.21241603]\n",
            "[25645815.68687413]\n",
            "[17383306.12722194]\n",
            "[16895778.92344718]\n",
            "[17468661.81478284]\n",
            "[25694355.66243868]\n",
            "[23099028.99463775]\n",
            "[36136372.9888555]\n",
            "[33396526.42198326]\n",
            "[25643474.1213129]\n",
            "[22972336.84856122]\n",
            "[22930746.42314397]\n",
            "[31925387.00006223]\n",
            "[37558192.04523374]\n",
            "[30788305.2421533]\n",
            "[37463548.58577325]\n",
            "[23144114.20183729]\n",
            "[16560769.19722754]\n",
            "[28009882.46605729]\n",
            "[37761715.18573044]\n",
            "Train : Episode 98/100 - Steps Count 3 - Avg Delay: [4.99892374], Avg Energy: [0.01951149], Avg Reward: [-0.28232291]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32101176.86387233]\n",
            "[35012392.61798893]\n",
            "[36347484.43972605]\n",
            "[37183179.85403487]\n",
            "[22863385.83933584]\n",
            "[22909576.72630381]\n",
            "[17199417.92088686]\n",
            "[37888798.74227113]\n",
            "[36371413.08071175]\n",
            "[25998497.61105239]\n",
            "[36465943.70246384]\n",
            "[35012392.61798893]\n",
            "Train : Episode 99/100 - Steps Count 1 - Avg Delay: [0.79720072], Avg Energy: [0.01162833], Avg Reward: [-0.32492553]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37729660.21154652]\n",
            "[19571583.73581321]\n",
            "[36817582.25267707]\n",
            "[17394646.86375295]\n",
            "[23141171.40343641]\n",
            "[16846055.00355843]\n",
            "[37217234.0637295]\n",
            "[22975900.28349184]\n",
            "[37841003.8937868]\n",
            "[22955767.61327179]\n",
            "[23346538.87102699]\n",
            "[37888798.74227113]\n",
            "[23099028.99463775]\n",
            "[35012392.61798893]\n",
            "[37334828.07263988]\n",
            "[22973052.53303035]\n",
            "[30645388.8952045]\n",
            "[22659857.9640809]\n",
            "[30790750.55375671]\n",
            "[37055105.90344616]\n",
            "[36706661.99646848]\n",
            "[36616050.00963596]\n",
            "[25811171.08250926]\n",
            "[16305126.50900097]\n",
            "[17094810.50090114]\n",
            "[34193871.01812514]\n",
            "[19527736.53580739]\n",
            "[31377987.62431901]\n",
            "[19995943.32335969]\n",
            "[37765984.32313542]\n",
            "[25793641.38391782]\n",
            "[17486112.12373819]\n",
            "[22799830.5023152]\n",
            "[37537220.01035793]\n",
            "[17463933.19420492]\n",
            "[17468661.81478284]\n",
            "[37522252.64397581]\n",
            "[23131719.3189122]\n",
            "[17434183.86088461]\n",
            "Train : Episode 100/100 - Steps Count 4 - Avg Delay: [1.11368853], Avg Energy: [0.02428349], Avg Reward: [-0.25616641]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[32178832.61118336]\n",
            "[37943794.42292785]\n",
            "[23055105.21767381]\n",
            "[37381803.7129907]\n",
            "[34296805.57122349]\n",
            "[23141171.40343641]\n",
            "[17141952.75056796]\n",
            "[17176004.77788424]\n",
            "[23434545.55667115]\n",
            "[23055105.21767381]\n",
            "[37000339.12021171]\n",
            "[20111335.16712698]\n",
            "[25274515.11968128]\n",
            "[25694355.66243868]\n",
            "[17543569.96823049]\n",
            "Train : Episode 1/100 - Steps Count 1 - Avg Delay: [1.41754503], Avg Energy: [0.02741867], Avg Reward: [-0.39550289]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25045136.34460792]\n",
            "[25694355.66243868]\n",
            "[19767530.8677337]\n",
            "[20447009.26497448]\n",
            "[23056938.4906387]\n",
            "[23327668.66642797]\n",
            "[22684039.11247029]\n",
            "[28189371.97228298]\n",
            "[31288479.46918773]\n",
            "[23298834.56303016]\n",
            "[19592742.24065392]\n",
            "[34879655.68939269]\n",
            "[30989899.09935594]\n",
            "[19955573.88327515]\n",
            "[19767530.8677337]\n",
            "Train : Episode 2/100 - Steps Count 1 - Avg Delay: [0.72522545], Avg Energy: [0.03389925], Avg Reward: [-0.45129114]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34879655.68939269]\n",
            "[37173268.89776052]\n",
            "[22972336.84856122]\n",
            "[17352765.25137783]\n",
            "[22109576.72630381]\n",
            "[22806321.84884968]\n",
            "[37905332.08680747]\n",
            "[22975900.28349184]\n",
            "[25045136.34460792]\n",
            "[23221850.92200008]\n",
            "[35882218.0810269]\n",
            "[37422249.46500327]\n",
            "[28587937.88213278]\n",
            "[31886355.41331746]\n",
            "[22604096.74141473]\n",
            "[37943794.42292785]\n",
            "[23327668.66642797]\n",
            "[17468661.81478284]\n",
            "[19677731.64264556]\n",
            "[25989473.53424372]\n",
            "[31640794.30772437]\n",
            "[37729660.21154652]\n",
            "Train : Episode 3/100 - Steps Count 2 - Avg Delay: [0.90136514], Avg Energy: [0.01741898], Avg Reward: [-0.27968398]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28531935.30360627]\n",
            "[17383306.12722194]\n",
            "[27860102.32512784]\n",
            "[23327668.66642797]\n",
            "[17199417.92088686]\n",
            "[36928338.18491662]\n",
            "[25045136.34460792]\n",
            "[17383306.12722194]\n",
            "[26119229.00670706]\n",
            "[37943794.42292785]\n",
            "[17601771.60014259]\n",
            "[22617251.37942997]\n",
            "[31160584.49184104]\n",
            "[28835772.42802463]\n",
            "[20233810.40952746]\n",
            "[37408619.62639716]\n",
            "[23309121.46516518]\n",
            "[17468661.81478284]\n",
            "[29331810.56094465]\n",
            "[17528485.90136891]\n",
            "[37537220.01035793]\n",
            "[25655643.78171249]\n",
            "[19677731.64264556]\n",
            "[34269157.64027312]\n",
            "[28103422.52966256]\n",
            "[36573449.46113697]\n",
            "[28425043.89782093]\n",
            "[22842410.58300274]\n",
            "[17068588.18644486]\n",
            "[17150773.33297116]\n",
            "[25472984.40504406]\n",
            "[36172697.10044441]\n",
            "[37350595.85663405]\n",
            "[22577881.01926151]\n",
            "[23184806.46192613]\n",
            "[37676608.39470155]\n",
            "[34586096.58830592]\n",
            "[37646744.64037579]\n",
            "[37351917.85212491]\n",
            "[17063186.52843027]\n",
            "[36915664.21047833]\n",
            "[17521890.35473581]\n",
            "[23397501.0965972]\n",
            "[37215603.17101134]\n",
            "[28204477.83087342]\n",
            "[23014936.91285769]\n",
            "[21724187.07671386]\n",
            "[28285967.23983448]\n",
            "[36915664.21047833]\n",
            "[19840201.72736316]\n",
            "[20026820.86060049]\n",
            "[31650189.28857807]\n",
            "[28753037.89282673]\n",
            "[34883558.93560814]\n",
            "[37408619.62639716]\n",
            "[34564516.98360153]\n",
            "[37869490.96616099]\n",
            "[26214578.7160036]\n",
            "[22314465.3015374]\n",
            "[37420314.92112336]\n",
            "[37869490.96616099]\n",
            "[26283308.16772587]\n",
            "[28341799.26304719]\n",
            "[19840365.53609677]\n",
            "[17210046.01882355]\n",
            "[37494422.05144375]\n",
            "[20597217.53024061]\n",
            "Train : Episode 4/100 - Steps Count 6 - Avg Delay: [0.88229388], Avg Energy: [0.02105179], Avg Reward: [-0.26074005]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28304404.55035065]\n",
            "[25026648.25438679]\n",
            "[36300348.09089724]\n",
            "[34600521.73552445]\n",
            "[31874941.13902245]\n",
            "[29119679.57029104]\n",
            "[16634281.69064251]\n",
            "[17176004.77788424]\n",
            "[37204879.51220907]\n",
            "[34677984.43858017]\n",
            "[17350169.62329838]\n",
            "[36292469.48107947]\n",
            "[36772249.46500327]\n",
            "[32208778.89239567]\n",
            "[25919998.45279995]\n",
            "[36934117.37109922]\n",
            "[23141171.40343641]\n",
            "[23019398.28243497]\n",
            "[33393498.66909074]\n",
            "[34850066.48245369]\n",
            "[34001204.62723239]\n",
            "[28322069.58879394]\n",
            "[19359422.60589272]\n",
            "[25308694.16588933]\n",
            "[21549968.85280308]\n",
            "[23368246.99681947]\n",
            "[31377987.62431901]\n",
            "[20302490.05215138]\n",
            "[17630928.9218197]\n",
            "[28189371.97228298]\n",
            "[30546715.94726384]\n",
            "[37522252.64397581]\n",
            "[28828509.80725035]\n",
            "[16634281.69064251]\n",
            "[20146728.76829955]\n",
            "[28957291.34771126]\n",
            "Train : Episode 5/100 - Steps Count 4 - Avg Delay: [1.2961466], Avg Energy: [0.01916574], Avg Reward: [-0.29823967]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26119229.00670706]\n",
            "[19741483.1253228]\n",
            "[16790613.43675935]\n",
            "[36817582.25267707]\n",
            "[22664420.18757814]\n",
            "[32138916.66526449]\n",
            "[35114347.61885431]\n",
            "[17176004.77788424]\n",
            "[25946877.54878111]\n",
            "[22664420.18757814]\n",
            "[33393498.66909074]\n",
            "[29152583.57548841]\n",
            "Train : Episode 6/100 - Steps Count 1 - Avg Delay: [2.64419646], Avg Energy: [0.01244962], Avg Reward: [-0.26509381]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22753342.94408209]\n",
            "[17383306.12722194]\n",
            "[35740089.29565461]\n",
            "[36292469.48107947]\n",
            "[22863385.83933584]\n",
            "[16895778.92344718]\n",
            "[23327668.66642797]\n",
            "[26184448.60517605]\n",
            "[17503581.52471655]\n",
            "[32138916.66526449]\n",
            "[22955767.61327179]\n",
            "[37344241.26155248]\n",
            "[16895778.92344718]\n",
            "Train : Episode 7/100 - Steps Count 1 - Avg Delay: [0.80744629], Avg Energy: [0.02071551], Avg Reward: [-0.3099845]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19369376.29548629]\n",
            "[17468661.81478284]\n",
            "[20109628.80572335]\n",
            "[37220218.27042358]\n",
            "[31930132.15414155]\n",
            "[33445986.08730524]\n",
            "[23082773.89107458]\n",
            "[37422249.46500327]\n",
            "[33393498.66909074]\n",
            "[36215213.62534444]\n",
            "Train : Episode 8/100 - Steps Count 1 - Avg Delay: [1.91645988], Avg Energy: [0.00969711], Avg Reward: [-0.26161357]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31646893.0337486]\n",
            "[36717508.73248485]\n",
            "[28911383.00706495]\n",
            "[22914352.17637786]\n",
            "[19571583.73581321]\n",
            "[23346538.87102699]\n",
            "[30933952.98995384]\n",
            "[31874941.13902245]\n",
            "[33445986.08730524]\n",
            "[31646893.0337486]\n",
            "[19871179.05862106]\n",
            "[28190926.59842022]\n",
            "[17244968.86356172]\n",
            "[28734737.72659854]\n",
            "[26240178.90761231]\n",
            "[34664002.31938358]\n",
            "[34280338.58110063]\n",
            "[37078625.43830004]\n",
            "[22824660.68859064]\n",
            "[17142422.96240774]\n",
            "[32138916.66526449]\n",
            "[34643190.92813012]\n",
            "[34743317.64356495]\n",
            "[30989986.7776644]\n",
            "[37996574.52270168]\n",
            "[28300186.79639672]\n",
            "[37726693.8202557]\n",
            "[37602157.21120273]\n",
            "[23375892.59420712]\n",
            "[34372746.22308144]\n",
            "[37415213.16212002]\n",
            "[16900324.50852202]\n",
            "[34372746.22308144]\n",
            "[23455105.2176738]\n",
            "[30485253.28746152]\n",
            "[28106675.23484211]\n",
            "[28807850.13841398]\n",
            "[22808081.88785036]\n",
            "[25600653.36644475]\n",
            "[36983849.98418273]\n",
            "[23265532.74234084]\n",
            "[23197669.7736107]\n",
            "[20217737.33253852]\n",
            "[36488785.04037894]\n",
            "[22709262.08769719]\n",
            "[31930132.15414155]\n",
            "[36488785.04037894]\n",
            "[31930132.15414155]\n",
            "[37537220.01035793]\n",
            "[31522475.97689674]\n",
            "[32003894.09472608]\n",
            "[32647769.91391711]\n",
            "[37891203.62379798]\n",
            "Train : Episode 9/100 - Steps Count 5 - Avg Delay: [0.88042219], Avg Energy: [0.01929127], Avg Reward: [-0.26545471]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37543237.99735022]\n",
            "[22517784.40940859]\n",
            "[34695453.66995613]\n",
            "[18865056.80943498]\n",
            "[38088349.49679654]\n",
            "[26051904.23504078]\n",
            "[19606701.46227572]\n",
            "[22942795.21241603]\n",
            "[19464536.24983275]\n",
            "[19464536.24983275]\n",
            "[22664420.18757814]\n",
            "[28114251.20996682]\n",
            "[31871931.91032086]\n",
            "Train : Episode 10/100 - Steps Count 1 - Avg Delay: [1.63576233], Avg Energy: [0.02185635], Avg Reward: [-0.31195365]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26184448.60517605]\n",
            "[19871179.05862106]\n",
            "[20345943.32335969]\n",
            "[23089191.28723542]\n",
            "[25108604.72222977]\n",
            "[37726693.8202557]\n",
            "[25831745.69681176]\n",
            "[17141952.75056796]\n",
            "[36655344.37576871]\n",
            "[25108604.72222977]\n",
            "[31748557.39627735]\n",
            "[20236714.72203723]\n",
            "[31101353.56779106]\n",
            "[25108604.72222977]\n",
            "[34296805.57122349]\n",
            "Train : Episode 11/100 - Steps Count 1 - Avg Delay: [0.98649622], Avg Energy: [0.0162746], Avg Reward: [-0.33392777]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34879655.68939269]\n",
            "[31450836.85163994]\n",
            "[26184448.60517605]\n",
            "[25045136.34460792]\n",
            "[20043476.09198097]\n",
            "[22799830.5023152]\n",
            "[31471263.46936724]\n",
            "[20376834.3143557]\n",
            "[20236714.72203723]\n",
            "[26273192.54575916]\n",
            "[36817582.25267707]\n",
            "[22799830.5023152]\n",
            "[37924189.80188567]\n",
            "[23394641.18879384]\n",
            "[37537220.01035793]\n",
            "Train : Episode 12/100 - Steps Count 1 - Avg Delay: [0.67492361], Avg Energy: [0.02217512], Avg Reward: [-0.43951671]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36915664.21047833]\n",
            "[28911383.00706495]\n",
            "[17176004.77788424]\n",
            "[23181274.29148512]\n",
            "[37888798.74227113]\n",
            "[22767445.41994687]\n",
            "[16946329.74159406]\n",
            "[36982487.73357826]\n",
            "[31646893.0337486]\n",
            "[32178832.61118336]\n",
            "[31018924.79733403]\n",
            "[33393498.66909074]\n",
            "[34001204.62723239]\n",
            "[28469123.27268241]\n",
            "[17686955.37538531]\n",
            "[37773828.19691648]\n",
            "[33784660.57190188]\n",
            "[22328571.84442481]\n",
            "[34424220.00719497]\n",
            "[33739877.29136622]\n",
            "[30933952.98995384]\n",
            "Train : Episode 13/100 - Steps Count 2 - Avg Delay: [1.58986007], Avg Energy: [0.01606931], Avg Reward: [-0.30337346]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36915664.21047833]\n",
            "[28190926.59842022]\n",
            "[22894131.58299772]\n",
            "[37422249.46500327]\n",
            "[26119229.00670706]\n",
            "[33101571.21500776]\n",
            "[37888798.74227113]\n",
            "[34879655.68939269]\n",
            "[33779643.60638414]\n",
            "[37352188.03769341]\n",
            "[23161759.90100849]\n",
            "[17468661.81478284]\n",
            "[20236714.72203723]\n",
            "[35008321.89032526]\n",
            "[17394646.86375295]\n",
            "[16801626.52385116]\n",
            "[17282874.4338201]\n",
            "[22666532.87855252]\n",
            "[23141171.40343641]\n",
            "[31562214.62530965]\n",
            "[22664420.18757814]\n",
            "[20496761.18986945]\n",
            "[37943794.42292785]\n",
            "[31871931.91032086]\n",
            "[29164413.84355208]\n",
            "[38180159.34832978]\n",
            "[26077775.93190305]\n",
            "[37947043.91089671]\n",
            "[16957714.18668741]\n",
            "[37000339.12021171]\n",
            "[20452940.71769166]\n",
            "[35125629.78867051]\n",
            "[36461715.18573044]\n",
            "[21985580.93842291]\n",
            "Train : Episode 14/100 - Steps Count 3 - Avg Delay: [1.04831161], Avg Energy: [0.02261704], Avg Reward: [-0.28837123]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23327668.66642797]\n",
            "[19871179.05862106]\n",
            "[25045136.34460792]\n",
            "[22198526.00555366]\n",
            "[37217234.0637295]\n",
            "[31450836.85163994]\n",
            "[29064163.91409667]\n",
            "[37422249.46500327]\n",
            "[23291615.95642512]\n",
            "[28124245.4947768]\n",
            "[37422249.46500327]\n",
            "[23269262.6569858]\n",
            "[33393498.66909074]\n",
            "[20496761.18986945]\n",
            "Train : Episode 15/100 - Steps Count 1 - Avg Delay: [1.61418095], Avg Energy: [0.02253489], Avg Reward: [-0.38129193]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22109576.72630381]\n",
            "[34193547.75465608]\n",
            "[20236714.72203723]\n",
            "[22666532.87855252]\n",
            "[34393295.41979598]\n",
            "[22198526.00555366]\n",
            "[23375445.02235322]\n",
            "[37888798.74227113]\n",
            "[16632501.42049318]\n",
            "[23056124.95495202]\n",
            "[38180159.34832978]\n",
            "[22909576.72630381]\n",
            "Train : Episode 16/100 - Steps Count 1 - Avg Delay: [0.60947442], Avg Energy: [0.01804249], Avg Reward: [-0.31031863]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26904481.76420993]\n",
            "[31566178.90721865]\n",
            "[22842410.58300274]\n",
            "[17391361.80924979]\n",
            "[23327668.66642797]\n",
            "[16632501.42049318]\n",
            "[19499578.46999943]\n",
            "[33674451.67315209]\n",
            "[23386125.4513474]\n",
            "[20109628.80572335]\n",
            "[37220230.76551127]\n",
            "[37146855.74244598]\n",
            "[22370970.58801287]\n",
            "[23019398.28243497]\n",
            "[22666532.87855252]\n",
            "[37018431.58976579]\n",
            "[20167333.72659649]\n",
            "[22863385.83933584]\n",
            "[37854879.51220907]\n",
            "[20334731.3325545]\n",
            "Train : Episode 17/100 - Steps Count 2 - Avg Delay: [1.52197987], Avg Energy: [0.02602176], Avg Reward: [-0.31504374]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[22972336.84856122]\n",
            "[24963111.73385957]\n",
            "[31335450.99164369]\n",
            "[32191542.50669491]\n",
            "[22109576.72630381]\n",
            "[31748557.39627735]\n",
            "[34296805.57122349]\n",
            "[36928338.18491662]\n",
            "[36904703.3278506]\n",
            "[37215603.17101134]\n",
            "[28573718.32557052]\n",
            "[22684039.11247029]\n",
            "[36817582.25267707]\n",
            "[20530778.06515941]\n",
            "[36509352.345822]\n",
            "[34586096.58830592]\n",
            "[16704593.47681655]\n",
            "[31450836.85163994]\n",
            "[23346538.87102699]\n",
            "[33006026.62144569]\n",
            "[23016186.64503101]\n",
            "[36507859.52250478]\n",
            "[20324784.81851898]\n",
            "[17167699.93928518]\n",
            "[25694355.66243868]\n",
            "[23091831.89019085]\n",
            "[28992774.60838833]\n",
            "[17487247.18950984]\n",
            "[26260658.91372831]\n",
            "[36717508.73248485]\n",
            "[20474039.88882665]\n",
            "[22728116.58328618]\n",
            "[20432327.92652291]\n",
            "[16626367.0981686]\n",
            "[24534779.83428265]\n",
            "[28189371.97228298]\n",
            "Train : Episode 18/100 - Steps Count 3 - Avg Delay: [0.83320076], Avg Energy: [0.02005366], Avg Reward: [-0.2778313]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36817582.25267707]\n",
            "[34330166.31026895]\n",
            "[32138916.66526449]\n",
            "[36772249.46500327]\n",
            "[34695453.66995613]\n",
            "[25735785.87920674]\n",
            "[29020033.92695951]\n",
            "[17391361.80924979]\n",
            "[26119229.00670706]\n",
            "[37543237.99735022]\n",
            "[23434545.55667115]\n",
            "[22529642.75031909]\n",
            "[26051904.23504078]\n",
            "[36772249.46500327]\n",
            "Train : Episode 19/100 - Steps Count 1 - Avg Delay: [1.74184687], Avg Energy: [0.01474284], Avg Reward: [-0.33791325]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28152583.57548842]\n",
            "[34600521.73552445]\n",
            "[23434545.55667115]\n",
            "[23222791.65811059]\n",
            "[28190926.59842022]\n",
            "[33445986.08730524]\n",
            "[23327668.66642797]\n",
            "[37553963.52850033]\n",
            "[37060653.9999494]\n",
            "[30933952.98995384]\n",
            "[31258779.31047771]\n",
            "[22314465.3015374]\n",
            "[37726693.8202557]\n",
            "[31896361.85457627]\n",
            "[37943794.42292785]\n",
            "[37943794.42292785]\n",
            "[17383306.12722194]\n",
            "[23144114.20183729]\n",
            "[19499578.46999943]\n",
            "[22753342.94408209]\n",
            "Train : Episode 20/100 - Steps Count 2 - Avg Delay: [0.74419523], Avg Energy: [0.01397684], Avg Reward: [-0.27722104]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[24963111.73385957]\n",
            "[26173344.11419477]\n",
            "[37841003.8937868]\n",
            "[22995354.19359219]\n",
            "[30775326.29289488]\n",
            "[28782649.5151188]\n",
            "[30933952.98995384]\n",
            "[37537220.01035793]\n",
            "[25582293.26591071]\n",
            "[22201937.08113873]\n",
            "[26904481.76420993]\n",
            "[26119229.00670706]\n",
            "[37905513.52504303]\n",
            "[32072475.97689674]\n",
            "[21767118.21268075]\n",
            "[25989473.53424372]\n",
            "[25026648.25438679]\n",
            "[20140853.87076932]\n",
            "[28322069.58879394]\n",
            "[20236714.72203723]\n",
            "Train : Episode 21/100 - Steps Count 2 - Avg Delay: [1.38414878], Avg Energy: [0.01698082], Avg Reward: [-0.24336497]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37943794.42292785]\n",
            "[26184448.60517605]\n",
            "[17352765.25137783]\n",
            "[25893347.99273708]\n",
            "[23309121.46516518]\n",
            "[34600521.73552445]\n",
            "[25033615.83983283]\n",
            "[19677731.64264556]\n",
            "[26240178.90761231]\n",
            "[37905332.08680747]\n",
            "[37943794.42292785]\n",
            "[23072663.55216632]\n",
            "[30775326.29289488]\n",
            "[26236123.10336099]\n",
            "[22730718.74742981]\n",
            "[17210503.08140014]\n",
            "[20140853.87076932]\n",
            "[34001204.62723239]\n",
            "[38213568.7974591]\n",
            "[36226247.73196699]\n",
            "[38015964.77598054]\n",
            "[22256809.70046797]\n",
            "[16834229.02308463]\n",
            "[20462740.08316351]\n",
            "[17391361.80924979]\n",
            "[23089191.28723542]\n",
            "[32101176.86387233]\n",
            "[28686886.44096498]\n",
            "[23172500.81037895]\n",
            "[20345943.32335969]\n",
            "[31627897.30382799]\n",
            "[37381803.7129907]\n",
            "[37493578.38282262]\n",
            "[34193547.75465608]\n",
            "[37344710.26682355]\n",
            "Train : Episode 22/100 - Steps Count 3 - Avg Delay: [0.77667752], Avg Energy: [0.01784183], Avg Reward: [-0.26147565]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36465943.70246384]\n",
            "[34330166.31026895]\n",
            "[22914352.17637786]\n",
            "[17176004.77788424]\n",
            "[31874941.13902245]\n",
            "[17210503.08140014]\n",
            "[37905332.08680747]\n",
            "[16946329.74159406]\n",
            "[26139548.45933644]\n",
            "[34879655.68939269]\n",
            "[23434545.55667115]\n",
            "[20376834.3143557]\n",
            "[26295323.65034433]\n",
            "[30775326.29289488]\n",
            "[34296805.57122349]\n",
            "[23141171.40343641]\n",
            "[33784660.57190188]\n",
            "[25045136.34460792]\n",
            "[28427821.6413908]\n",
            "[16632501.42049318]\n",
            "[37935913.65913034]\n",
            "[22824660.68859064]\n",
            "[31906062.07962395]\n",
            "[31194762.91113888]\n",
            "[25634372.01557465]\n",
            "[20350535.35126624]\n",
            "[34501630.62966619]\n",
            "[30905885.76416366]\n",
            "[34656911.46195004]\n",
            "[33328678.18895999]\n",
            "[16501171.90528276]\n",
            "[23027850.9764727]\n",
            "[32101176.86387233]\n",
            "[37368004.53500567]\n",
            "[22918614.06402665]\n",
            "[23491831.89019086]\n",
            "[28858789.94542358]\n",
            "[23014736.80579115]\n",
            "[28753037.89282673]\n",
            "[24878058.24476222]\n",
            "[19882468.51789796]\n",
            "[22918614.06402665]\n",
            "[23056938.4906387]\n",
            "[17462389.33876514]\n",
            "Train : Episode 23/100 - Steps Count 4 - Avg Delay: [1.99259651], Avg Energy: [0.02276347], Avg Reward: [-0.2861197]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17141952.75056796]\n",
            "[25783707.83748036]\n",
            "[22617251.37942997]\n",
            "[20345943.32335969]\n",
            "[28906368.56194376]\n",
            "[25831745.69681176]\n",
            "[37018431.58976579]\n",
            "[16900504.28603463]\n",
            "[37888798.74227113]\n",
            "[28124245.4947768]\n",
            "[16634281.69064251]\n",
            "[30041607.62952571]\n",
            "[37905332.08680747]\n",
            "[23181274.29148512]\n",
            "[37550990.51165712]\n",
            "[23291615.95642512]\n",
            "[28902442.16903898]\n",
            "[28782649.5151188]\n",
            "[32178832.61118336]\n",
            "[25562733.00802555]\n",
            "[36717508.73248485]\n",
            "[37841003.8937868]\n",
            "[37285696.10301242]\n",
            "[20376834.3143557]\n",
            "[33013539.48316884]\n",
            "[28946866.26774202]\n",
            "[28828509.80725035]\n",
            "[35454762.37440694]\n",
            "[22643803.63786399]\n",
            "[25598153.39723187]\n",
            "[28255809.01422213]\n",
            "[23169752.63774424]\n",
            "[35255959.90044323]\n",
            "[35494056.74053968]\n",
            "[35012225.1365407]\n",
            "[37580606.18695441]\n",
            "[17011885.86037996]\n",
            "[17101390.61173077]\n",
            "[23014736.80579115]\n",
            "[25445842.00199294]\n",
            "[35494056.74053968]\n",
            "[37471793.82336424]\n",
            "[29354679.6920211]\n",
            "[29331810.56094465]\n",
            "[22767445.41994687]\n",
            "[22500347.98405902]\n",
            "[37334828.07263988]\n",
            "[33393498.66909074]\n",
            "[20158577.21681089]\n",
            "[27760880.96477817]\n",
            "[34201884.12154081]\n",
            "[25218848.82971999]\n",
            "[32057185.39227651]\n",
            "[27624938.17285466]\n",
            "[34005549.47492135]\n",
            "[25218848.82971999]\n",
            "[37215603.17101134]\n",
            "[35882218.0810269]\n",
            "[35095544.28899894]\n",
            "[36488785.04037894]\n",
            "[31962588.29434368]\n",
            "Train : Episode 24/100 - Steps Count 6 - Avg Delay: [2.46594672], Avg Energy: [0.01765133], Avg Reward: [-0.27011728]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20324784.81851898]\n",
            "[20140853.87076932]\n",
            "[36655344.37576871]\n",
            "[22664420.18757814]\n",
            "[36172697.10044441]\n",
            "[37373433.51909681]\n",
            "[37381803.7129907]\n",
            "[20140853.87076932]\n",
            "[35740089.29565461]\n",
            "[31258779.31047771]\n",
            "[36817582.25267707]\n",
            "[37334828.07263988]\n",
            "[25946744.39415146]\n",
            "[25946744.39415146]\n",
            "[37726693.8202557]\n",
            "[37027462.65389091]\n",
            "[36745956.36260124]\n",
            "[36915664.21047833]\n",
            "[34528968.17609446]\n",
            "[23275567.48442303]\n",
            "[36699023.30895393]\n",
            "[19871179.05862106]\n",
            "[32101176.86387233]\n",
            "[17033903.28944234]\n",
            "[28443957.43490734]\n",
            "[37459320.06903985]\n",
            "[34012051.61278963]\n",
            "[31410969.99922127]\n",
            "[28989807.49147278]\n",
            "[34975552.29119044]\n",
            "[34883558.93560814]\n",
            "[33530701.44800819]\n",
            "[30283038.10135065]\n",
            "Train : Episode 25/100 - Steps Count 3 - Avg Delay: [0.90128117], Avg Energy: [0.01891622], Avg Reward: [-0.28496902]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36817582.25267707]\n",
            "[17352765.25137783]\n",
            "[22981335.38921884]\n",
            "[26150861.14477431]\n",
            "[22981335.38921884]\n",
            "[32138916.66526449]\n",
            "[20167333.72659649]\n",
            "[23394641.18879384]\n",
            "[34600521.73552445]\n",
            "[37220218.27042358]\n",
            "[34001204.62723239]\n",
            "[16634281.69064251]\n",
            "[20236714.72203723]\n",
            "[19918009.13930412]\n",
            "[29130646.42167375]\n",
            "[19642806.48201869]\n",
            "[28425043.89782093]\n",
            "[30872636.68512827]\n",
            "[31899939.83027377]\n",
            "[31740174.69805712]\n",
            "[26260682.06743352]\n",
            "[34393295.41979598]\n",
            "[31007192.6063296]\n",
            "[28300186.79639672]\n",
            "[22861370.92014445]\n",
            "[18865056.80943498]\n",
            "[37888798.74227113]\n",
            "[30775326.29289488]\n",
            "[20109628.80572335]\n",
            "[22666532.87855252]\n",
            "[22275136.46487672]\n",
            "[23018831.41945874]\n",
            "[28152583.57548842]\n",
            "Train : Episode 26/100 - Steps Count 3 - Avg Delay: [6.3451104], Avg Energy: [0.01283645], Avg Reward: [-0.23130277]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23161759.90100849]\n",
            "[19677731.64264556]\n",
            "[24963111.73385957]\n",
            "[22256809.70046797]\n",
            "[37776611.57367409]\n",
            "[26904481.76420993]\n",
            "[37943794.42292785]\n",
            "[37018431.58976579]\n",
            "[22824660.68859064]\n",
            "[34001204.62723239]\n",
            "[26119229.00670706]\n",
            "[23055105.21767381]\n",
            "[34664002.31938358]\n",
            "[30775326.29289488]\n",
            "[25694355.66243868]\n",
            "[28015552.72504381]\n",
            "[16632501.42049318]\n",
            "[37100342.29918425]\n",
            "[36136372.9888555]\n",
            "[19642806.48201869]\n",
            "[22861370.92014445]\n",
            "[36817582.25267707]\n",
            "[17142422.96240774]\n",
            "[37712283.38065342]\n",
            "[35098631.31815562]\n",
            "[37377471.07710729]\n",
            "[30041607.62952571]\n",
            "[36172697.10044441]\n",
            "[37182218.08102691]\n",
            "[31229449.15723325]\n",
            "[22689167.61542506]\n",
            "[22528005.42044411]\n",
            "[31704767.47674729]\n",
            "[34705098.04407764]\n",
            "[25072340.13654597]\n",
            "[31964011.16062849]\n",
            "Train : Episode 27/100 - Steps Count 3 - Avg Delay: [0.69591376], Avg Energy: [0.01768217], Avg Reward: [-0.26143363]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35731950.36212119]\n",
            "[31930132.15414155]\n",
            "[37373433.51909681]\n",
            "[22942795.21241603]\n",
            "[23291615.95642512]\n",
            "[37217234.0637295]\n",
            "[22664420.18757814]\n",
            "[17226367.0981686]\n",
            "[36915664.21047833]\n",
            "[32101176.86387233]\n",
            "[22975892.59420711]\n",
            "[25876877.84313171]\n",
            "[20324784.81851898]\n",
            "Train : Episode 28/100 - Steps Count 1 - Avg Delay: [0.74062847], Avg Energy: [0.02506235], Avg Reward: [-0.41041836]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[17210503.08140014]\n",
            "[25996841.63935604]\n",
            "[17210503.08140014]\n",
            "[29179807.46749961]\n",
            "[22664420.18757814]\n",
            "[36292469.48107947]\n",
            "[33445986.08730524]\n",
            "[28807850.13841398]\n",
            "[32138916.66526449]\n",
            "[34424220.00719497]\n",
            "[25643044.59753439]\n",
            "[17176004.77788424]\n",
            "[19527736.53580739]\n",
            "[19787418.71197018]\n",
            "[37038519.25028561]\n",
            "[25831745.69681176]\n",
            "[16710275.68312621]\n",
            "[20140853.87076932]\n",
            "[23247658.61489594]\n",
            "[37776611.57367409]\n",
            "[36745956.36260124]\n",
            "[17394646.86375295]\n",
            "Train : Episode 29/100 - Steps Count 2 - Avg Delay: [0.71764462], Avg Energy: [0.0236756], Avg Reward: [-0.25166597]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[23221850.92200008]\n",
            "[29152583.57548841]\n",
            "[21767118.21268075]\n",
            "[22617251.37942997]\n",
            "[20140853.87076932]\n",
            "[37888798.74227113]\n",
            "[23089191.28723542]\n",
            "[34399183.4783781]\n",
            "[25733743.74690542]\n",
            "[23099028.99463775]\n",
            "[28740559.9725295]\n",
            "[24890041.30376846]\n",
            "[29112740.2305749]\n",
            "[19864336.36738674]\n",
            "[22660182.51539686]\n",
            "[36254507.99147719]\n",
            "[36371413.08071175]\n",
            "[36254507.99147719]\n",
            "[31930132.15414155]\n",
            "[25045136.34460792]\n",
            "[37214440.183749]\n",
            "[24959274.27382637]\n",
            "[28190926.59842022]\n",
            "[28058478.00218581]\n",
            "[22942795.21241603]\n",
            "[34814272.60515618]\n",
            "[37183662.10925821]\n",
            "[37707189.96702443]\n",
            "[34887501.7562117]\n",
            "[33199603.64623894]\n",
            "[22331264.18191224]\n",
            "Train : Episode 30/100 - Steps Count 3 - Avg Delay: [0.88966398], Avg Energy: [0.01795374], Avg Reward: [-0.30110147]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31646893.0337486]\n",
            "[32101176.86387233]\n",
            "[37018431.58976579]\n",
            "[23019398.28243497]\n",
            "[36321884.43111597]\n",
            "[22684039.11247029]\n",
            "[28152583.57548842]\n",
            "[19767530.8677337]\n",
            "[25989473.53424372]\n",
            "[32502254.10671569]\n",
            "[37917428.23559942]\n",
            "[36817582.25267707]\n",
            "[36579115.4417682]\n",
            "[36292469.48107947]\n",
            "[19871526.11101412]\n",
            "[22517784.40940859]\n",
            "[31377987.62431901]\n",
            "[17294783.38078358]\n",
            "[34760368.81048299]\n",
            "[23254157.09709105]\n",
            "[20438728.07732992]\n",
            "[35835457.00514677]\n",
            "[35186196.80449704]\n",
            "[20117502.52879877]\n",
            "[36133783.11104792]\n",
            "[30618355.07252065]\n",
            "[17246036.12027198]\n",
            "[37855234.05936348]\n",
            "[16501171.90528276]\n",
            "[31018924.79733403]\n",
            "[34174211.92385018]\n",
            "[37855234.05936348]\n",
            "[26156729.41805036]\n",
            "[36475792.47012598]\n",
            "[31791022.47300706]\n",
            "[22734933.76928626]\n",
            "Train : Episode 31/100 - Steps Count 4 - Avg Delay: [1.13572411], Avg Energy: [0.01601402], Avg Reward: [-0.25326086]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[35186196.80449704]\n",
            "[32072475.97689674]\n",
            "[32138916.66526449]\n",
            "[29179807.46749961]\n",
            "[36717508.73248485]\n",
            "[19767530.8677337]\n",
            "[26184448.60517605]\n",
            "[33393498.66909074]\n",
            "[35695626.25053229]\n",
            "[28582875.11061588]\n",
            "[37383343.29322017]\n",
            "[29078383.47065892]\n",
            "[35946648.05543454]\n",
            "[37653310.00221647]\n",
            "[22308910.88247291]\n",
            "[22929874.45092416]\n",
            "[16846055.00355843]\n",
            "[17176004.77788424]\n",
            "[22256809.70046797]\n",
            "[37653310.00221647]\n",
            "Train : Episode 32/100 - Steps Count 2 - Avg Delay: [1.33651002], Avg Energy: [0.01765811], Avg Reward: [-0.30649462]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[25616270.32937485]\n",
            "[17630928.9218197]\n",
            "[19871179.05862106]\n",
            "[37905332.08680747]\n",
            "[20236714.72203723]\n",
            "[23434545.55667115]\n",
            "[34879655.68939269]\n",
            "[29179807.46749961]\n",
            "[26349438.75783203]\n",
            "[37334828.07263988]\n",
            "[27810580.50601654]\n",
            "[28573718.32557052]\n",
            "[19764479.95508612]\n",
            "[23199234.18248916]\n",
            "[37404328.64659457]\n",
            "[17383306.12722194]\n",
            "[25472984.40504406]\n",
            "[25946744.39415146]\n",
            "[19871526.11101412]\n",
            "[31302295.15128869]\n",
            "[22863385.83933584]\n",
            "[20345943.32335969]\n",
            "[37334828.07263988]\n",
            "Train : Episode 33/100 - Steps Count 2 - Avg Delay: [1.03072864], Avg Energy: [0.01308367], Avg Reward: [-0.22063614]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26119229.00670706]\n",
            "[31646893.0337486]\n",
            "[36530741.0630051]\n",
            "[23269262.6569858]\n",
            "[31562214.62530965]\n",
            "[17383306.12722194]\n",
            "[23394641.18879384]\n",
            "[28190926.59842022]\n",
            "[23181274.29148512]\n",
            "[29020033.92695951]\n",
            "[19527736.53580739]\n",
            "[25996841.63935604]\n",
            "[28807850.13841398]\n",
            "[28427821.6413908]\n",
            "[22838825.62147018]\n",
            "[23075329.78963304]\n",
            "[34399183.4783781]\n",
            "[37183179.85403487]\n",
            "[32178832.61118336]\n",
            "[22123731.81557523]\n",
            "[23089191.28723542]\n",
            "[25489577.98450861]\n",
            "[36864741.43084024]\n",
            "[37344710.26682355]\n",
            "[20404077.14587521]\n",
            "[28514983.64862052]\n",
            "Train : Episode 34/100 - Steps Count 2 - Avg Delay: [1.03031306], Avg Energy: [0.01833026], Avg Reward: [-0.33666826]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30571518.3977119]\n",
            "[16632501.42049318]\n",
            "[22109576.72630381]\n",
            "[26240178.90761231]\n",
            "[25026648.25438679]\n",
            "[23019398.28243497]\n",
            "[29143440.50290697]\n",
            "[34695453.66995613]\n",
            "[34879655.68939269]\n",
            "[36777189.57532506]\n",
            "[28304404.55035065]\n",
            "[23099028.99463775]\n",
            "[22824660.68859064]\n",
            "[28425043.89782093]\n",
            "[19772739.28643238]\n",
            "[26904481.76420993]\n",
            "[37494422.05144375]\n",
            "[37204879.51220907]\n",
            "[37537220.01035793]\n",
            "[34238155.84412488]\n",
            "[17060025.26203794]\n",
            "[37373433.51909681]\n",
            "[26119229.00670706]\n",
            "[36136372.9888555]\n",
            "[28124245.4947768]\n",
            "[25622966.56763788]\n",
            "[28488922.1027994]\n",
            "Train : Episode 35/100 - Steps Count 2 - Avg Delay: [1.26518012], Avg Energy: [0.01693631], Avg Reward: [-0.27746075]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[34521241.84326933]\n",
            "[37537220.01035793]\n",
            "[33779643.60638414]\n",
            "[23394641.18879384]\n",
            "[26009116.75135473]\n",
            "[28190926.59842022]\n",
            "[36817582.25267707]\n",
            "[33445986.08730524]\n",
            "[28425043.89782093]\n",
            "[22972336.84856122]\n",
            "[33912884.58798402]\n",
            "[28114251.20996682]\n",
            "[34296805.57122349]\n",
            "[31879668.23332975]\n",
            "[19871179.05862106]\n",
            "[37204879.51220907]\n",
            "[22109576.72630381]\n",
            "[20220484.43354032]\n",
            "[23327668.66642797]\n",
            "[23019398.28243497]\n",
            "[37996574.52270168]\n",
            "[22353341.73044022]\n",
            "Train : Episode 36/100 - Steps Count 2 - Avg Delay: [1.11465391], Avg Energy: [0.01851312], Avg Reward: [-0.29235505]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[36172697.10044441]\n",
            "[22842410.58300274]\n",
            "[23144114.20183729]\n",
            "[36817582.25267707]\n",
            "[20447009.26497448]\n",
            "[20384552.22655621]\n",
            "[34600521.73552445]\n",
            "[26904481.76420993]\n",
            "[20111335.16712698]\n",
            "[23089191.28723542]\n",
            "[19741483.1253228]\n",
            "[30775326.29289488]\n",
            "[17630928.9218197]\n",
            "[26349438.75783203]\n",
            "[17025015.53581829]\n",
            "[23357914.51627679]\n",
            "[35941658.80564721]\n",
            "[26184448.60517605]\n",
            "[37888798.74227113]\n",
            "[34845776.05734305]\n",
            "[22864077.81258375]\n",
            "[26139548.45933644]\n",
            "[22974056.15931845]\n",
            "[37905332.08680747]\n",
            "[28828509.80725035]\n",
            "[23095224.59633775]\n",
            "[37166435.02501307]\n",
            "Train : Episode 37/100 - Steps Count 2 - Avg Delay: [0.71324441], Avg Energy: [0.02006666], Avg Reward: [-0.29855769]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[30775326.29289488]\n",
            "[22666532.87855252]\n",
            "[23089191.28723542]\n",
            "[37506913.88576131]\n",
            "[29020033.92695951]\n",
            "[22617251.37942997]\n",
            "[29152583.57548841]\n",
            "[25045136.34460792]\n",
            "[25946744.39415146]\n",
            "[23082773.89107458]\n",
            "[18865056.80943498]\n",
            "[17510388.10402471]\n",
            "[37710653.9999494]\n",
            "[37073099.72041079]\n",
            "[31607484.70760105]\n",
            "[36817582.25267707]\n",
            "[37018431.58976579]\n",
            "[19767530.8677337]\n",
            "[35979070.87924019]\n",
            "[17510388.10402471]\n",
            "[29425302.65473899]\n",
            "[20199747.62916119]\n",
            "[20369438.88809485]\n",
            "[16808206.63468079]\n",
            "[17328879.66689213]\n",
            "[33920834.11421838]\n",
            "Train : Episode 38/100 - Steps Count 2 - Avg Delay: [1.13349485], Avg Energy: [0.0136367], Avg Reward: [-0.35130865]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[28573718.32557052]\n",
            "[17141952.75056796]\n",
            "[28443957.43490734]\n",
            "[23161759.90100849]\n",
            "[26150861.14477431]\n",
            "[26184448.60517605]\n",
            "[28469123.27268241]\n",
            "[19767530.8677337]\n",
            "[25996841.63935604]\n",
            "[28782649.5151188]\n",
            "[23327668.66642797]\n",
            "[22666532.87855252]\n",
            "[32502254.10671569]\n",
            "[31925387.00006223]\n",
            "[17011885.86037996]\n",
            "[16632501.42049318]\n",
            "[29143440.50290697]\n",
            "[26296675.08964827]\n",
            "[19571583.73581321]\n",
            "[22591701.81615216]\n",
            "[35821200.09834924]\n",
            "[21549968.85280308]\n",
            "[23089191.28723542]\n",
            "[34681294.81621967]\n",
            "[32164689.33345329]\n",
            "[29179807.46749961]\n",
            "[37282424.94174721]\n",
            "[31640397.45711039]\n",
            "[37678178.59967539]\n",
            "[31632432.45110742]\n",
            "[25389971.26622317]\n",
            "[19291805.91860667]\n",
            "[28300186.79639672]\n",
            "[35012392.61798893]\n",
            "[23413718.36157534]\n",
            "[22370970.58801287]\n",
            "[19776573.15236542]\n",
            "[19764479.95508612]\n",
            "[22500347.98405902]\n",
            "[22643803.63786399]\n",
            "[22500347.98405902]\n",
            "[35529350.37122569]\n",
            "[22808081.88785036]\n",
            "[19776573.15236542]\n",
            "[20124039.88882665]\n",
            "[36717508.73248485]\n",
            "[28992774.60838833]\n",
            "[22818229.43461336]\n",
            "[36905991.86632062]\n",
            "[17360017.44078583]\n",
            "[36016411.15138074]\n",
            "[37062345.45231881]\n",
            "[20075611.93043339]\n",
            "[17630928.9218197]\n",
            "[34797408.67082152]\n",
            "[33679655.68939269]\n",
            "[23074847.84624837]\n",
            "[25682026.60761308]\n",
            "[37381020.55499062]\n",
            "[33881678.94844089]\n",
            "[23529581.10515236]\n",
            "[17301363.49161321]\n",
            "[28842295.05218013]\n",
            "[37383535.62768522]\n",
            "[25827137.22954367]\n",
            "[22154353.62051403]\n",
            "[23019398.28243497]\n",
            "[25700365.49000043]\n",
            "[25645815.68687413]\n",
            "[20479145.1034269]\n",
            "[37018781.79185726]\n",
            "[34377057.73062259]\n",
            "[35081567.85028093]\n",
            "[36968738.75556932]\n",
            "[19583433.32774355]\n",
            "[31274177.36127323]\n",
            "[31591697.27177098]\n",
            "[25229611.34173245]\n",
            "Train : Episode 39/100 - Steps Count 8 - Avg Delay: [0.91140679], Avg Energy: [0.01821395], Avg Reward: [-0.25309971]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[37381803.7129907]\n",
            "[24963111.73385957]\n",
            "[33393498.66909074]\n",
            "[16900504.28603463]\n",
            "[25518808.14954366]\n",
            "[25946877.54878111]\n",
            "[22328571.84442481]\n",
            "[19767530.8677337]\n",
            "[30947721.77413095]\n",
            "[28908130.30188541]\n",
            "[20452940.71769166]\n",
            "[36337223.18933047]\n",
            "[23327668.66642797]\n",
            "[17352765.25137783]\n",
            "[25033615.83983283]\n",
            "[31673483.79159844]\n",
            "[26184448.60517605]\n",
            "[20236714.72203723]\n",
            "[24909580.34065679]\n",
            "[36905991.86632062]\n",
            "[19484946.30297206]\n",
            "[22723487.42372498]\n",
            "[23152320.66518418]\n",
            "[29574809.78172462]\n",
            "[30788305.2421533]\n",
            "[36573449.46113697]\n",
            "[36717508.73248485]\n",
            "[22591701.81615216]\n",
            "[22264385.97554751]\n",
            "[25867117.40424105]\n",
            "[20296864.16724717]\n",
            "[33862519.47086416]\n",
            "[17459184.13511348]\n",
            "[17399893.54318714]\n",
            "[28488922.1027994]\n",
            "[20183800.72707804]\n",
            "[31741349.80837413]\n",
            "[33580523.22492369]\n",
            "[25719503.12430791]\n",
            "[19882468.51789796]\n",
            "[37147846.04469525]\n",
            "[22798612.88710769]\n",
            "[19772739.28643238]\n",
            "Train : Episode 40/100 - Steps Count 4 - Avg Delay: [1.25863626], Avg Energy: [0.01753021], Avg Reward: [-0.28623071]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[31627897.30382799]\n",
            "[32072475.97689674]\n",
            "[25859468.61047201]\n",
            "[22666532.87855252]\n",
            "[32138916.66526449]\n",
            "[25859468.61047201]\n",
            "[30947721.77413095]\n",
            "[22995354.19359219]\n",
            "[19677731.64264556]\n",
            "[31627897.30382799]\n",
            "[25518808.14954366]\n",
            "[22370970.58801287]\n",
            "[17471012.62107315]\n",
            "[27860102.32512784]\n",
            "[20345943.32335969]\n",
            "Train : Episode 41/100 - Steps Count 1 - Avg Delay: [1.06113007], Avg Energy: [0.01333548], Avg Reward: [-0.41439661]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[19527736.53580739]\n",
            "[25946744.39415146]\n",
            "[32178832.61118336]\n",
            "[36292469.48107947]\n",
            "[34393295.41979598]\n",
            "[37351917.85212491]\n",
            "[25616270.32937485]\n",
            "[19677731.64264556]\n",
            "[21767118.21268075]\n",
            "[23089191.28723542]\n",
            "[17476887.48431465]\n",
            "[20195240.60167987]\n",
            "[23218229.43461335]\n",
            "[31871931.91032086]\n",
            "[34600521.73552445]\n",
            "[36465943.70246384]\n",
            "[29179807.46749961]\n",
            "[37634918.84616083]\n",
            "[23181274.29148512]\n",
            "[38028187.12661475]\n",
            "[22842410.58300274]\n",
            "[24907503.86263305]\n",
            "[28300186.79639672]\n",
            "[33692650.1057578]\n",
            "[22981335.38921884]\n",
            "[20183800.72707804]\n",
            "[36904703.3278506]\n",
            "[25996841.63935604]\n",
            "[22942795.21241603]\n",
            "[17391361.80924979]\n",
            "[25996841.63935604]\n",
            "[37038519.25028561]\n",
            "Train : Episode 42/100 - Steps Count 3 - Avg Delay: [0.88517723], Avg Energy: [0.02292586], Avg Reward: [-0.26599854]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[26184448.60517605]\n",
            "[23341135.84376071]\n",
            "[30571518.3977119]\n",
            "[37107157.88970394]\n",
            "[31930132.15414155]\n",
            "[23434545.55667115]\n",
            "[19677731.64264556]\n",
            "[26139548.45933644]\n",
            "[29402521.36604876]\n",
            "[21889458.19665842]\n",
            "[36172697.10044441]\n",
            "Train : Episode 43/100 - Steps Count 1 - Avg Delay: [0.86537643], Avg Energy: [0.01806463], Avg Reward: [-0.29165728]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[20111335.16712698]\n",
            "[16834229.02308463]\n",
            "[36717508.73248485]\n",
            "[37204879.51220907]\n",
            "[37381803.7129907]\n",
            "[36968738.75556932]\n",
            "[22666532.87855252]\n",
            "[24890041.30376846]\n",
            "[36575470.4751154]\n",
            "[32101176.86387233]\n",
            "[22152507.86227071]\n",
            "[22152507.86227071]\n",
            "[37865603.17101134]\n",
            "[36677751.49806259]\n",
            "[34685140.6056327]\n",
            "[33445986.08730524]\n",
            "[23099028.99463775]\n",
            "[22364218.41669537]\n",
            "[33301188.04234686]\n",
            "[17429290.02897894]\n",
            "[23161759.90100849]\n",
            "[30947721.77413095]\n",
            "[34118496.5810165]\n",
            "[22423071.77001782]\n",
            "[33328245.26101746]\n",
            "[34927677.25728597]\n",
            "[33782795.02053718]\n",
            "[32032125.97471727]\n",
            "[34695453.66995613]\n",
            "[34670602.44826128]\n",
            "[28911383.00706495]\n",
            "[28573718.32557052]\n",
            "Train : Episode 44/100 - Steps Count 3 - Avg Delay: [0.836859], Avg Energy: [0.0169314], Avg Reward: [-0.28339326]\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m env\u001b[39m.\u001b[39mF_max_es \u001b[39m=\u001b[39m F_max_es \u001b[39m*\u001b[39m \u001b[39m1e9\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[39m# Train the agent\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(num_train_episodes)\n\u001b[0;32m     38\u001b[0m \u001b[39m# Save the Q-table for this configuration\u001b[39;00m\n\u001b[0;32m     39\u001b[0m q_table_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(q_table_folder, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mQ_table_F\u001b[39m\u001b[39m{\u001b[39;00mF_max_es\u001b[39m}\u001b[39;00m\u001b[39m_Dev\u001b[39m\u001b[39m{\u001b[39;00mdeviation\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[3], line 147\u001b[0m, in \u001b[0;36mQLearningAgent.train\u001b[1;34m(self, num_episodes)\u001b[0m\n\u001b[0;32m    142\u001b[0m avg_rewards \u001b[39m=\u001b[39m []\n\u001b[0;32m    145\u001b[0m \u001b[39mfor\u001b[39;00m episode \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_episodes):\n\u001b[0;32m    146\u001b[0m     \u001b[39m# Initialize device state information for all users at the beginning of each episode\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     device_state_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset()\n\u001b[0;32m    149\u001b[0m     \u001b[39m# Initialize total delay and energy for this episode\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     total_delay \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "Cell \u001b[1;32mIn[2], line 374\u001b[0m, in \u001b[0;36mEdgeComputingEnvironment.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessing_tasks \u001b[39m=\u001b[39m []  \u001b[39m# Clear processing tasks\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_time \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reset current time\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize_user_device_params()  \u001b[39m# Reinitialize user device parameters\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_bandwidth \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reinitialize total bandwidth\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_computation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reinitialize total computation\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mEdgeComputingEnvironment.initialize_user_device_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marea_size \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)  \u001b[39m# Distance to server\u001b[39;00m\n\u001b[0;32m     61\u001b[0m g_m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPL_d(d)])  \u001b[39m# Path loss\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m h_bar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39mj \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)  \u001b[39m# Channel gain\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_device_params\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     65\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdevice_id\u001b[39m\u001b[39m'\u001b[39m: device_id,  \u001b[39m# Assign a unique ID to each device\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m: d,\n\u001b[0;32m     67\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mg_m\u001b[39m\u001b[39m'\u001b[39m: g_m,\n\u001b[0;32m     68\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mh_bar\u001b[39m\u001b[39m'\u001b[39m: h_bar,\n\u001b[0;32m     69\u001b[0m })\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# learning and test for F_max_es and deviation_values\n",
        "\n",
        "# Assuming you have your EdgeComputingEnvironment and QLearningAgent defined as per your code\n",
        "env = EdgeComputingEnvironment()\n",
        "\n",
        "# Define the number of users/devices\n",
        "num_users = env.M\n",
        "\n",
        "# Define the different F_max_es values and f_es_dev, f_ue_dev values\n",
        "F_max_es_values = [30, 32, 34, 36, 38]\n",
        "deviation_values = [0.0, 0.02]\n",
        "\n",
        "# Initialize the Q-learning agent\n",
        "agent = QLearningAgent(env, num_users)\n",
        "\n",
        "# Define the number of episodes for training and testing steps\n",
        "num_train_episodes = 100  # or any suitable number for training\n",
        "num_test_steps = 20  # or any suitable number for testing\n",
        "\n",
        "# Create the folder for Q-table files if it doesn't exist\n",
        "q_table_folder = 'Q-Tables_Tese2'\n",
        "os.makedirs(q_table_folder, exist_ok=True)\n",
        "\n",
        "# Storage for results\n",
        "results = []\n",
        "\n",
        "# Train and save Q-tables\n",
        "for deviation in deviation_values:\n",
        "    env.f_es_dev = deviation\n",
        "    env.f_ue_dev = deviation\n",
        "\n",
        "    for F_max_es in F_max_es_values:\n",
        "        env.F_max_es = F_max_es * 1e9\n",
        "\n",
        "        # Train the agent\n",
        "        agent.train(num_train_episodes)\n",
        "\n",
        "        # Save the Q-table for this configuration\n",
        "        q_table_filename = os.path.join(q_table_folder, f'Q_table_F{F_max_es}_Dev{deviation}.json')\n",
        "        agent.save_q_table(q_table_filename)\n",
        "\n",
        "# Test and collect metrics\n",
        "for deviation in deviation_values:\n",
        "    for F_max_es in F_max_es_values:\n",
        "\n",
        "        # Load the Q-table for this configuration\n",
        "        q_table_filename = os.path.join(q_table_folder, f'Q_table_F{F_max_es}_Dev{deviation}.json')\n",
        "        agent.load_q_table(q_table_filename)\n",
        "\n",
        "        env.f_es_dev = deviation\n",
        "        env.f_ue_dev = deviation\n",
        "        env.F_max_es = F_max_es * 1e9\n",
        "\n",
        "        # Test the agent and get the average delay and alpha\n",
        "        avg_delay, avg_alpha = agent.test(num_test_steps)\n",
        "\n",
        "        # Store the results\n",
        "        results.append({\n",
        "            'F_max_es': F_max_es,\n",
        "            'f_dev': deviation,\n",
        "            'avg_delay': avg_delay,\n",
        "            'avg_alpha': avg_alpha\n",
        "        })\n",
        "\n",
        "# Prepare data for plotting\n",
        "delays_data = {deviation: [] for deviation in deviation_values}\n",
        "alphas_data = {deviation: [] for deviation in deviation_values}\n",
        "\n",
        "# Fill the data lists with default values if missing\n",
        "for F_max_es in F_max_es_values:\n",
        "    for deviation in deviation_values:\n",
        "        found = False\n",
        "        for result in results:\n",
        "            if result['F_max_es'] == F_max_es and result['f_dev'] == deviation:\n",
        "                delays_data[deviation].append(result['avg_delay'][0] if isinstance(result['avg_delay'], np.ndarray) else result['avg_delay'])\n",
        "                if deviation == 0:\n",
        "                    alphas_data[deviation].append(result['avg_alpha'])\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            delays_data[deviation].append(0)\n",
        "            if deviation == 0:\n",
        "                alphas_data[deviation].append(0)\n",
        "\n",
        "# Plotting the results\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot for delay\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(F_max_es_values))\n",
        "\n",
        "for i, deviation in enumerate(deviation_values):\n",
        "    ax1.bar(index + i * bar_width, delays_data[deviation], bar_width, label=f'Latency, $\\hat{{f}} = {deviation}$', alpha=0.6)\n",
        "\n",
        "ax1.set_xlabel(\"Maximum ES's processing rate (GHz)\")\n",
        "ax1.set_ylabel(\"The total latency (ms)\")\n",
        "ax1.set_title(\"The impact of ES's processing rate, deviation values, and offloading behavior\")\n",
        "ax1.set_xticks(index + bar_width / 2)\n",
        "ax1.set_xticklabels(F_max_es_values)\n",
        "ax1.legend(loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot for average alphas\n",
        "ax2 = ax1.twinx()\n",
        "alphas = alphas_data[0]\n",
        "ax2.plot(index + bar_width / 2, alphas, marker='o', color='red', label='Average offloading portions, $\\hat{f} = 0$')\n",
        "\n",
        "ax2.set_ylabel(\"Average UEs offloading portions\")\n",
        "ax2.legend(loc='upper right')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
